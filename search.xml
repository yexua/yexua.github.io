<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[双亲委派模型]]></title>
    <url>%2F2019%2F08%2F14%2F%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[背景对于任意一个类，都需要由加载它的类加载器和这个类本身来一同确立在Java虚拟机中的唯一性 如果不是同一个类加载器加载，即使是相同的class文件，也会出现判断不同的情况，从而引发一些意想不到情况，为了保证相同的class文件，在使用的时候，是相同的对象，JVM设计的时候，采用了双亲委派的方式来加载类。 双亲委派模型双亲委派模式的工作原理的是;如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行，如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器，如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务（它的搜索范围中没有找到所需的类），子加载器才会尝试自己去加载，这就是双亲委派模式，即每个儿子都不愿意干活，每次有活就丢给父亲去干，直到父亲说这件事我也干不了时，儿子自己想办法去完成。 双亲委派模式优势采用双亲委派模式的是好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关系可以避免类的重复加载，当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次。其次是考虑到安全因素，java核心api中定义类型不会被随意替换，假设通过网络传递一个名为java.lang.Integer的类，通过双亲委托模式传递到启动类加载器，而启动类加载器在核心Java API发现这个名字的类，发现该类已被加载，并不会重新加载网络传递的过来的java.lang.Integer，而直接返回已加载过的Integer.class，这样便可以防止核心API库被随意篡改。 破环双亲委派模型双亲委派模型并不是一个强制性的约束模型，而是java设计者推荐给开发者的类加载器实现方式。在Java的世界中大部分的类加载器都遵循这个模型，但也有例外。 为什么要破坏双亲委派因为在某些情况下父类加载器需要委托子类加载器去加载class文件。受到加载范围的限制，父类加载器无法加载到需要的文件，以Driver接口为例，由于Driver接口定义在JDK当中的，而其实现由各个数据库的服务商来提供，比如mysql的就写了MySQL Connector，那么问题就来了，DriverManager（也由jdk提供）要加载各个实现了Driver接口的实现类，然后进行管理，但是DriverManager由启动类加载器加载，只能记载JAVA_HOME的lib下文件，而其实现是由服务商提供的，由系统类加载器加载，这个时候就需要启动类加载器来委托子类来加载Driver实现，从而破坏了双亲委派，这里仅仅是举了破坏双亲委派的其中一个情况。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[动态代理]]></title>
    <url>%2F2019%2F08%2F09%2F%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[什么是动态代理 它是一个代理机制。如果熟悉设计模式中的代理模式，我们会知 道，代理可以看作是对调用目标的一个包装，这样我们对目标代码的调 用不是直接发生的，而是通过代理完成。 通过代理可以让调用者与实现者之间解耦。比如进行RPC调用，框架内 部的寻址、序列化、反序列化等，对于调用者往往是没有太大意义的， 通过代理，可以提供更加友善的界面。 写一个简单的JDK动态代理例 12345678910111213141516171819202122232425262728293031323334353637383940public class MyDynamicProxy &#123; public static void main(String[] args) &#123; HelloImpl helloImpl = new HelloImpl(); MyInvocationHandler handler = new MyInvocationHandler(helloImpl); Hello hello = (Hello) Proxy.newProxyInstance(HelloImpl.class.getClassLoader(), new Class[]&#123;Hello.class&#125;, handler); hello.hello(); &#125;&#125;interface Hello &#123; void hello();&#125;class HelloImpl implements Hello &#123; @Override public void hello() &#123; System.out.println("Hello World"); &#125;&#125;class MyInvocationHandler implements InvocationHandler &#123; //目标对象 private Object target; public MyInvocationHandler(Object target) &#123; this.target = target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println("前置通知代码"); //执行目标方法 Object result = method.invoke(target, args); System.out.println("后置通知代码"); return result; &#125;&#125; 在上面的例子中，非常简单地实现了动态代理的构建和代理操作。首先，实现对应的InvocationHandler；然后，以接口Hello为纽带，为被调用目标构建代理对象，进而应用程序就可以使用代理对象间接运行调用目标的逻辑，代理为应用插入额外逻辑提供了便利的入口。 从API设计和实现的角度，这种实现仍然有局限性，因为它是以接口为 中心的，相当于添加了一种对于被调用者没有太大意义的限制。我们实 例化的是Proxy对象，而不是真正的被调用类型，这在实践中还是可能 带来各种不便和能力退化 如果被调用者没有实现接口，而我们还是希望利用动态代理机制，那么可以考虑其他方式。我们知道还有一种方式cglib，如果我们选择cglib方式，你会发现对接口的依赖 被克服了。cglib动态代理采取的是创建目标类的子类的方式，因为是子类化，我们 可以达到近似使用被调用者本身的效果。 JDK Proxy的优势： 最小化依赖关系，减少依赖意味着简化开发和维护，JDK本身的支 持，可能比cglib更加可靠。 平滑进行JDK版本升级，而字节码类库通常需要进行更新以保证在 新版Java上能够使用。 代码实现简单。 基于类似cglib框架的优势： 有的时候调用目标可能不便实现额外接口，从某种角度看，限定调 用者实现接口是有些侵入性的实践，类似cglib动态代理就没有这种 限制。 只操作我们关心的类，而不必为其他相关类增加工作量。 高性能。]]></content>
      <categories>
        <category>java基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[TCP拥塞控制]]></title>
    <url>%2F2019%2F08%2F04%2FTCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[拥塞计算机网络中的资源都是有限的，某段时间内网络中对资源的需求超过了网络中的可用部分，而导致网络性能下降的情况就是拥塞。通俗点说就是发送的数据包太多网络中的设备处理不过来，而导致网络性能下降的情况。 拥塞控制室作用于网络，他是防止过多的数据注入到网络中，避免出现网络负载过大的情况； TCP为什么要进行拥塞控制网络中的路由器会有一个数据包处理队列，当路由器接收到的数据包太多而一下子处理不过来时，就会导致数据包处理队列过长。此时，路由器就会无条件的丢弃新接收到的数据封包。 这就会导致上层的TCP协议以为数据包在网络中丢失，进行重传这些数据包，而路由器又会丢弃这些重传的数据包，如此以往，就会导致网络性能急剧下降，引起网络瘫痪。 因此，TCP需要控制数据包发送的数量来避免网络性能的下降 拥塞控制的方法慢开始拥塞窗口发送方维持一个叫做拥塞窗口cwnd（congestion window）的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口，另外考虑到接受方的接收能力，发送窗口可能小于拥塞窗口。 传输轮次一个传输轮次是指发送方把自己的发送窗口内的数据全部发送出去并收到对最后一个字节的确认。 例如，A将自己的发送窗口内的数据全部连续发送给了B，而B收到这些数据后向A发送了对这些数据的确认，A收到这个确认后，一个传输轮次就算是完成了。 拥塞避免为了防止cwnd增长过大引起网络拥塞，还需设置一个慢开始门限(slow-start threshold)状态变量。ssthresh的用法如下：当cwnd&lt;ssthresh时，使用慢开始算法。当cwnd&gt;ssthresh时，改用拥塞避免算法。当cwnd=ssthresh时，慢开始与拥塞避免算法任意 拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口按线性规律缓慢增长。 拥塞避免的过程如下： 快重传快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方，可提高网络吞吐量约20%）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。 快恢复快恢复算法是与快重传算法配合使用的一个算法。 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半（为了预防网络发生拥塞）。但是接下去并不执行慢开始算法考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh减半后的值，然后执行拥塞避免算法，使cwnd缓慢增大。 快恢复过程如下： 关于 乘法减小（Multiplicative Decrease）和加法增大（Additive Increase）： “乘法减小”指的是无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞，就把慢开始门限ssthresh设置为出现拥塞时的发送窗口大小的一半，并执行慢开始算法，所以当网络频繁出现拥塞时，ssthresh下降的很快，以大大减少注入到网络中的分组数。“加法增大”是指执行拥塞避免算法后，使拥塞窗口缓慢增大，以防止过早出现拥塞。常合起来成为AIMD算法。]]></content>
      <categories>
        <category>网络</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MySQL索引]]></title>
    <url>%2F2019%2F05%2F13%2FMySQL%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[MySQL索引的建立对于MySQL的高效运行是很重要的，索引可以大大提高MySQL的检索速度。那我们就来详细了解一下索引 索引是什么 MySQL官方对索引的定义为：索引是帮助 MySQL 高效获取数据的数据结构。 在数据之外，数据库系统还维护着满足特定查找算法的数据结构**，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。下图就是一种可能的索引方式示例： 索引的出现就是为了提高查询效率，就像书的目录。其实说白了，索引要解决的就是查询问题。 查询，是数据库所提供的一个重要功能，我们都想尽可能快的获取到目标数据，因此就需要优化数据库的查询算法，选择合适的查询模型来实现索引。 优势 索引提高数据检索的效率，降低数据库的IO成本。 通过索引对数据进行排序，降低数据排序的成本，降低了CPU的消耗。 劣势 实际索引也是一张表，该表保存了主键与索引字段，并指向实体表的记录，索引列也要占空间。 提高查询速度，降低更新表的速度。保存表数据，还要保存索引文件每次更新添加索引列字段。 索引的数据结构B+树任何一种数据结构都不是凭空产生的，一定会有它的背景和使用场景，我们现在总结一下，我们需要这种数据结构能够做些什么，其实很简单，那就是：每次查找数据时把磁盘IO次数控制在一个很小的数量级，最好是常数数量级。那么我们就想到如果一个高度可控的多路搜索树是否能满足需求呢？就这样，b+树应运而生。 如上图，是一颗b+树，关于b+树的定义可以参见B+树，这里只说一些重点，浅蓝色的块我们称之为一个磁盘块，可以看到每个磁盘块包含几个数据项（深蓝色所示）和指针（黄色所示），如磁盘块1包含数据项17和35，包含指针P1、P2、P3，P1表示小于17的磁盘块，P2表示在17和35之间的磁盘块，P3表示大于35的磁盘块。真实的数据存在于叶子节点即3、5、9、10、13、15、28、29、36、60、75、79、90、99。非叶子节点不存储真实的数据，只存储指引搜索方向的数据项，如17、35并不真实存在于数据表中。 b+树的查找过程如图所示，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。 建索引的几大原则 最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。 =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。 尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录。 索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’)。 尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。 索引优化explain命令 explain命令的具体用法和字段含义可以参考官网explain-output。rows是核心指标，绝大部分rows小的语句执行一定很快，所以优化语句基本上是在优化rows。 explain结果列说明id列id为SELECT的标识符。它是在SELECT查询中的顺序编号。如果这一行表示其他行的union结果，这个值可以为空。在这种情况下，table列会显示为形如，表示它是id为M和N的查询行的联合结果。 注意：id列数字越大越先执行，如果说数字一样大，那么就从上往下依次执行。 select_type SIMPLE： 简单的 select 查询，查询中不包含 子查询 或者 UNION。 PRIMARY： 查询中若包含任何复杂的子部分，最外层查询则被标记为 PRIMARY。 SUBQUERY： 在 SELECT 或 WHERE 列表中包含了子查询。 DERIVED： 在FROM列表中包含的子查询被标记为DERIVED(衍生)MySQL会递归执行这些子查询,把结果放在临时表里。 UNION： 若第二个SELECT出现在UNION之后，则被标记为UNION; 若UNION包含在FROM子句的子查询中,外层SELECT将被标记为：DERIVED。 UNION RESULT： 从 UNION 表获取结果的 SELECT。 table显示的查询表名，如果查询使用了别名，那么这里显示的是别名，如果不涉及对数据表的操作，那么这显示为null，如果显示为尖括号括起来的就表示这个是临时表，后边的N就是执行计划中的id，表示结果来自于这个查询产生。如果是尖括号括起来的，与类似，也是一个临时表，表示这个结果来自于union查询的id为M,N的结果集。如果是尖括号括起来的，这个表示子查询结果被物化，之后子查询结果可以被复用。 type从最好到最差依次是：system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL一般来说，保证查询至少达到 range 级别，最好能达到 ref。除了all之外，其他的type都可以使用到索引，除了index_merge之外，其他的type只可以用到一个索引。 system： 表只有一行记录(等于系统表)，这是const类型的特列，平时不会出现，也可以忽略不计。 const： 表示通过索引一次就找到了,const用于比较primary key或者unique索引。因为只匹配一行数据，所以很快Dr如将主键置于where列表中，MySQL 就能将该查询转换为一个常量。 eq_ref： 唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键或唯一 索引扫描。 ref： 非唯一性索引扫描，返回匹配某个单独值的所有行。本质上也是一种索引访问，它返回所有匹配某个单独值的行，然而，它可能会找到多个符合条件的行，所以他应该属于查找和扫描的混合体。 fulltext：全文索引检索，要注意，全文索引的优先级很高，若全文索引和普通索引同时存在时，mysql不管代价，优先选择使用全文索引 ref_or_null：与ref方法类似，只是增加了null值的比较。实际用的不多。 例如： SELECT * FROM ref_table WHERE key_column=expr OR key_column IS NULL; index_merge：表示查询使用了两个以上的索引，最后取交集或者并集，常见and ，or的条件使用了不同的索引，官方排序这个在ref_or_null之后，但是实际上由于要读取所个索引，性能可能大部分时间都不如range unique_subquery：用于where中的in形式子查询，子查询返回不重复值唯一值 index_subquery：用于in形式子查询使用到了辅助索引或者in常数列表，子查询可能返回重复值，可以使用索引将子查询去重。 range： 只检索给定范围的行，使用一个索引来选择行。key 列显示使用了哪个索引，一般就是在你的where语句中出现了between、&lt;、&gt;、in等的查询这种范围扫描索引扫描比全表扫描要好，因为它只需要开始于索引的某一点， 而结束语另- -点，不用扫描全部索引。 index： Full Index Scan，index 与 ALL 区别是 index类型只遍历索引树。这通常比ALL快，因为索引文件通常比数据文件小。(也就是说虽然all和Index都是读全表，但index是 从索引中读取的，而all是 从硬盘中读的) ALL： Full Table Scan，将遍历全表以找到匹配的行。 partitions版本5.7以前，该项是explain partitions显示的选项，5.7以后成为了默认选项。该列显示的为分区表命中的分区情况。非分区表该字段为空（null）。 possible_keys查询可能使用到的索引都会在这里列出来 key 查询真正使用到的索引，select_type为index_merge时，这里可能出现两个以上的索引，其他的select_type这里只会出现一个。 key_len用于处理查询的索引长度，如果是单列索引，那就整个索引长度算进去，如果是多列索引，那么查询不一定都能使用到所有的列，具体使用到了多少个列的索引，这里就会计算进去，没有使用到的列，这里不会计算进去。留意下这个列的值，算一下你的多列索引总长度就知道有没有使用到所有的列了。要注意，mysql的ICP特性使用到的索引不会计入其中。另外，key_len只计算where条件用到的索引长度，而排序和分组就算用到了索引，也不会计算到key_len中。 ref如果是使用的常数等值查询，这里会显示const，如果是连接查询，被驱动表的执行计划这里会显示驱动表的关联字段，如果是条件使用了表达式或者函数，或者条件列发生了内部隐式转换，这里可能显示为func rows这里是执行计划中估算的扫描行数，不是精确值 Extra Using filesort：说明MySQL会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。MySQL中无法利用索引完成的排序成为“文件排序”。 Using temporary：使用了临时表保存中间结果，MySQL在对查询结果排序时使用临时表。常见于排序order by和分组查询 group by。 Using index：表示相应的select操作中使用了覆盖索引(Covering Index)， 避免访问了表的数据行，效率不错!如果同时出现 usingwhere,表明索引被用来执行索引键值的查找;如果没有同时出现 usingwhere,表明索引用来读取数据而非执行查找动作。 Using where：表明使用了 where 过滤。 Using join buffer：使用了连接缓存。 Impossible where：where 字句的值总是false，不能用来获取任何元素。 select tables optimized away：在没有 group by 字句的情况下，基于索引优化MIN/MAX操作或者对于MyISAM存储引擎优化COUNT(*)操作，不必等到执行阶段在进行计算，查询执行计划生成的阶段即完成优化。 distinct：优化 distinct 操作，在找到第一匹配的元素后即停止找同样值的动作。 慢查询日志MySQL的慢查询日志是MySQL提供的一种日志记录，它用来记录在MySQL中响应时间超过阈值的语句,具体指运行时间超过 long_query_time 值 的SQL,则会被记录到慢查询日志中。 运行时间超过 long_query_time 值的SQL，会被记录到慢查询日志中，默认关闭，调优需要手动开启。long_ query_ time的默认值为10，意思是运行10秒以上的语句。由他来查看哪些SQL超出了我们的最大忍耐时间值，比如一条sql执行超过5秒钟，我们就算慢SQL，希望能收集超过5秒的sql，结合之前explain进行全面分析。 slow_query_log1234567891011121314&lt;!--如何查看--&gt;SHOW VARIABLES LIKE '%slow_query_log%';&lt;!--如何开启 下面命令只对当前数据库有效--&gt;set global slow_query_log=1;&lt;!--永久生效 修改my.cnf[mysqld]下增加或修改参数--&gt;slow_query_log=1slow_query_log_file=host_name-slow.log&lt;!--SQL语句健康查询--&gt;show global status like 'Slow_queries'; long_query_time12345678&lt;!--是大于 &gt; 10秒 而非 大于等于 &gt;= 10--&gt;SHOW VARIABLES LIKE '%long_query_time%';&lt;!--设置时间--&gt;set global long_query_time=3;&lt;!--设置后可能时间看不到变化 需要用 global 或者重新连接或新开一个会话才能看到修改值--&gt;show global VARIABLES like 'long_query_time'; Slow_queries12&lt;!--SQL语句健康查询--&gt;show global status like 'Slow_queries'; mysqldumpslow –help 慢查询工具 s：是表示按照何种方式排序。 c：访问次数。 l：锁定时间。 r：返回记录。 t：查询时间。 al：平均锁定时间。 ar：平均返回记录数。 at：平均查询时间。 t：即为返回前面多少条的数据。 g：后边搭配一个正则匹配模式，大小写不敏感的。 全局查询日志 注：生产环境不开启这个功能 12345678&lt;!--开启功能，默认关闭--&gt;set global general_log=1;&lt;!--输出到表--&gt;set global log_output='TABLE';&lt;!--查看--&gt;select * from mysql.general_log;]]></content>
      <categories>
        <category>MySql</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[NIO]]></title>
    <url>%2F2019%2F05%2F08%2FNIO%2F</url>
    <content type="text"><![CDATA[Java NIO（New IO）是从Java 1.4版本开始引入的一个新的IO API，可以替代标准的Java IO API。 NIO与原来的IO有同样的作用和目的，但是使用的方式完全不同。NIO支持面向缓冲区的、基于通道的IO操作。NIO将以更加高效的方式进行文件的读写操作。**]]></content>
  </entry>
  <entry>
    <title><![CDATA[Redis]]></title>
    <url>%2F2019%2F05%2F07%2FRedis%2F</url>
    <content type="text"><![CDATA[非关系性数据库NoSQL:Redis CAP+BASE传统的ACID Atomicity（原子性）：一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。 Consistency（一致性）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器、级联回滚等。 Isolation（隔离性）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 Durability（持久性）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 CAP C: Consistency(强一致性) A: Availability（可用性） P: Partition tolerance（分区容错性） 因此，根据CAP原理将NoSQL数据库分成满足CA、CP、AP原则三大类 CA - 传统数据库。单点集群，满足一致性，可用性的系统，在可扩展性上不太强。 CP - Redis、Mongodb。 满足一致性，分区容忍性的系统，性能不是特别高。 AP - 满足可用性，分区容忍性的系统，通常可能对一致性要求低一些。(大多数网站架构的选择) CAP的3进2 CAP理论就是在分布式存储系统中，最多只能实现上面的两点。由于网络硬件肯定会出现延迟丢包等问题，分区容错性是我们必须需要实现的。 只能在一致性 C 和 可用性 A 之间进行权衡，没有NoSQL系统能同时保证这三点。 BASEBASE就是为了解决关系数据库强一致性引起的问题而引起的可用性降低而提出的解决方案 基本可用 Basically Available 软状态 Soft State 最终一致 Eventually Consistent 它的思想是通过让系统放松对某一时刻数据一致性的要求来换取系统整体伸缩性和性能上改观。为什么这么说呢，缘由就在于大型系统往往由于地域分布和极高性能的要求，不可能采用分布式事务来完成这些指标，要想获得这些指标，我们必须采用另外一种方式来完成，这里BASE就是解决这个问题的办法 Redis的特点 Redis支持数据的持久化，可以将内存中的数据(支持异步)保持在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的 key-value 类型的数据，同时还提供 string，list，set，zset，hash 等数据结构的存储。 Redis支持数据的备份，即 master-slave 模式的数据备份。 Redis基础知识 Redis 是单进程 默认16个数据库，类似数组下表从 0 开始，初始默认使用 0 号库。 select ：命令切换数据库。SELECT 7 ——&gt; 选择 6号库。 dbsize ：查看当前数据库的key的数量。 keys *：查看所有的 key。(支持占位符 key k?) flushdb：清空当前库。 flushall：通杀全部库。 统一密码管理，16个库都是同样密码，要么都OK要么一个也连接不上。 Redis 索引都是从 0 开始。 默认端口是6379 (9宫格键盘 merz)。 Redis数据类型Redis 键(key) keys * 查看所有的 key。 exists key： 判断某个key是否存在。 move key db： 把当前 key 移动到指定 DB (当前库就没有了)。 expire key 秒钟： 为给定的key设置过期时间。 ttl key 查看还有多少秒过期，-1表示永不过期，-2表示已过期。(过期移除内存系统) type key： 查看你的key是什么类型。 String（字符串） string 是 redis 最基本的类型，可以理解成与Memcached一样的类型，key：value。 string 类型是二进制安全的。意思是redis的string可以包含任何数据。比如序列化的对象… string 一个redis中字符串 value 最多可以是512M。 单值 单value 常用命令： set/get/del/append/strlen 设置、获取、删除、追加、获取长度。 incr/decr/incrby/decrby： 一定要是数字才能进行加减。 getrange： 获取指定区间范围内的值，截取字符串。从0到-1表示全部。 setrange： 设置指定区间范围内的值，插入字符串。格式是setrange key值 具体值。对指定位置 覆盖操作。 setex(set with expire)键秒值： 对该key设置存活时间。setex k1 10 v1 setnx(set if not exist)： 如果key值存在返回0，如果不存在进行set设置值。setnx k1 v1 mset： 合并set。mset k1 v1 k2 v2 k3 v3 mget： 合并get。gset k1 k2 k3 msetnx： mset k1 v1 k2 v2 如果 k1 已经存在了。全部set失败！ getset(先get再set)： 获取输出当前value值，然后set。 hash（哈希，类似Java里的Map） Redis hash 是一个键值对集合。 Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象 类似Java里面的 Map&lt; String,Object&gt; K/V模式不变，但V是一个键值对。 常用命令： hset/hget： hset KEY_NAME name zs hget KEY_NAME name hmset/hmget： hmset KEY_NAME id 11 name zs hmget KEY_NAME id name hgetall/hdel： hgetall KEY_NAME hdel KEY_NAME name hexists： 用于查看哈希表的指定字段是否存在。hexists KEY_NAME id hkeys/hvals： 用于获取哈希表中的所有域（key）,返回哈希表所有域(value)的值。hkeys KEY_NAME hvals KEY_NAME hincrby/hincrbyfloat： 用于为哈希表中的字段值加上指定增量值。hincrby user id hlen： 获取哈希表中字段的数量。hlen KEY_NAME hsetnx： 用于为哈希表中不存在的的字段赋值。hsetnx KEY_NAME key value v1 list（列表） Redis 列表是简单的字符串列表，按照插入顺序排序。 你可以添加一个元素列表的头部（左边）或者尾部（右边）。 底层实际是个链表 单值多value 常用命令： lpush/rpushlpop/rpop/lrange lindex： 按照索引下标获得元素(从上到下)。LINDEX KEY_NAME 1 llen： 获取长度。 LLEN KEY_NAME lrem： 删2个1。LREM KEY_NAME 2 1 ltrim： 开始index 结束index，截取指定范围的值后再赋值给key。LTRIM KEY_NAME 3 5 set（集合） Redis 的Set是string类型的无序集合，且不允许重复的成员。它是通过HashTable实现实现的。 单值多value 常用命令： sadd： 将一个或多个成员元素加入到集合中，已经存在于集合的成员元素将被忽略。sadd KEY_NAME v1 del： 删除集合。del KEY_NAME smembers： 命令返回集合中的所有的成员。不存在的集合 set 被视为空集合。smembers KEY_NAME srandmember： srandmember KEY_NAME value 从集合中随机出几个数。 sismember： 判断成员元素是否是集合的成员。sismember KEY_NAME 1 scard： 返回集合中元素的数量。scard KEY_NAME srem： 删除集合中元素。srem KEY_NAME value spop： 随机集合中一个value出栈。spop KEY_NAME smove： 将指定成员 member 元素从 source 集合移动到目标集合。smove set01 set02 value 数学集合类 差集：sdiff 返回在KEY_NAME01里面，不在set02里面的 value。 sdiff KEY_NAME01 KEY_NAME02 交集：sinter 返回在KEY_NAME01里面，也在set02里面的 value。 sinter KEY_NAME01 KEY_NAME02 并集：sunion 返回去重后的集合。 zset(sorted set：有序集合) Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。 不同的是每个元素都会关联一个整数或者双精度浮点数的分数。(比如游戏分数) redis正是通过分数来为集合中的成员进行从小到大的排序。zset的成员是唯一的,但分数(score)却可以重复。 在set基础上，加一个score值。之前set是k1 v1 v2 v3，现在 zset是k1 score1 v1 score2 v2 常用命令： zadd： 用于将一个或多个成员元素及其分数值加入到有序集中。zadd KEY_NAME 60 v1 70 v2 zrange： ZRANGE KEY_NAME 0 -1 | ZRANGE KEY_NAME 0 -1 withscores zrangebyscore：返回有序集合中指定分数区间的成员列表。 1zrangebyscore KEY_NAME 开始score 结束score withscores zrangebyscore zset 10 (50 不包含50。 zrangebyscore zset 10 (50 limit 2 2 limit 返回限制,limit 开始下标走多少步。 zrem： 用于移除有序集中的一个或多个成员，不存在的成员将被忽略。zrem KEY_NAME value zcard： 用于计算集合中元素的数量。ZCARD KEY_NAME zcount： 用于计算有序集合中指定分数区间的成员数量。ZCOUNT KEY_NAME min max zrank： 作用是获得下标值。zrank KEY_NAME value zscore： 对应值,获得分数。 zscore KEY_NAME value zrevrank： 作用是逆序获得下标值。 zrevrank KEY_NAME value zrevrange： 返回有序集中，指定区间内的成员。其中成员的位置按分数值递减(从大到小)来排列。ZREVRANGE key 0 -1 [WITHSCORES] zrevrangebyscore： 返回有序集中指定分数区间内的所有的成员。有序集成员按分数值递减(从大到小)的次序排列。 redis.conf配置文件GENERAL 通用 daemonize yes：是否将Redis作为守护进程运行 pidfile：当Redis以守护进程方式运行时，Redis默认会把pid写入 /var/run/redis.pid文件。 port：6379 端口号。 tcp-backlog：设置tcp的backlog，backlog其实是一个连接队列，backlog队列总和=未完成三次握手队列 + 已经完成三次握手队列。 timeout：超时断开连接。(0 to disable) bind：端口的绑定。 tcp-keepalive：单位为秒，设置为60s (0即为不检测) loglevel：日志级别,debug、verbose、notice、warning。 logfile：指定日志文件名，为空则标准输出。 syslog-enabled：是否把系统日志输出到syslog中，默认关闭 syslog-ident：日志鉴别，日志以 redis 开头。 syslog-facility：指定syslog设备，值可以是USER或 LOCAL0-LOCAL7。默认为 LOCAL 0 databases 16：默认为 16 个库。 SNAPSHOTTING快照 Save：save &lt;seconds&gt; &lt;changes&gt; Redis 默认配置文件中提供了三个条件 触发 RDB 保存： save 900 1 ：——&gt; 900s（15min）至少有 1 次 key 的改动。 save 300 10 ：——&gt; 300s（5min）至少有 10 次 key 的改动。 save 60 10000 ：——&gt; 60s（1min）至少有 10000 次 key 的改动。 直接输入 save 或者是 bgsave 命令，即刻备份！ Save：save时只管保存，其它不管，全部阻塞。 BGSAVE：会在后台异步进行快照操作，快照同时还可以响应客户端请求。 可以通过 lastsave 命令获取最后一次成功执行快照的时间。 禁用 RDB： save “” (不设置任何save指令，或者给save传入一个空字符串参数)。 stop-writes-on-bgsave-error：yes 如果配置成no，表示你不在乎数据不一致或者有其他的手段发现和控制。 rdbcompression： 对于存储到磁盘中的快照，可以设置是否进行压缩存储。 如果是的话，redis会采用LZF算法进行压缩。如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能。 rdbchecksum 在存储快照后，还可以让redis使用CRC64算法来进行数据校验。 但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。 dbfilename dump.rdb 指定本地数据库文件名，默认值为dump.rdb。 dir：config get dir (获取目录) SECURITY 安全 访问密码的查看、设置和取消 127.0.0.1：6379 &gt; config get requirepass (获取密码) 127.0.0.1：6379 &gt; config set requirepass “123456” (设置密码) ping 不通了。 127.0.0.1：6379 &gt; auth 123456 （输入密码） LIMITS 限制 maxclients 10000： redis同时可以与多少个客户端进行连接，默认情况为10000个客户端。 maxmemory： 设置redis可以使用的内存量。一旦到达内存使用上限，redis将会试图移除内部数据，移除规则可以通过maxmemory-policy来指定。 maxmemory-policy： volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰。 volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰。 volatile-random：从已设置过期时间的数据集中任意选择数据淘汰。 allkeys-lru：从数据集中挑选最近最少使用的数据淘汰。 allkeys-random：从数据集中随机选择数据淘汰。 no-enviction（驱逐）：永不过期，不进行移除。针对写操作，只是返回错误信息。禁止驱逐数 volatile-lfu： 使用具有过期集的键之间的近似LFU(数据过去被访问多次，那么将来被访问的频率也更高)将访问频率最少的键值对淘汰。 allkeys-lfu：从数据集中近似LFU(将访问频率最少的键值对淘汰。)选择数据淘汰。 maxmemory-samples： 设置样本数量，LRU算法和最小TTL算法都并非是精确的算法，而是估算值，所以你可以设置样本的大小。 redis默认会检查这么多个key并选择其中LRU的那个。 持久化RDB（Redis DataBase）在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是Snapshot快照，它恢复时是将快照文件直接读到内存里。 Redis 会单独创建（fork）一个子进程进行持久化，会先将数据写入到一个临时文件中，待持久化过程结束了再用这个临时文件替换上次持久化好的文件 fork 的作用是复制一个与当前进程一样的进程。 新进程的所有数据（变量、环境变量、程序计数器等）数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程 RDB 保存的是 (默认) dump.rdb 文件，可以在 redis.conf中配置 优势 整个过程中，主进程是不进行任何IO操作的，确保了极高的性能 适合进行大规模数据的恢复。 如果对于数据恢复的 完整性 不是非常敏感，那RDB方式要比AOF方式更加的高效。 劣势 整个过程中，主进程是不进行任何IO操作的，确保了极高的性能 适合进行大规模数据的恢复。 如果对于数据恢复的 完整性 不是非常敏感，那RDB方式要比AOF方式更加的高效。 修复 如果 RDB 文件有错误 在安装目录下，用 redis-check-rdb 对 RDB 文件进行修复，把错误的命令全部删除。 redis-check-rdb –fix dump.rdb 停止 动态停止所有RDB保存规则的方法：redis-cli config set save “” AOF快照并不是很可靠。如果你的电脑突然宕机了，或者电源断了，又或者不小心杀掉了进程，那么最新的数据就会丢失。而AOF文件则提供了一种更为可靠的持久化方式。每当Redis接受到会修改数据集的命令时，就会把命令追加到AOF文件里，当你重启Redis时，AOF里的命令会被重新执行一次，重建数据。 启用AOF把配置项appendonly（默认为false）设为yes： 1appendonly yes 文件路径和名称12345# 文件存放目录，与RDB共用。默认为当前工作目录。dir ./# 默认文件名为appendonly.aofappendfilename "appendonly.aof" 可靠性你可以配置Redis调用fsync的频率，有三个选项： 每当有新命令追加到AOF的时候调用fsync。速度最慢，但是最安全。 每秒fsync一次。速度快（2.4版本跟快照方式速度差不多），安全性不错（最多丢失1秒的数据）。 从不fsync，交由系统去处理。这个方式速度最快，但是安全性一般。 推荐使用每秒fsync一次的方式（默认的方式），因为它速度快，安全性也不错。相关配置如下： 123# appendfsync alwaysappendfsync everysec# appendfsync no 日志重写随着写操作的不断增加，AOF文件会越来越大。例如你递增一个计数器100次，那么最终结果就是数据集里的计数器的值为最终的递增结果，但是AOF文件里却会把这100次操作完整的记录下来。而事实上要恢复这个记录，只需要1个命令就行了，也就是说AOF文件里那100条命令其实可以精简为1条。所以Redis支持这样一个功能：在不中断服务的情况下在后台重建AOF文件。 工作原理如下： Redis调用fork()，产生一个子进程。 子进程把新的AOF写到一个临时文件里。 主进程持续把新的变动写到内存里的buffer，同时也会把这些新的变动写到旧的AOF里，这样即使重写失败也能保证数据的安全。 当子进程完成文件的重写后，主进程会获得一个信号，然后把内存里的buffer追加到子进程生成的那个新AOF里。 我们可以通过配置设置日志重写的条件： 123456# Redis会记住自从上一次重写后AOF文件的大小（如果自Redis启动后还没重写过，则记住启动时使用的AOF文件的大小）。# 如果当前的文件大小比起记住的那个大小超过指定的百分比，则会触发重写。# 同时需要设置一个文件大小最小值，只有大于这个值文件才会重写，以防文件很小，但是已经达到百分比的情况。auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb 要禁用自动的日志重写功能，我们可以把百分比设置为0： 1auto-aof-rewrite-percentage 0 Redis 2.4以上才可以自动进行日志重写，之前的版本需要手动运行BGREWRITEAOF这个命令。 数据损坏修复如果因为某些原因（例如服务器崩溃）AOF文件损坏了，导致Redis加载不了，可以通过以下方式进行修复： 备份AOF文件。 使用redis-check-aof命令修复原始的AOF文件： 1$ redis-check-aof --fix 可以使用diff -u命令看下两个文件的差异。 使用修复过的文件重启Redis服务。 优点 比RDB可靠。你可以制定不同的fsync策略：不进行fsync、每秒fsync一次和每次查询进行fsync。默认是每秒fsync一次。这意味着你最多丢失一秒钟的数据。 AOF日志文件是一个纯追加的文件。就算是遇到突然停电的情况，也不会出现日志的定位或者损坏问题。甚至如果因为某些原因（例如磁盘满了）命令只写了一半到日志文件里，我们也可以用redis-check-aof这个工具很简单的进行修复。 当AOF文件太大时，Redis会自动在后台进行重写。重写很安全，因为重写是在一个新的文件上进行，同时Redis会继续往旧的文件追加数据。新文件上会写入能重建当前数据集的最小操作命令的集合。当新文件重写完，Redis会把新旧文件进行切换，然后开始把数据写到新文件上。 AOF把操作命令以简单易懂的格式一条接一条的保存在文件里，很容易导出来用于恢复数据。例如我们不小心用FLUSHALL命令把所有数据刷掉了，只要文件没有被重写，我们可以把服务停掉，把最后那条命令删掉，然后重启服务，这样就能把被刷掉的数据恢复回来。 缺点 在相同的数据集下，AOF文件的大小一般会比RDB文件大。 在某些fsync策略下，AOF的速度会比RDB慢。通常fsync设置为每秒一次就能获得比较高的性能，而在禁止fsync的情况下速度可以达到RDB的水平。 在过去曾经发现一些很罕见的BUG导致使用AOF重建的数据跟原数据不一致的问题。 小结RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储 AOF持久化方式记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始的数据，AOF命令以redis协议追加保存每次写的操作到文件末尾 同时开启两种持久化方式 在这种情况下,当redis重启的时候会优先载入AOF文件来恢复原始的数据。 AOF 文件保存的数据集要比 RDB 文件保存的数据集要 完整 RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件。 那要不要只使用AOF呢？ 因为RDB更适合用于备份数据库(AOF在不断变化不好备份)，快速重启，而且不会有AOF可能潜在的bug，留着作为一个万一的手段。 性能建议因为 RDB 文件只用作后备用途，建议只在Slave上持久化RDB文件，只要15分钟备份一次就够了，只保留 save 900 1 这条规则。 如果开启 Enalbe AOF 好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自己的AOF文件就可以了，代价一是带来了持续的IO。二是AOF rewrite 的最后将 rewrite 过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少AOF rewrite的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上。默认超过原大小100%大小时重写可以改到适当的数值。 如果不开启 Enable AOF 仅靠Master-Slave Replication 实现高可用性也可以。能省掉一大笔IO也减少了rewrite时带来的系统波动。代价是如果 Master/Slave 同时down掉，会丢失十几分钟的数据，启动脚本也要比较两个Master/Slave中的RDB文件，载入较新的那个。 Redis事务 一个队列中可以一次性，顺序性执行多个命令，本质是一组命令的集合。 一个事务中的所有命令都会序列化，按顺序地串行化执行而不会被其它命令插入，不许加塞。 没有隔离级别的概念。不保证原子性，没有回滚。 命令 MULTI： 标记一个事务块的开始。OK EXEC： 执行所有事务块内的命令。 DISCARD： 取消事务，放弃执行事务块内的所有命令。 UNWATCH： 取消 WATCH 命令对所有 key 的监视。一旦执行了exec，之前加的监控锁都会被取消掉了。 WATCH： 监视一个或多个 key；如果在事务执行之前这个 key 被其他命令所改动，事务将被打断。 Case1 正常执行： MULTI 一系列操作 EXECCase2 放弃事务： MULTI 一系列操作 DISCARDCase3 全体连坐： MULTI 一系列操作中有错误操作（直接报错的命令） EXEC（全部失败）Case4 冤头债主： MULTI 一系列操作中有错误操作（不直接报错的命令，比如 incr 字符串） EXEC （错误命令不执行）Case4 watch监控： 先监控 在开启事务。watch key 、MULTI 一系列操作 EXEC 如果其他线程没有干扰则成功，反之失败。 悲观锁/乐观锁/CAS(Check And Set) 悲观锁： 行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。 乐观锁： 读写不会上锁。但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。 Watch指令，类似乐观锁，事务提交时，如果Key的值已被别的客户端改变，整个事务队列都不会被执行。 通过WATCH命令在事务执行之前监控了多个Keys，倘若在WATCH之后有任何Key的值发生了变化，EXEC命令执行的事务都将被放弃，同时返回Nullmulti-bulk应答以通知调用者事务执行失败。 Redis 的复制(Master/Slave) 主从复制 读写分离 容灾恢复。配从不配主 主机数据更新后根据配置和策略，自动同步到备机的 master/slaver 机制，Master以写为主，Slave以读为主。 info replication 查看 role 角色。 一主二仆info replication： 返回主从复制的信息。主机才可以写，从机只能读。 从库配置：slaveof 主库IP 主库端口 slaveof 127.0.0.1 6379 如果 master shutdown 后，从库 role 还是 slave。 master 恢复上线，关系也恢复。 每次 slave shutdown 与 master 断开之后，都需要重新连接，除非你配置进redis.conf文件。 从库每次 slave shutdown 后 role 变为 master。 info replication 查看 role 角色。 薪火相传上一个 Slave 可以是下一个 Slave 的 Master，Slave 同样可以接收其他 slaves 的连接和同步请求。减轻主 Master 压力。 中途变更转向：会清除之前的数据，重新建立拷贝最新的。 slaveof 新主库IP 新主库端口 slaveof 127.0.0.1 6379 反客为主上一个 Slave 可以是下一个 Slave 的 Master，Slave 同样可以接收其他 slaves 的连接和同步请求。减轻主 Master 压力。 中途变更转向：会清除之前的数据，重新建立拷贝最新的。 slaveof 新主库IP 新主库端口 slaveof 127.0.0.1 6379 哨兵模式(反客为主自动版本) 能够后台自动监控主机是否故障，如果故障了根据投票数自动将从库转换为主库。 原有体系 主仆关系1、新建一个文件名为 sentinel.conf 空 配置文件。2、配置 sentinel.conf文件。写入 sentinel monitor 被监控数据库名字 127.0.0.1 6379 1 上面最后一个数字1，表示主机挂掉后 salve 投票看让谁接替成为主机，得票数多成为主机。3、启用 redis-sentinel /myredis/sentinel.conf 监控。4、如果 主Master shutdown 以后，salve 投票多的选为 新Master，而剩余 salve 转向 新Master。5、即便 主Master恢复，原来的体系已经建立，由于监控则变成新Master 的 salve6、一组sentinel能同时监控多个Master。 缺点 由于所有的写操作都是先在Master上操作，然后同步更新到Slave上， 所以从Master同步到Slave机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题更加严重。]]></content>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM调优参数]]></title>
    <url>%2F2019%2F05%2F06%2FJVM%E8%B0%83%E4%BC%98%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[本文介绍JVM调优常见参数 XX参数1-XX:SurvivorRatio=n:年轻代中Eden区与两个Survivor区的比值。默认-XX:SurvivorRatio=8, 即Eden:S0:S1 = 8:1:1 我们设置JVM参数为：-XX:+PrintGCDetails -XX:+UseSerialGC -Xms10m -Xmx10m 12345 ... eden space 2752K, from space 320K, to space 320K, ... 从输出信息可以看出，eden space 2752K from space 320K to space 320K ，320*8≈2752，8:1:1并不是非常准确的比例 我们再把JVM参数设为：-XX:+PrintGCDetails -XX:+UseSerialGC -Xms10m -Xmx10m -XX:SurvivorRatio=4 12345... eden space 2368K, from space 512K, to space 512K, ... 可以看出大致是4:1:1的关系 1-XX:NewRatio 配置年轻代与老年代在堆结构的占比，默认为2，新生代占1老年代占2 设置JVM参数为：-XX:+PrintGCDetails -XX:+UseSerialGC -Xms10m -Xmx10m -XX:NewRatio=2 12new generation total 3072Ktenured generation total 6848K, 可以看出年轻代和老年代的比例大致为1:2 再把参数改为-XX:+PrintGCDetails -XX:+UseSerialGC -Xms10m -Xmx10m -XX:NewRatio=4 12new generation total 1856Ktenured generation total 8192K 1-XX:MaxTenuringThreshold 设置垃圾最大年龄,默认15 设置JVM参数为：-XX:MaxTenuringThreshold =20,会输出一下信息 123Error: Could not create the Java Virtual Machine.Error: A fatal exception has occurred. Program will exit.MaxTenuringThreshold of 20 is invalid; must be between 0 and 15]]></content>
      <categories>
        <category>JVM</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[synchronized和Lock区别]]></title>
    <url>%2F2019%2F05%2F05%2Fsynchronized%E5%92%8CLock%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[并发编程中，锁是经常需要用到的，我们了解一下synchronized和lock的区别 synchronized和Lock区别 原始构成 synchronized是关键字属于JVM层面，monitorenter(底层是通过monitor对象来完成，其wait/notify等方法也依赖monitor对象只有在同步块或方法中能调wait/notifymonitorexit Lock是具体类( java.util.concurrent.locks.Lock)是api层面的锁 使用方法 synchronized不需要用户去手动释放锁，当synchronized代码执行完后系统会自动让线程释放对锁的占用ReentrantLock则需要用户去手动释放锁若没有主动释放锁，就有可能导致出现死锁现象。需要Lock() lunlock()方法配合try/finally语句块来完成。 等待是否可中断 synchronized不可中断，除非抛出异常或者iE:常运行完成 ReentrantLock可中断 ​ 1.设置超时方法tryLock(long timeout, TimeUnit unit) ​ 2.lockInterruptibly()放代码块中，调用interrupt() 方法可中断 加锁是否公平 synchronized非公平锁 Reentrantlock两者都可以，默认非公平锁，构造方法可以传入boolean值, true 为公平锁，false为非公平锁 锁绑定多个条件condition synchronized没有 ReentrantLock用来实现分组唤醒需要唤醒的线程们，可以精确唤醒，而不是像synchronized要么随机唤醒一个线程要么唤醒全部线程。 1234567public static void main(String[] args) &#123; synchronized (new Object())&#123; &#125; new ReentrantLock();&#125; 对synchronized和ReentrantLock进行反汇编 123456789101112131415161718192021public static void main(java.lang.String[]); Code: 0: new #2 // class java/lang/Object 3: dup 4: invokespecial #1 // Method java/lang/Object."&lt;init&gt;":()V 7: dup 8: astore_1 9: monitorenter 10: aload_1 11: monitorexit 12: goto 20 15: astore_2 16: aload_1 17: monitorexit 18: aload_2 19: athrow 20: new #3 // class java/util/concurrent/locks/ReentrantLock 23: dup 24: invokespecial #4 // Method java/util/concurrent/locks/ReentrantLock."&lt;init&gt;":()V 27: pop 28: return 可以看到synchronized映射成字节码指令就是两个指令monitorenter和monitorexit。当一条线程进行执行的遇到monitorenter指令的时候，它会去尝试获得锁，如果获得锁那么锁计数+1（为什么会加一呢，因为它是一个可重入锁，所以需要用这个锁计数判断锁的情况），如果没有获得锁，那么阻塞。当它遇到monitorexit的时候，锁计数器-1，当计数器为0，那么就释放锁。 但是，我们发现有2个monitorexit。synchronized锁释放有两种机制，一种就是执行完释放；另外一种就是发送异常，虚拟机释放。第二个monitorexit就是发生异常时执行的流程，在第13行，有一个goto指令，也就是说如果正常运行结束会跳转到20行执行。 Lock的小练习123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100/** * 多线程之间按顺序调用，实现A-&gt;B-&gt;C三个线程启动，要求如下： * AA打印5次，BB打印10次，CC打印15次 * 紧接着 * AA打印5次，BB打印10此，CC打印15此 * .... * 进行10轮 */public class SyncAndReentrantLockDemo &#123; public static void main(String[] args) &#123; ShareResource shareResource = new ShareResource(); new Thread(()-&gt;&#123; for (int i = 0; i &lt; 10; i++) &#123; try &#123; shareResource.print5(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;, "A").start(); new Thread(()-&gt;&#123; for (int i = 0; i &lt; 10; i++) &#123; try &#123; shareResource.print10(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;, "B").start(); new Thread(()-&gt;&#123; for (int i = 0; i &lt; 10; i++) &#123; try &#123; shareResource.print15(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;, "C").start(); &#125;&#125;class ShareResource&#123; private int number = 1; private Lock lock = new ReentrantLock(); Condition c1 = lock.newCondition(); Condition c2 = lock.newCondition(); Condition c3 = lock.newCondition(); public void print5() throws InterruptedException &#123; lock.lock(); try &#123; while(number != 1)&#123; c1.await(); &#125; for (int i = 1; i &lt;= 5 ; i++) &#123; System.out.println(Thread.currentThread().getName() + "\t" + i); &#125; number = 2; c2.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void print10() throws InterruptedException &#123; lock.lock(); try &#123; while(number != 2)&#123; c2.await(); &#125; for (int i = 1; i &lt;= 10 ; i++) &#123; System.out.println(Thread.currentThread().getName() + "\t" + i); &#125; number = 3; c3.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void print15() throws InterruptedException &#123; lock.lock(); try &#123; while(number != 3)&#123; c3.await(); &#125; for (int i = 1; i &lt;= 15 ; i++) &#123; System.out.println(Thread.currentThread().getName() + "\t" + i); &#125; number = 1; c1.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125;&#125;]]></content>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池]]></title>
    <url>%2F2019%2F04%2F29%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[线程池做的工作主要是控制运行的线程的数量，处理过程中将任务放入队列，然后在线程创建后启动这些任务，如果线程数量超出数量的线程排队等候，等其他线程执行完毕，再从队列中取出来执行。 主要特点：线程复用、控制最大并发数、管理线程。 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。 第三:提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统的分配， 调优和监控 创建线程池1234Executors.newFixedThreadPool(int);Executors.newSingleThreadExecutor();Executors.newCachedThreadPool();Executors.newScheduledThreadPool(int); newCachedThreadPool 是一个可根据需要创建新线程的线程池，但是在以前构造的线程可用时将重用它们。对于执行很多短期异步任务的程序而言，这些线程池通常可提高程序性能。调用 execute() 将重用以前构造的线程（如果线程可用）。如果现有线程没有可用的，则创建一个新线程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程。因此，长时间保持空闲的线程池不会使用任何资源。注意，可以使用 ThreadPoolExecutor 构造方法创建具有类似属性但细节不同（例如超时参数）的线程池。 newSingleThreadExecutor 创建是一个单线程池，也就是该线程池只有一个线程在工作，所有的任务是串行执行的，如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它，此线程池保证所有任务的执行顺序按照任务的提交顺序执行。 newFixedThreadPool 创建固定大小的线程池，每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小，线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。 newScheduledThreadPool 创建一个大小无限的线程池，此线程池支持定时以及周期性执行任务的需求。 使用哪个上述创建线程池的方法都不推荐使用 线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样 的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 说明：Executors 返回的线程池对象的弊端如下： FixedThreadPool 和 SingleThreadPool: 允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。 CachedThreadPool 和 ScheduledThreadPool: 允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。 ​ —来自《阿里巴巴Java手册》 线程池流程 在创建了线程池后，等待提交过来的任务请求。 当调用execute()方法添加一一个请求任务时，线程池会做如下判断: 如果正在运行的线程数量小于corePoolSize,那么马上创建线程运行这个任务; 如果正在运行的线程数量大于或等于corePoolSize,那么将这个任务放入队列; 如果这时候队列满了且正在运行的线程数量还小于maximumPoolSize,那么还是要创建非核心线程立刻运行这个任务; 如果队列满了且正在运行的线程数量大于或等于maximumPoolSize,那么线程池会启动饱和拒绝策略来执行。 当一个线程完成任务时，它会从队列中取下一个任务来执行。 当一个线程无事可做超过一定的时间(keepAliveTime) 时，线程池会判断:如果当前运行的线程数大于corePoolSize,那么这个线程就被停掉。所以线程池的所有任务完成后它最终会收缩到corePoolSize的大小 线程池参数12int corePoolSize;线程池中的常驻核心线程数，allowCoreThreadTimeOut(boolean value) 设置为 true 时，闲置的核心线程会存在超时机制，如果在指定时间没有新任务来时，核心线程也会被终止，而这个时间间隔由第3个属性 keepAliveTime 指定。 12int maximumPoolSize,线程池中的常驻核心线程数 12long keepAliveTime;多余的空闲线程的存货时间。当前线程池数量超过corePoolSize时，当空闲时间达到keepAliveTime值时，多余空闲线程会被销毁直到只剩下corePoolSize个线程为止 12TimeUnit unit；keepAliveTime的单位 12BlockingQueue&lt;Runnable&gt; workQueue;任务队列，被提交但尚未被执行的任务 12ThreadFactory threadFactory;表示生产线程池中工作线程的线程工厂，用于创建线程一般用默认的即可 12RejectedExecutionHandler handler;拒绝策略，表实当前队列满了并且工作线程大于等于线程池的最大线程数 线程池拒绝策略RejectedExecutionHandler提供了四种方式来处理任务拒绝策略 直接丢弃（DiscardPolicy） 丢弃队列中最老的任务(DiscardOldestPolicy)。 抛异常(AbortPolicy) 将任务分给调用线程来执行(CallerRunsPolicy)。 如何配置线程上述提到了几个核心参数应该如何配置呢？ 有一点是肯定的，线程池肯定是不是越大越好。 通常我们是需要根据这批任务执行的性质来确定的。 CPU 密集型任务（大量复杂的运算）应当分配较少的线程，比如 CPU 个数相当的大小。 IO 密集型任务： 由于线程并不是一直在运行，所以可以尽可能的多配置线程，比如 CPU 个数 * 2 该任务需要大量的IO，即大量的阻塞，故需要多配置线程数，如 CPU核数 / (1 - 阻塞系数) 阻塞系数在0.8~0.9之间 线程池的关闭ThreadPoolExecutor 提供了两个方法，用于线程池的关闭，分别是 shutdown() 和 shutdownNow()。 12shutdown()：不会立即的终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务。shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务。 线程池Demo1234567891011121314151617181920212223242526272829303132import java.util.Arrays;import java.util.List;import java.util.concurrent.*;public class MyThreadPoolDemo &#123; public static void main(String[] args) throws InterruptedException &#123; ExecutorService threadPool = new ThreadPoolExecutor( 2, 5, 1L, TimeUnit.SECONDS, new LinkedBlockingDeque&lt;&gt;(3), Executors.defaultThreadFactory(), new ThreadPoolExecutor.CallerRunsPolicy()); List&lt;String&gt; list = Arrays.asList("a", "b", "c");// ExecutorService threadPool = Executors.newFixedThreadPool(5); //线程池中5个线程// ExecutorService threadPool = Executors.newSingleThreadExecutor(); // 一池一个处理线程 // ExecutorService threadPool = Executors.newCachedThreadPool();// 一池N个处理线程 // 模拟10个用户办理业务，每个用户就是一个来自外部的请求线程 try &#123; for (int i = 0; i &lt; 10; i++) &#123; threadPool.execute(() -&gt; System.out.println(Thread.currentThread().getName() + "\t 办理业务")); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; threadPool.shutdown(); &#125; &#125;&#125;]]></content>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阻塞队列]]></title>
    <url>%2F2019%2F04%2F28%2F%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[当我们要创建ThreadPoolExecutor的时候需要传进来一个类型为BlockingQueue的参数，它就是阻塞队列，在这一篇文章里我们会介绍阻塞队列的定义、种类、实现原理以及应用。 阻塞队列，是一个队列，而在一个阻塞队列在数据结构中所起的作用大致如下图所示 当阻塞队列是空时，从队列中获取元素的操作将会被阻塞 当阻塞队列时满时，往队列里添加元素的操作将会被阻塞 阻塞队列有什么好处在多线程领域：所谓阻塞，在某些情况下，会挂起线程（即阻塞），一旦条件满足，被挂起的线程又会自动被唤醒 ArrayBlockingQueue:由数狙结构組成的有界阻塞队列。 LinkedBlockingQueue:由链表构狙成的有界(但大小默人値カInteger.MAX_ _VALUE)阻塞队列 SynchronousQueue:不存储元素的阻塞队列，也即単个元素的队列 PriorityBlockingQueue:支持优先级排序的无界阻塞叺列 DelayQueue:使用优先级队列实现的延迟无界阻塞臥列 linkedTransferQueue:由链表结构組成的无界阻塞队列 LinkedBlockingDeque:由链表结构組成的双向阻塞队列 阻塞队列提供了四种处理方法: 方法类型 抛出异常 特殊值 阻塞 超时 插入 add(e) offer(e) put(e) offer(e,time,unit) 移除 remove() poll() take() poll(time,unit) 检查 element() peek() 不可用 不可用 抛出异常：是指当阻塞队列满时候，再往队列里插入元素，会抛出 IllegalStateException(“Queue full”) 异常。当队列为空时，从队列里获取元素时会抛出 NoSuchElementException 异常 。 返回特殊值：插入方法会返回是否成功，成功则返回 true。移除方法，则是从队列里拿出一个元素，如果没有则返回 null 一直阻塞：当阻塞队列满时，如果生产者线程往队列里 put 元素，队列会一直阻塞生产者线程，直到拿到数据，或者响应中断退出。当队列空时，消费者线程试图从队列里 take 元素，队列也会阻塞消费者线程，直到队列可用。 超时退出：当阻塞队列满时，队列会阻塞生产者线程一段时间，如果超过一定的时间，生产者线程就会退出。 线程通信之生产者消费者阻塞队列123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.BlockingQueue;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicInteger;public class ProdConsumer_BlockQueue &#123; public static void main(String[] args) throws InterruptedException &#123; MyResource myResource = new MyResource(new ArrayBlockingQueue&lt;&gt;(10)); new Thread(()-&gt;&#123; System.out.println(Thread.currentThread().getName() + "\t生产线程启动"); try &#123; myResource.myProd(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;, "Prod").start(); new Thread(()-&gt;&#123; System.out.println(Thread.currentThread().getName() + "\t消费线程启动"); try &#123; myResource.myConsumer(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;, "Consumer").start(); TimeUnit.SECONDS.sleep(5); System.out.println(Thread.currentThread().getName() + "\t 主线程叫停FLAG=false，生产动作结束"); myResource.close(); &#125;&#125;class MyResource&#123; private volatile boolean FLAG = true;//默认开启，进行生产+消费 private AtomicInteger atomicInteger = new AtomicInteger(); BlockingQueue&lt;String&gt; blockingQueue = null; public MyResource(BlockingQueue&lt;String&gt; blockingQueue) &#123; this.blockingQueue = blockingQueue; System.out.println(blockingQueue.getClass().getName()); &#125; public void myProd() throws InterruptedException &#123; String data; boolean retValue; while(FLAG)&#123; data = atomicInteger.incrementAndGet() + ""; retValue = blockingQueue.offer(data, 2L, TimeUnit.SECONDS); if(retValue)&#123; System.out.println(Thread.currentThread().getName() + "\t 插入队列"+data+"成功"); &#125;else&#123; System.out.println(Thread.currentThread().getName() + "\t 插入队列"+data+"失败"); &#125; TimeUnit.SECONDS.sleep(1); &#125; System.out.println(Thread.currentThread().getName() + "/ FLAG = false,生产结束"); &#125; public void myConsumer() throws InterruptedException&#123; String result; while(FLAG)&#123; result = blockingQueue.poll(2L, TimeUnit.SECONDS); if(null == result || result.equalsIgnoreCase(""))&#123; FLAG = false; System.out.println(Thread.currentThread().getName() + "\t 超过2秒没有消费成功，消费退出"); return; &#125; System.out.println(Thread.currentThread().getName() + "\t消费队列" + result + "成功"); &#125; &#125; public void close()&#123; FLAG =false; &#125;&#125;// 输出Prod 生产线程启动Consumer 消费线程启动Prod 插入队列1成功Consumer 消费队列1成功Consumer 消费队列2成功Prod 插入队列2成功Consumer 消费队列3成功Prod 插入队列3成功Prod 插入队列4成功Consumer 消费队列4成功Prod 插入队列5成功Consumer 消费队列5成功main 主线程叫停FLAG=false，生产动作结束Prod FLAG = false,生产结束Consumer 超过2秒没有消费成功，消费退出]]></content>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java锁]]></title>
    <url>%2F2019%2F04%2F27%2FJava%E9%94%81%2F</url>
    <content type="text"><![CDATA[Java提供了种类丰富的锁，每种锁因其特性的不同，在适当的场景下能够展现出非常高的效率。 公平锁/非公平锁并发包中ReentrantL ock的创建可以指定构造函数的boolean类型来得到公平锁或非公平锁，默认是非公平锁关于两者区别:公平锁: Threads acquire a fair lock in the order in which they requested it公平锁，就是很公平，在并发环境中，每个线程在获取锁时会先查看此锁维护的等待队列，如果为空，或者当前线程是等待队列的第一个，就占有锁，否则就会加入到等待队列中，以后会按照FIFO的规则从队列中取到自已非公平锁: a nonfair lock permits barging: threads requesting a lock can jump ahead of the queue of waiting threads if the lockhappens to be available when it is requested.非公平锁比较粗鲁，上来就 直接尝试占有锁，如果尝试失败，就再采用类似公平锁那种方式。 非公平锁的优点在于吞吐量比公平锁大。 对于synchronized而言，也是一种非公平锁 可重入锁（也叫递归锁） 指的是同一线程外层函数获得锁之后，内层递归函数仍然能获取该锁的代码，在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁。也即是说 ，线程可以 进入任何一个它已经拥有的锁所同步着的代码块。 ReentrantLock/synchronized就是一个典型的可重入锁 可重入锁的最大作用就是避免死锁 自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU 独占锁(写锁)/共享锁(读锁)/互斥锁独占锁：指该锁一次之只能被一个线程所持有。对ReentrantLock/synchronized都是独占锁 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980import java.util.HashMap;import java.util.Map;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.ReentrantReadWriteLock;class MyCache&#123; private volatile Map&lt;Integer, Object&gt; map = new HashMap&lt;&gt;(); private ReentrantReadWriteLock rwLock = new ReentrantReadWriteLock(); public void put(Integer key, Object value)&#123; rwLock.writeLock().lock(); try &#123; System.out.println(Thread.currentThread().getName() + "\t 正在写入："+key); TimeUnit.MILLISECONDS.sleep(300); map.put(key, value); System.out.println(Thread.currentThread().getName() + "\t 写入完成"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; rwLock.writeLock().unlock(); &#125; &#125; public void get(Integer key)&#123; rwLock.readLock().lock(); try &#123; System.out.println(Thread.currentThread().getName() + "\t 正在读取"); TimeUnit.MILLISECONDS.sleep(300); System.out.println(Thread.currentThread().getName() + "\t 读取完成："+ map.get(key)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; rwLock.readLock().unlock(); &#125; &#125;&#125;/** * 多个线程同时读一个资源类没有任何问题，所以为了满足并发量，读取共享资源应该可以同时进行 * 但是有一个线程想去写共享资源，就不因该再有其他线程可以对该资源进行读写 * 总结： * 读-读能共存 * 读-写不能共存 * 写-写不能共存 * 写操作：原子+独占，整个过程必须是一个完整的统一体，中间不许被分割，被打断 */public class ReadWriteLockDemo &#123; public static void main(String[] args) &#123; MyCache myCache = new MyCache(); for (int i = 0; i &lt; 5; i++) &#123; final int tempInt = i; new Thread(()-&gt; myCache.put(tempInt, tempInt),String.valueOf(i)).start(); &#125; for (int i = 0; i &lt; 5; i++) &#123; final int tempInt = i; new Thread(()-&gt; myCache.get(tempInt),String.valueOf(i)).start(); &#125; &#125;&#125;// 输出0 正在写入：00 写入完成1 正在写入：11 写入完成2 正在写入：22 写入完成3 正在写入：33 写入完成4 正在写入：44 写入完成1 正在读取0 正在读取2 正在读取3 正在读取4 正在读取3 读取完成：31 读取完成：10 读取完成：02 读取完成：24 读取完成：4 CountDownLatch让一些线程阻塞直到另一些线程完成一系列操作后才被唤醒 CountDownLatch主要有两个方法，当一个或多个线程调用await方法时，调用线程会被阻塞。其他线程调用countDown方法会将计数器减1（调用countDown方法的线程不会阻塞），当计数器的值变为0时，因调用await方法被阻塞的线程会被唤醒，继续执行。 CyclicBarrierCyclicBarrier的字面意思是可循环（Cyclic）使用的屏障（Barrier）。他要做的事情就是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，知道最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活，线程进入屏障通过CyclicBarrier的await（）方法。 Semaphore信号量主要用于两个目的，一个是用于多个共享资源的互斥使用，另一个用于并发线程的控制。]]></content>
      <categories>
        <category>JUC</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CAS]]></title>
    <url>%2F2019%2F04%2F27%2FCAS%2F</url>
    <content type="text"><![CDATA[在Java并发中，我们最初接触的应该就是synchronized关键字了，但是synchronized属于重量级锁，很多时候会引起性能问题，volatile也是个不错的选择，但是volatile不能保证原子性，只能在某些场合下使用。像synchronized这种独占锁属于悲观锁，它是在假设一定会发生冲突的，那么加锁恰好有用，除此之外，还有乐观锁，乐观锁的含义就是假设没有发生冲突，那么我正好可以进行某项操作，如果要是发生冲突呢，那我就重试直到成功，乐观锁最常见的就是CAS。 CASCAS的全称为Compare-And-Swap,它是一条CPU并发原语。 CAS有3个操作数，内存值V，旧的预期值A，要修改的更新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。它的功能是判断内存某个位置的值是否为预期值，如果是则更改为新的值，这个过程是原子的。 CAS并发原语体现在JAVA语言中就是sun.misc.Unsafe类中的各个方法。调用UnSafe类中的CAS方法，JVM 会帮我们实现出CAS汇编指令。这是一种完全依赖于硬件的功能，通过它实现了原子操作。由于CAS是一 种系统原语，原语属于操作系统用语范畴，是由若干条指令组成的，用于完成某个功能的一个过程，并且原语的执行必须是连续的，在执行过程中不允许被中断，也就是说CAS是一条CPU的原子指令，不会造成所谓的数据不一致问题。 UnsafeUnsafe是CAS的核心类，由于Java方法无法直接访问底层系统，需要通过本地(native) 方法来访问，Unsafe相当于-一个后门，基于该类可以直接操作特定内存的数据。Unsafe 类存在于sun.misc包中，其内部方法操作可以像C的指针一样直接操作内存，因为Java中CAS操作的执行依赖于Unsafe类的方法。注：Unsafe类中的所有方法都是native修饰的，也就是说Unsafe类中的方法都直接调用操作系统底层资源执行相应任务 CAS的缺点：循环时间长，开销大123456789101112131415//var1 AtomicInteger对象本身//var2 该对象值的引用地址// var4 需要变动的值// var5 通过var1、var2找出主内存中真实的值// 用该对象当前的值与var5比较：// 相同，更新var5+var4并返回true// 不同，继续取值然后再比较,直到更新完成public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; 如果CAS失败，会一直进行尝试。如果CAS长时间一直不成功，可能会给CPU带来很大的开销。 只能保证一个共享变量的原子操作对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就需要锁来保证原子性。 ABA问题CAS算法实现一个重要前提需要取出内存中某时刻的数据并在当下时刻比较并替换，那么在这个时间差类会导致数据的变化。比如说一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A，并且线程two进行了一些操作将值变成了B,:然后线程two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后线程one操作成功。尽管线程one的CAS操作成功，但是不代表这个过程就是没有问题的。 12345678910111213141516171819202122public class CASDemo &#123; static AtomicReference&lt;Integer&gt; atomicReference = new AtomicReference&lt;&gt;(100); public static void main(String[] args) &#123; new Thread(()-&gt;&#123; atomicReference.compareAndSet(100, 101); atomicReference.compareAndSet(101, 100); &#125;, "t1").start(); new Thread(()-&gt;&#123; try &#123; // 暂停1秒钟t2线程，保证上面的t1线程完成了一次ABA操作 TimeUnit.SECONDS.sleep(1); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; System.out.println(atomicReference.compareAndSet(100, 200) + "\t" + atomicReference.get()); &#125;, "t2").start(); // 输出 true 200 &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class CASDemo &#123; static AtomicStampedReference&lt;Integer&gt; atomicStampedReference = new AtomicStampedReference&lt;&gt;(100, 1); public static void main(String[] args) &#123; System.out.println("------ABA问题的解决--------"); new Thread(() -&gt; &#123; // 初始版本号 int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + "\t第一次版本号" + stamp); try &#123; // 暂停1秒钟t3线程 TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; atomicStampedReference.compareAndSet(100, 101, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1); System.out.println(Thread.currentThread().getName() + "\t第二次版本号" + atomicStampedReference.getStamp()); atomicStampedReference.compareAndSet(101, 100, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1); System.out.println(Thread.currentThread().getName() + "\t第三次版本号" + atomicStampedReference.getStamp()); &#125;, "t3").start(); new Thread(() -&gt; &#123; int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + "\t第一次版本号" + stamp); try &#123; // 暂停3秒钟t4线程，保证上面的t3线程完成了一次ABA操作 TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; boolean result = atomicStampedReference.compareAndSet(100, 200, stamp, stamp + 1); System.out.println(Thread.currentThread().getName() + "\t修改成功否：" + result + "\t当前最新实际版本号:" + atomicStampedReference.getStamp()); System.out.println(Thread.currentThread().getName() + "\t当前实际最新值：" + atomicStampedReference.getReference()); &#125;, "t4").start(); &#125;&#125;//输出------ABA问题的解决--------t3 第一次版本号1t4 第一次版本号1t3 第二次版本号2t3 第三次版本号3t4 修改成功否：false 当前最新实际版本号:3t4 当前实际最新值：100]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java8-接口的改变]]></title>
    <url>%2F2019%2F04%2F26%2FJava8-%E6%8E%A5%E5%8F%A3%E7%9A%84%E6%94%B9%E5%8F%98%2F</url>
    <content type="text"><![CDATA[jdk8出现的一个新特性–接口的增强。此次变化中，接口中某些方法也可以有方法体了。jdk8对于接口的设计，除了保留之前的版本记本特性外，还提供了两个新的功能。除了抽象方法外，还可以有默认方法（default方法）和静态方法（static方法），此两个方法都可以拥有方法体。 接口中允许有默认实现,使用 default 关键字声明,可以被覆写.必须创建实例调用 类优先规则：如果同时继承一个类 ，实现一个接口，接口中的默认方法和父类中的方法一样，则“接口中的默认方法会被忽略” 12345public interface MyInterface &#123; default String get()&#123; return "MyInterface"; &#125;&#125; 12345public interface MyFun &#123; default String get()&#123; return "MyFun"; &#125;&#125; 12345public class SubClass &#123; public String get() &#123; return "SubClass"; &#125;&#125; 123456public class MyClass extends SubClass implements MyInterface &#123; public static void main(String[] args) &#123; MyClass myClass = new MyClass(); System.out.println(myClass.get());//输出SubClass &#125;&#125; ​ 接口冲突。如果一个父接口提供一个默认方法，而另一个接口也是提供了一个具有相同名称和参数列表的方法（不管方法是否是默认方法），那么必须覆盖该方法来解决冲突 123456789public class MyClass /*extends SubClass*/ implements MyInterface, MyFun &#123; @Override public String get() &#123; return MyInterface.super.get(); // 或return MyFun.super.get(); // 或自己实现 &#125;&#125; 接口中运行有静态方法,直接类名调用,不需要实例 123456789public interface MyInterface &#123; default String get()&#123; return "MyInterface"; &#125; static void show()&#123; System.out.println("接口中的静态方法"); &#125;&#125; 1MyInterface.show(); //接口中的静态方法]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>Java8新特性关于</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Stream]]></title>
    <url>%2F2019%2F04%2F26%2FStream%2F</url>
    <content type="text"><![CDATA[Stream 是 Java8 中处理集合的关键抽象概念，它可以指定你希望对集合进行的操作，可以执行非常复杂的查找、过滤和映射数据等操作。使用Stream API 对集合数据进行操作，就类似于使用 SQL 执行的数据库查询。也可以使用 Stream API 来并行执行操作。简而言之，Stream API 提供了一种高效且易于使用的处理数据的方式。 流（Stream）是数据渠道，用于操作数据源（集合、数组等）所生成的元素序列。 “集合讲的是数据，流讲的是计算” 注意： Stream自己不会存储元素 Steam不会改变源对象。相反，他们会返回一个持有结果的新Stream。 Stream操作是延迟执行的。这意味着他们会等到需要结果的时候才执行。 Stream的三个操作步骤： 创建Stream 中间操作 终止操作（终端操作） 创建Stream1234567891011121314151617181920212223242526// 通过Collection 系列集合提供的stream()或parallelStream()获取stream// default Stream&lt;E&gt; stream() : 返回一个顺序流 // default Stream&lt;E&gt; parallelStream() : 返回一个并行流List&lt;String&gt; list = new ArrayList&lt;&gt;();Stream&lt;String&gt; stream = list.stream();// 通过Arrays中的静态方法stream()获取数组流// static &lt;T&gt; Stream&lt;T&gt; stream(T[] array): 返回一个流// 重载形式，能够处理对应基本类型的数组： // public static IntStream stream(int[] array)// public static LongStream stream(long[] array)// public static DoubleStream stream(double[] array)Integer[] arr = new Integer[]&#123;1,2,3,4,5&#125;;Stream&lt;Integer&gt; integerStream = Arrays.stream(arr);//通过Stream中的静态方法of()获取流//public static&lt;T&gt; Stream&lt;T&gt; of(T... values) : 返回一个流Stream&lt;String&gt; aa = Stream.of("aa", "bb", "cc");// 创建无限流// 可以使用静态方法 Stream.iterate() 和 Stream.generate(), 创建无限流。// 迭代// public static&lt;T&gt; Stream&lt;T&gt; iterate(final T seed, final UnaryOperator&lt;T&gt; f) // 生成// public static&lt;T&gt; Stream&lt;T&gt; generate(Supplier&lt;T&gt; s) : Stream&lt;Integer&gt; iterate = Stream.iterate(0, x -&gt; x + 2); 中间操作（Intermediate Operation）多个中间操作可以连接起来形成一个流水线，除非流水 线上触发终止操作，否则中间操作不会执行任何的处理！ 而在终止操作时一次性全部处理，称为“惰性求值”。 筛选和切片 方 法 描 述 filter(Predicate p) 接收 Lambda ， 从流中排除某些元素。 distinct() 筛选，通过流所生成元素的 hashCode() 和 equals() 去 除重复元素 limit(long maxSize) 截断流，使其元素不超过给定数量。 skip(long n) 跳过元素，返回一个扔掉了前 n 个元素的流。若流中元素 不足 n 个，则返回一个空流。与 limit(n) 互补 映射 方 法 描 述 map(Function f) 接收一个函数作为参数，该函数会被应用到每个元 素上，并将其映射成一个新的元素。 mapToDouble(ToDoubleFunction f) 接收一个函数作为参数，该函数会被应用到每个元 素上，产生一个新的 DoubleStream。 mapToInt(ToIntFunction f) 接收一个函数作为参数，该函数会被应用到每个元 素上，产生一个新的 IntStream。 mapToLong(ToLongFunction f) 接收一个函数作为参数，该函数会被应用到每个元 素上，产生一个新的 LongStream。 flatMap(Function f) 接收一个函数作为参数，将流中的每个值都换成另 一个流，然后把所有流连接成一个流 排序##### 方 法 描 述 sorted() 产生一个新流，其中按自然顺序排序 sorted(Comparator comp 产生一个新流，其中按比较器顺序排序 终止操作（Terminal Operation）终端操作会从流的流水线生成结果。其结果可以是任何不是流的 值，例如：List、Integer，甚至是 void 。 Terminal 操作的执行，才会真正开始流的遍历，并且会生成一个结果，或者一个 side effect。 注：一个流只能有一个 terminal 操作，当这个操作执行后，流就被使用“光”了，无法再被操作。所以这必定是流的最后一个操作。 查找与匹配 方 法 描 述 allMatch(Predicate p) 检查是否匹配所有元素 anyMatch(Predicate p) 检查是否至少匹配一个元素 noneMatch(Predicate p) 检查是否没有匹配所有元素 findFirst() 返回第一个元素 findAny() 返回当前流中的任意元素 count() 返回流中元素总数 max(Comparator c) 返回流中最大值 min(Comparator c) 返回流中最小值 forEach(Consumer c) 内部迭代(使用 Collection 接口需要用户去做迭 代，称为外部迭代。相反，Stream API 使用内部 迭代——它帮你把迭代做了) 归约 方 法 描 述 reduce(T iden, BinaryOperator b) 可以将流中元素反复结合起来，得到一个值。 返回 T 归约 reduce(BinaryOperator b) 可以将流中元素反复结合起来，得到一个值。 返回 Optional 收集Collector 接口中方法的实现决定了如何对流执行收集操作(如收集到 List、Set、Map)。但是 Collectors 实用类提供了很多静态方法，可以方便地创建常见收集器实例，具体方法与实例如下表： 方 法 描 述 collect(Collector c) 将流转换为其他形式。接收一个 Collector接口的 实现，用于给Stream中元素做汇总的方法 1234567891011121314151617181920212223242526272829303132333435363738394041// toList List&lt;T&gt; 把流中元素收集到ListList&lt;Employee&gt; emps= list.stream().collect(Collectors.toList()); // toSet Set&lt;T&gt; 把流中元素收集到SetSet&lt;Employee&gt; emps= list.stream().collect(Collectors.toSet()); // toCollection Collection&lt;T&gt; 把流中元素收集到创建的集合Collection&lt;Employee&gt;emps=list.stream().collect(Collectors.toCollection(ArrayList::new)); // counting Long 计算流中元素的个数long count = list.stream().collect(Collectors.counting()); // summingInt Integer 对流中元素的整数属性求和inttotal=list.stream().collect(Collectors.summingInt(Employee::getSalary)); // averagingInt Double 计算流中元素Integer属性的平均 值 doubleavg= list.stream().collect(Collectors.averagingInt(Employee::getSalary)); // summarizingInt IntSummaryStatistics 收集流中Integer属性的统计值。 如：平均值 IntSummaryStatisticsiss=list.stream().collect(Collectors.summarizingInt(Employee::getSalary));// joining String 连接流中每个字符串 String str= list.stream().map(Employee::getName).collect(Collectors.joining());// maxBy Optional&lt;T&gt; 根据比较器选择最大值 Optional&lt;Emp&gt; max = list.stream().collect(Collectors.maxBy(comparingInt(Employee::getSalary)));// minBy Optional&lt;T&gt; 根据比较器选择最小值 Optional&lt;Emp&gt; min = list.stream().collect(Collectors.minBy(comparingInt(Employee::getSalary))); // reducing 归约产生的类型 从一个作为累加器的初始值 开始，利用BinaryOperator与 流中元素逐个结合，从而归 约成单个值 int total = list.stream().collect(Collectors.reducing(0, Employee::getSalar, Integer::sum)); // collectingAndThen 转换函数返回的类型 包裹另一个收集器，对其结果转换函数 int how = list.stream().collect(Collectors.collectingAndThen(Collectors.toList(), List::size)); // groupingBy Map&lt;K, List&lt;T&gt;&gt; 根据某属性值对流分组，属性为K，结果为V Map&lt;Emp.Status, List&lt;Emp&gt;&gt; map= list.stream() .collect(Collectors.groupingBy(Employee::getStatus)); // partitioningBy Map&lt;Boolean, List&lt;T&gt;&gt; 根据true或false进行分区Map&lt;Boolean,List&lt;Emp&gt;&gt;vd=list.stream().collect(Collectors.partitioningBy(Employee::getManage)); API练习123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215public class TestStreamAPI &#123; List&lt;Transaction&gt; transactions = null; @Before public void before() &#123; Trader raoul = new Trader("Raoul", "Cambridge"); Trader mario = new Trader("Mario", "Milan"); Trader alan = new Trader("Alan", "Cambridge"); Trader brian = new Trader("Brian", "Cambridge"); transactions = Arrays.asList( new Transaction(brian, 2011, 300), new Transaction(raoul, 2012, 1000), new Transaction(raoul, 2011, 400), new Transaction(mario, 2012, 710), new Transaction(mario, 2012, 700), new Transaction(alan, 2012, 950) ); &#125; //找出2011年发生的所有交易，并按交易额排序（从低到高） @Test public void test1() &#123; transactions.stream() .filter(t -&gt; t.getYear() == 2011) .sorted(Comparator.comparingInt(Transaction::getValue)) .forEach(System.out::println); &#125; //交易员都在哪些不同的城市工作过？ @Test public void test2() &#123; transactions.stream() .map(t -&gt; t.getTrader().getCity()) .distinct() .forEach(System.out::println); &#125; //查找所有来自剑桥的交易员，并按姓名排序 @Test public void test3() &#123; transactions.stream() .map(Transaction::getTrader) .filter(trader -&gt; trader.getCity().equals("Cambridge")) .sorted(Comparator.comparing(Trader::getName)) .distinct() .forEach(System.out::println); &#125; //返回所有交易员的姓名字符串，按字母排序 @Test public void test4() &#123; transactions.stream() .map(t -&gt; t.getTrader().getName()) .sorted() .forEach(System.out::println); System.out.println("---------------"); String reduce = transactions.stream() .map(t -&gt; t.getTrader().getName()) .sorted() .reduce("", String::concat); System.out.println(reduce); &#125; //有没由交易员在米兰工作？ @Test public void test5() &#123; boolean miLan = transactions.stream() .anyMatch(t -&gt; t.getTrader().getCity().equals("Milan")); System.out.println(miLan); &#125; //打印生活在剑桥的交易员的所有交易额 @Test public void test6() &#123; Optional&lt;Integer&gt; cambridge = transactions.stream() .filter(t -&gt; t.getTrader().getCity().equals("Cambridge")) .map(Transaction::getValue) .reduce(Integer::sum); System.out.println(cambridge.get()); Integer cambridge1 = transactions.stream() .filter(t -&gt; t.getTrader().getCity().equals("Cambridge")) .collect(Collectors.summingInt(Transaction::getValue)); System.out.println(cambridge1); &#125; //所有交易中，最高的交易额是多少 @Test public void test7()&#123; Optional&lt;Integer&gt; max = transactions.stream() .map(Transaction::getValue) .max(Integer::compare); System.out.println(max.get()); &#125; //找到所有交易额最小的交易 @Test public void test8()&#123; Optional&lt;Transaction&gt; min = transactions.stream() .min(Comparator.comparingInt(Transaction::getValue)); System.out.println(min.get()); &#125; @Test public void test9()&#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(100000); for(int i=0; i&lt; 100000; i++)&#123; list.add((int) (Math.random()*100000)); &#125; Map&lt;Integer, Long&gt; collect = list.stream() .collect(Collectors.groupingBy(Function.identity(), Collectors.counting())); System.out.println(collect); &#125; /** * 给定一个数字列表，如何返回一个由每个数的平方构成的列表呢？ * 给定[1,2,3,4,5],应该返回[1,4,9,16,25] */ @Test public void test() &#123; Integer[] numArr = new Integer[]&#123;1, 2, 3, 4, 5&#125;;// Stream&lt;Integer&gt; numArr1 = Stream.of(numArr); Stream&lt;Integer&gt; stream = Arrays.stream(numArr); stream.map(x -&gt; x * x).forEach(System.out::println); &#125;&#125;//交易class Transaction &#123; private Trader trader; private int year; private int value; public Transaction() &#123; &#125; public Transaction(Trader trader, int year, int value) &#123; this.trader = trader; this.year = year; this.value = value; &#125; public Trader getTrader() &#123; return trader; &#125; public void setTrader(Trader trader) &#123; this.trader = trader; &#125; public int getYear() &#123; return year; &#125; public void setYear(int year) &#123; this.year = year; &#125; public int getValue() &#123; return value; &#125; public void setValue(int value) &#123; this.value = value; &#125; @Override public String toString() &#123; return "Transaction&#123;" + "trader=" + trader + ", year=" + year + ", value=" + value + '&#125;'; &#125;&#125;//交易员class Trader &#123; private String name; private String city; public Trader() &#123; &#125; public Trader(String name, String city) &#123; this.name = name; this.city = city; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getCity() &#123; return city; &#125; public void setCity(String city) &#123; this.city = city; &#125; @Override public String toString() &#123; return "Trader&#123;" + "name='" + name + '\'' + ", city='" + city + '\'' + '&#125;'; &#125;&#125;]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>Java8新特性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lambda]]></title>
    <url>%2F2019%2F04%2F24%2FLambda%2F</url>
    <content type="text"><![CDATA[本篇记录了Java8新特性Lambda表达式的使用以及函数式接口 Lambda表达式的基础语法：Java8中引入了一个新的操作符 “-&gt;” 该操作符称为箭头操作符 箭头操作符将Lambda表达式拆分成两部分： 左侧：Lambda表达式的参数列表 右侧：Lambda表达式中所需执行的功能，即Lambda体 语法格式 无参数，无返回值 1() -&gt; System.out.println("Hello Lambda"); 有一个参数，无返回值 1(x) -&gt; System.out.println(x); 若只有一个参数，小括号可以省略不写 1x -&gt; System.out.println(x); 有两个以上的参数，有返回值，并且Lambda体中有多条语句 1234Comparator&lt;Integer&gt; com = (x, y) -&gt;&#123; System.out.println("函数式接口"); return Integer.compare(x, y);&#125;; 若Lambda体中只有一条语句，return和大括号都可以省略不写 12Comparator&lt;Integer&gt; coms = (Integer x, Integer y) -&gt; Integer.compare(x, y);// Comparator&lt;Integer&gt; com = Integer::compare; Lambda表达式的参数列表的数据类型可以省略不写，因为JVM编译器可以通过上下文推断出，数据类型，即“类型推断”。 1Comparator&lt;Integer&gt; coms = (x, y) -&gt; Integer.compare(x, y); Lambda表达式需要“函数式接口”的支持 函数式接口：接口中只有一个抽象方法的接口，称为函数式接口。可以使用注解@FunctionalInterface修饰，可以检查是否是函数式接口。 内置函数式接口Java8中帮我们写好了函数式接口，无需我们自己定义 四大核心函数式接口 函数式接口 参数类型 返回类型 用途 Consumer&lt;T&gt; 消费性接口 T void 对类型为T的对象应用操消费型接口 作，包含方法:void accept(I t) Supplier&lt;T&gt; 供给型接口 无 T 返回类型为T的对象，包含方法: T get()； Punction&lt;T, R&gt;函数性接口 T R 对类型为T的对象应用操作，并返回结果。结果是R类型的对象。包含方法：R apply(T t); Predicate&lt;T&gt; 断定型接口 T boolean 确定类型为T的对象是否满足某约束，并返回boolean值，包含方法boolean test(T t); 代码演示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class LambdaTest &#123; @Test public void test1() &#123; eat(36, m -&gt; System.out.println("吃红烧鱼，每次消费" + m + "元")); &#125; @Test public void test2() &#123; String hello_world = strHandler("Hello World", str -&gt; str.substring(6, str.length())); System.out.println(hello_world); &#125; @Test public void test3() &#123; List&lt;Integer&gt; numList = getNumList(10, () -&gt; (int) (Math.random() * 100)); numList.forEach(System.out::println); &#125; @Test public void test4() &#123; List&lt;String&gt; list = Arrays.asList("Hello", "no", "ok", "java"); List&lt;String&gt; strings = filterString(list, s -&gt; s.length() &gt; 2); strings.forEach(System.out::println); &#125; // 消费型接口 public void eat(double money, Consumer&lt;Double&gt; con) &#123; con.accept(money); &#125; // 供给型接口 public List&lt;Integer&gt; getNumList(int num, Supplier&lt;Integer&gt; supplier) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; num; i++) &#123; list.add(supplier.get()); &#125; return list; &#125; // 函数性接口 public String strHandler(String str, Function&lt;String, String&gt; fun) &#123; return fun.apply(str); &#125; // 断言型接口 // 将满足条件的字符串，放入集合中 public List&lt;String&gt; filterString(List&lt;String&gt; list, Predicate&lt;String&gt; predicate) &#123; ArrayList&lt;String&gt; strList = new ArrayList&lt;&gt;(); for (String s : list) &#123; if (predicate.test(s)) &#123; strList.add(s); &#125; &#125; return strList; &#125;&#125; 其他接口 函数式接口 参数类型 返回类型 用途 BiFunction&lt;T, U, R&gt; 消费性接口 T,U R 对类型为T，U参数应用操作，返回R类型的结果。包含方法为R apply(T t, U u); UnaryOperator&lt;T&gt;(Function子接口) T T 对类型为T的对象进行一元运算，并返回T类型的结果。包含方法为T apply(I t); BinaryOperator&lt;T&gt;(BiFunction子接口) T,T T 对类型为T的对象进行二元运算，并返回T类型的结果。包含方法为T apply(T t1, T t2); BiConsumer&lt;T, U&gt; T,U void 对类型为T, U参数应用操作。包含方法为void accept(T t, U u) ToIntFunction&lt;T&gt;ToLongFunction&lt;T&gt;ToDoubleFunction&lt;T&gt; T intlongdouble 分别计算int、long、double、值的函数 IntFunction&lt;R&gt;LongFunction&lt;R&gt;DoubleFunction&lt;R&gt; intlongdouble R 参数分别为int、long、double类型的函数 方法引用三种语法格式 对象::实例方法 类::静态方法名 类::实例方法名 注意： Lambda体中调用方法的参数列表与返回值类型，要与函数式接口中抽象方法的函数列表和返回值类型保一致。 若Lambda参数列表中的第一参数式实例方法的调用者，而第二个参数式是实例方法的参数时，可以使用ClassName::method 构造器引用格式:ClassName::new 注:需要调用的构造器的参数列表要与函数式接口中抽象方法的参数列表保持一致！ 数组引用格式：Type[]::new]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>Java8新特性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis]]></title>
    <url>%2F2019%2F04%2F23%2FMybatis%2F</url>
    <content type="text"><![CDATA[MyBatis 是一款优秀的持久层框架，它支持定制化 SQL、存储过程以及高级映射。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生类型、接口和 Java 的 POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。 相比之下，还有一款优秀的框架Hibernate，Hibernate应用非常广泛，但是过度强调持久化和隔离数据库底层细节， 也导致了很多弊端，例如HQL需要额外的学习，未必比深入学习SQL语 言更高效；减弱程序员对SQL的直接控制，还可能导致其他代价，本来 一句SQL的事情，可能被Hibernate生成几条，隐藏的内部细节也阻碍了 进一步的优化。 MyBatis虽然仍然提供了一些映射的功能，但更加以SQL为中心，开 发者可以侧重于SQL和存储过程，非常简单、直接。如果我们的应用需 要大量高性能的或者复杂的SELECT语句等，“半自动”的MyBatis就会比 Hibernate更加实用。]]></content>
  </entry>
  <entry>
    <title><![CDATA[关键字final与volatile]]></title>
    <url>%2F2019%2F04%2F22%2F%E5%85%B3%E9%94%AE%E5%AD%97final%E4%B8%8Evolatile%2F</url>
    <content type="text"><![CDATA[本篇学习关键字final和volatile final在Java语言中，关键字final通常指“这是无法修改的”。之所以要采用final关键字，一般是出于性能和设计层面的考虑。 final数据用final关键字修饰的属性，对于Java编译器来说就是一个“常量”。其特点是： 具体的值在编译期间就已经被确定 在运行时被初始化的值，不希望它被改变。 对于基本类型，其本身就存放于虚拟机栈内部，由于这些基本类型都是与底层数据类型直接对应的，一些确定的计算过程可以直接在编译期完成，优化了运行期的执行效率。 对于引用类型，我们已知引用本身其实也是存放于虚拟机栈中，final关键字只限制了对这个引用的更改，并不会限制对引用所指的实例化对象的变更。 空白（blank）final 一个final属性可以定义的时候不赋予初始的值，但是在其实际使用之前必定需要被初始化，通常final属性的初始化，只会位于构造函数中或者属性定义时的表达式。为此，一个类中final域就可以根据对象而有所不同，却又可以保持其恒定不变的特性。 final参数Java允许在参数列表里以声明的方式将参数指明为final。这意味这你无法在方法中更改参数引用所指向的对象。 final方法使用final方法的原因有两个。 第一个原因：可以把方法锁定，以防止任何继承类修改它的含义。 第二个原因：方法的调用过程采用内嵌机制，更为高效 在最近的Java版本里，虚拟机做了优化，因此不再需要使用final方法来进行优化了。应该让编译器和JVM去处理效率问题，只有在想要明确静止覆盖时，才将方法设置为final的。 类中所有private方法都隐式地指定为是final的。由于无法取用private方法，所以也就无法覆盖它。可以对private方法添加final修饰词，但这并不能给该方法增加任何额外的意义。 这一问题会造成混淆。因为，如果你视图覆盖一个private方法（隐式是final的），似乎是奏效的，而且编译器也不会给出错误信息。 final类当将某个类的整体定义为final时，就表明了对于该类的设计永不需要做任何变动，或者出于安全的考虑，它不能有子类。 由于子类禁止继承，所以final类中所有的方法都隐式指定为是final的，因为无法覆盖它们。在final类中可以给方法添加final修饰词，但这不会增添任何意义。 volatile在Java语言中volatile关键字是一个类型修饰符。Java中volatile的作用：强制每次都直接读内存，阻止重排序，确保volatile类型的值一旦被写入缓存必定会被立即更新到主存。 内存可见性由于 Java 内存模型(JMM)规定，所有的变量都存放在主内存中，而每个线程都有着自己的工作内存(高速缓存)。 这里所提到的主内存可以简单认为是堆内存，而工作内存则可以认为是栈内存。 如图所示： 在并发环境中，可能出现线程B读取到的数据是线程A更新之前的数据。 这时，就到volatile出场了： 当一个变量被 volatile 修饰时，任何线程对它的写操作都会立即刷新到主内存中，并且会强制让缓存了该变量的线程中的数据清空，必须从主内存重新读取最新数据。 注:volatile 修饰之后并不是让线程直接从主内存中获取数据，依然需要将变量拷贝到工作内存中。 内存可见性的应用当我们需要在两个线程间依据主内存通信时，通信的那个变量就必须的用 volatile 来修饰： 123456789101112131415161718192021222324252627282930313233import java.util.Scanner;public class Demo implements Runnable&#123; private static volatile boolean flag = true; @Override public void run() &#123; while(flag)&#123; &#125; System.out.println(Thread.currentThread().getName() + "执行完毕！"); &#125; public static void main(String[] args) &#123; Demo demo = new Demo(); new Thread(demo, "thread A").start(); System.out.println("main 线程正在运行!"); Scanner sc = new Scanner(System.in); while(sc.hasNext())&#123; String value = sc.next(); if(value.equals("q"))&#123; new Thread(()-&gt; demo.stopThread()).start(); break; &#125; &#125; System.out.println("主线程退出了"); &#125; private void stopThread() &#123; flag = false; &#125;&#125; 主线程在修改了标志位使得线程 A 立即停止，如果没有用 volatile 修饰，就有可能出现延迟。 这里我们需要注意，volatile并不能保证线程安全性！ 123456789101112131415161718192021222324252627public class VolatileDemo implements Runnable &#123; private static volatile int count = 0; //使用 volatile 修饰基本数据内存不能保证原子性 //private static AtomicInteger count = new AtomicInteger() ; @Override public void run() &#123; for (int i = 0; i &lt; 10000; i++) &#123; count++; //count.incrementAndGet() ; &#125; &#125; public static void main(String[] args) &#123; VolatileDemo volatileDemo = new VolatileDemo(); Thread t1 = new Thread(volatileDemo, "t1"); Thread t2 = new Thread(volatileDemo, "t2"); t1.start(); //t1.join(); t2.start(); //t2.join(); for (int i = 0; i &lt; 10000; i++) &#123; count++; //count.incrementAndGet(); &#125; System.out.println("最终Count=" + count); &#125;&#125; 这里，三个线程（t1,t2,main)同时对一个int类型的count变量进行累加时，会发现最后的结果并不是30000 这是因为虽然 volatile 保证了内存可见性，每个线程拿到的值都是最新值，但 count ++ 这个操作并不是原子的，这里面涉及到获取值、自增、赋值的操作并不能同时完成。 所以想到达到线程安全可以使这三个线程串行执行(其实就是单线程，没有发挥多线程的优势)。 也可以使用 synchronize 或者是锁的方式来保证原子性。 还可以用 Atomic 包中 AtomicInteger 来替换 int，它利用了 CAS 算法来保证了原子性。 指令重排序volatile 还可以防止 JVM 进行指令重排优化。 举一个伪代码 12345678910111213141516171819private static Map&lt;String,String&gt; map ;private static volatile boolean flag = fasle ;//以下方法发生在线程 A 中 初始化 Mappublic void initMap()&#123; //耗时操作 map = getMap() ;//1 flag = true ;//2&#125;//发生在线程 B中 等到 Map 初始化成功进行其他操作public void doSomeThing()&#123; while(!flag)&#123; sleep() ; &#125; //dosomething doSomeThing(value);&#125; 当flag没有被volatile修饰时，JVM对1和2进行重排，导致map还没有被初始化，就有可能被线程B使用了。 加上volatile之后可以防止这样的重排优化，保证业务的正常性。 指令重排的应用一个最经典的场景就是双重懒加载(DCL)的单例模式了： 12345678910111213141516171819public class Singleton &#123; private static volatile Singleton singleton; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; //防止指令重排 singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 这里的 volatile 关键字主要是为了防止指令重排。 如果不用 ，singleton = new Singleton();，这段代码其实是分为三步： 分配内存空间。(1) 初始化对象。(2) 将 singleton 对象指向分配的内存地址。(3) 加上 volatile 是为了让以上的三步操作顺序执行，反之有可能第二步在第三步之前被执行就有可能某个线程拿到的单例对象是还没有初始化的，以致于报错。]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java位运算]]></title>
    <url>%2F2019%2F04%2F21%2FJava%E4%BD%8D%E8%BF%90%E7%AE%97%2F</url>
    <content type="text"><![CDATA[Java提供的位运算符有：左移( &lt;&lt; )、右移( &gt;&gt; ) 、无符号右移( &gt;&gt;&gt; ) 、位与( &amp; ) 、位或( | )、位非( ~ )、位异或( ^ )，除了位非( ~ )是一元操作符外，其它的都是二元操作符。 左移( &lt;&lt; )将5左移2位： 123456public class Test&#123;public static void main(String[] args)&#123; System.out.println(5&lt;&lt;2);//运行结果是20 &#125;&#125; 运行结果是20，但是程序是怎样执行的呢？ 首先会将5转为2进制表示形式(java中，整数默认就是int类型,也就是32位): 0000 0000 0000 0000 0000 0000 0000 0101 然后左移2位后，低位补0： 0000 0000 0000 0000 0000 0000 0001 0100 换算成10进制为20 -5换算成二进制： 1111 1111 1111 1111 1111 1111 1111 1011 左移3： 1111 1111 1111 1111 1111 1111 1101 1000 -40的补码 左移相当于 X乘 x的n次方 注意：正负数皆右补0 右移( &gt;&gt; )右移同理，只是方向不一样罢了 123456public class Test&#123;public static void main(String[] args)&#123; System.out.println(5&gt;&gt;2);//运行结果是1 &#125;&#125; 还是先将5转为2进制表示形式：0000 0000 0000 0000 0000 0000 0000 0101 然后右移2位，高位补0：0000 0000 0000 0000 0000 0000 0000 0001 右移相当于X除2的n次方 注意：正数高位补0，负数高位补1 无符号右移( &gt;&gt;&gt; )我们知道在Java中int类型占32位，可以表示一个正数，也可以表示一个负数。正数换算成二进制后的最高位为0，负数的二进制最高位为1 例如 -5换算成二进制后为：1111 1111 1111 1111 1111 1111 1111 1011 我们分别对5进行右移3位、 -5进行右移3位和无符号右移3位： 1234567public class Demo &#123; public static void main(String[] args) &#123; System.out.println(5 &gt;&gt; 3);//结果是0 System.out.println(-5 &gt;&gt; 3);//结果是-1 System.out.println(-5 &gt;&gt;&gt; 3);//结果是536870911 &#125;&#125; 我们来看看它的移位过程(可以通过其结果换算成二进制进行对比)： 5换算成二进制：0000 0000 0000 0000 0000 0000 0000 0101 5右移3位后结果为0，0的二进制为：0000 0000 0000 0000 0000 0000 0000 0000 // (用0进行补位) -5换算成二进制： 1111 1111 1111 1111 1111 1111 1111 1011 -5右移3位后结果为-1，-1的二进制为：1111 1111 1111 1111 1111 1111 1111 1111 // (用1进行补位) -5无符号右移3位后的结果 536870911 换算成二进制：0001 1111 1111 1111 1111 1111 1111 1111 // (用0进行补位) 通过其结果转换成二进制后，我们可以发现，正数右移，高位用0补，负数右移，高位用1补，当负数使用无符号右移时，用0进行部位(自然而然的，就由负数变成了正数了) 位与( &amp; )12345public class Demo &#123; public static void main(String[] args) &#123; System.out.println(5 &amp; 3);//结果是1 &#125;&#125; 将2个操作数和结果都转换为二进制进行比较： 5转换为二进制：0000 0000 0000 0000 0000 0000 0000 0101 3转换为二进制：0000 0000 0000 0000 0000 0000 0000 0011 -———————————————————————————— 1转换为二进制：0000 0000 0000 0000 0000 0000 0000 0001 位与：第一个操作数的的第n位于第二个操作数的第n位如果都是1，那么结果的第n为也为1，否则为0（同1则1，否则为0） 位或( | )12345public class Demo &#123; public static void main(String[] args) &#123; System.out.println(5 | 3);//结果是7 &#125;&#125; 5转换为二进制：0000 0000 0000 0000 0000 0000 0000 0101 3转换为二进制：0000 0000 0000 0000 0000 0000 0000 0011 -———————————————————————————— 7转换为二进制：0000 0000 0000 0000 0000 0000 0000 0111 位或操作：第一个操作数的的第n位于第二个操作数的第n位 只要有一个是1，那么结果的第n为也为1，否则为0(有1则1，否则为0) 位异或( ^ )12345public class Demo &#123; public static void main(String[] args) &#123; System.out.println(5 ^ 3); &#125;&#125; 5转换为二进制：0000 0000 0000 0000 0000 0000 0000 0101 3转换为二进制：0000 0000 0000 0000 0000 0000 0000 0011 -———————————————————————————— 6转换为二进制：0000 0000 0000 0000 0000 0000 0000 0110 位异或：第一个操作数的的第n位于第二个操作数的第n位 相反，那么结果的第n为也为1，否则为0(相反为1，否则为0) 位非( ~ )位非是一元操作符 12345public class Demo &#123; public static void main(String[] args) &#123; System.out.println(~5);//结果为-6 &#125;&#125; 5转换为二进制：0000 0000 0000 0000 0000 0000 0000 0101 -———————————————————————————— -6转换为二进制：1111 1111 1111 1111 1111 1111 1111 1010 位非：操作数的第n位为1，那么结果的第n位为0，反之。(取反) 由位运算操作符衍生而来的有： &amp;=按位与赋值 |= 按位或赋值 ^= 按位非赋值 >&gt;= 右移赋值 >&gt;&gt;= 无符号右移赋值 &lt;&lt;= 赋值左移 和 += 一个概念而已。 举个例子： 1234567public class Demo &#123; public static void main(String[] args) &#123; int a = 5; a &amp;= 3; System.out.println(a);//结果是1 &#125;&#125;]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[线程和进程的区别]]></title>
    <url>%2F2019%2F04%2F20%2F%E7%BA%BF%E7%A8%8B%E5%92%8C%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。 线程和进程用一句话概括的总论：进程和线程都是一个时间段的描述，是CPU工作时间段的描述。 https://www.zhihu.com/question/25532384 背景：CPU+RAM+各种资源（比如显卡，光驱，键盘，GPS, 等等外设）构成我们的电脑，但是电脑的运行，实际就是CPU和相关寄存器以及RAM之间的事情。 一个最基础的事实：CPU太快，太快，太快了，寄存器仅仅能够追的上他的脚步，RAM和别的挂在各总线上的设备完全是望其项背。那当多个任务要执行的时候怎么办呢？轮流着来?或者谁优先级高谁来？不管怎么样的策略，一句话就是在CPU看来就是轮流着来。 一个必须知道的事实：执行一段程序代码，实现一个功能的过程介绍 ，当得到CPU的时候，相关的资源必须也已经就位，就是显卡啊，GPS啊什么的必须就位，然后CPU开始执行。这里除了CPU以外所有的就构成了这个程序的执行环境，也就是我们所定义的程序上下文。当这个程序执行完了，或者分配给他的CPU执行时间用完了，那它就要被切换出去，等待下一次CPU的临幸。在被切换出去的最后一步工作就是保存程序上下文，因为这个是下次他被CPU临幸的运行环境，必须保存。 串联起来的事实：前面讲过在CPU看来所有的任务都是一个一个的轮流执行的，具体的轮流方法就是：先加载程序A的上下文，然后开始执行A，保存程序A的上下文，调入下一个要执行的程序B的程序上下文，然后开始执行B,保存程序B的上下文。 进程就是包换上下文切换的程序执行时间总和 = CPU加载上下文+CPU执行+CPU保存上下文 线程是什么呢？ 进程的颗粒度太大，每次都要有上下的调入，保存，调出。如果我们把进程比喻为一个运行在电脑上的软件，那么一个软件的执行不可能是一条逻辑执行的，必定有多个分支和多个程序段，就好比要实现程序A，实际分成 a，b，c等多个块组合而成。那么这里具体的执行就可能变成： 程序A得到CPU =》CPU加载上下文，开始执行程序A的a小段，然后执行A的b小段，然后再执行A的c小段，最后CPU保存A的上下文。 这里a，b，c的执行是共享了A的上下文，CPU在执行的时候没有进行上下文切换的。这 里的a，b，c就是线程，也就是说线程是共享了进程的上下文环境，的更为细小的CPU时间段。 线程和进程的区别： 拥有资源 进程是资源分配的基本单位，线程是CPU调度的最小单位。线程不拥有资源，线程可以访问隶属进程的资源。 调度 线程是独立调度的基本单位，在同一进程中，线程的切换不会引|起进程切换，从-一个进程中的线程切换到另-个进程中的线程时，会引起进程切换。 系统开销 由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等,所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程CPU环境的保存及新调度进程CPU环境的设置，而线程切换时只需保存和设置少量寄存器内容,开销很小。 通信方面 线程间可以通过直接读写同-进程中的数据进行通信，但是进程通信需要借助IPC。]]></content>
      <tags>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap]]></title>
    <url>%2F2019%2F04%2F20%2FHashMap%2F</url>
    <content type="text"><![CDATA[本篇讲解HashMap的相关知识 JDK 1.7 put过程： 判断当前数组是否需要初始化。 如果 key 为空，则 put 一个空值进去。 根据 key 计算出 hashcode。 根据计算出的 hashcode 定位出所在桶。 如果桶是一个链表则需要遍历判断里面的 hashcode、key 是否和传入 key 相等，如果相等则进行覆盖，并返回原来的值。 如果桶是空的，说明当前位置没有数据存入；新增一个 Entry 对象写入当前位置。 get过程： 首先也是根据 key 计算出 hashcode，然后定位到具体的桶中。 判断该位置是否为链表。 不是链表就根据 key、key 的 hashcode 是否相等来返回值。 为链表则需要遍历直到 key 及 hashcode 相等时候就返回值。 啥都没取到就直接返回 null 。 JDK1.8 put过程： 判断当前桶是否为空，空的就需要初始化（resize 中会判断是否进行初始化）。 根据当前 key 的 hashcode 定位到具体的桶中并判断是否为空，为空表明没有 Hash 冲突就直接在当前位置创建一个新桶即可。 如果当前桶有值（ Hash 冲突），那么就要比较当前桶中的 key、key 的 hashcode与写入的 key 是否相等，相等就赋值给 e,在第 8 步的时候会统一进行赋值及返回。 如果当前桶为红黑树，那就要按照红黑树的方式写入数据。 如果是个链表，就需要将当前的 key、value 封装成一个新节点写入到当前桶的后面（形成链表）。 接着判断当前链表的大小是否大于预设的阈值，大于时就要转换为红黑树。 如果在遍历过程中找到 key 相同时直接退出遍历。 如果 e != null 就相当于存在相同的 key,那就需要将值覆盖。 最后判断是否需要进行扩容。 get过程： 首先将 key hash 之后取得所定位的桶。 如果桶为空则直接返回 null 。 否则判断桶的第一个位置(有可能是链表、红黑树)的 key 是否为查询的 key，是就直接返回 value。 如果第一个不匹配，则判断它的下一个是红黑树还是链表。 红黑树就按照树的查找方式返回值。 不然就按照链表的方式遍历匹配返回值。]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP、UDP]]></title>
    <url>%2F2019%2F04%2F17%2FTCP%E3%80%81UDP%2F</url>
    <content type="text"><![CDATA[本篇讲述TCP和UDP的特点，区别。TCP的三次握手、四次挥手。 TCP的主要特点： TCP是面向连接的运输层协议。 每条TCP连接只能是点对点的（一对一） TCP提供可靠交付的服务，即无差错、不丢失、不重复且按序到达 TCP提供全双工通信 面向字节流 UDP的主要特点 UDP是无连接的 UDP使用不可靠信道 UDP使用尽最大努力交付，及不保证可靠交付 UDP是面向报文的 UDP支持一对一、一对多、多对一和多对多的交互通信 拥塞控制和流量控制 拥塞控制：对网络中的路由和链路传输进行速度限制，避免网络过载；包含四个过程：慢启动、拥塞避免、快重传和快恢复 流量控制：对点和点发送方和接受方之间进行速度匹配，由于接收方的应用程序读取速度不一定很迅速，加上缓存有限，因此需要避免发送速度过快；相关技术：TCP滑动窗口、回退N针协议 TCP的三次握手TCP建立连接：三次握手 第一次握手：客户端将标志位SYN置为1，随机产生一个值seq=x，并将该数据包发送给服务器，客户端进入SYN_SENT状态，等待服务器确认。 第二次握手：服务器收到数据包后由标志位SYN=1知道客户端请求建立连接，服务器将标志位SYN和ACK都置为1，ack=x+1，随机产生一个值seq=y，并将该数据包发送给客户端以确认连接请求，服务器进入SYN_RCVD状态。 第三次握手：客户端收到确认后，检查ack是否为x+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=y+1，并将该数据包发送给服务器，服务器检查ack是否为y+1，ACK是否为1，如果正确则连接建立成功，客户端和服务器进入ESTABLISHED状态，完成三次握手，随后客户端与服务器之间可以开始传输数据了。 为什么要三次握手： 为了保证服务端能收接受到客户端的信息并能做出正确的应答而进行前两次(第一次和第二次)握手，为了保证客户端能够接收到服务器的信息并能做出正确的应答而进行后两次(第二次和第三次)握手。 第三次握手可以避免由于客户端延迟的请求连接的请求，使得服务端无故再次建立连接。客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。 TCP的四次挥手TCP的连接释放：四次挥手 注：通信的双方都可以发出释放连接的请求 第一次挥手：客户端发送一个FIN，用来关闭客户端到服务器的数据传送，客户端进入FIN_WAIT_1状态。 第二次挥手：服务器收到FIN后，发送一个ACK给客户端，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），服务器进入CLOSE_WAIT状态。 第三次挥手：服务器发送一个FIN，用来关闭服务器到客户端的数据传送，服务器进入LAST_ACK状态。 第四次挥手：客户端收到FIN后，客户端进入TIME_WAIT状态，接着发送一个ACK给服务器，确认序号为收到序号+1，服务器进入CLOSED状态，完成四次挥手。 为什么要四次挥手： 关闭连接时，当服务器收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉客户端端，”你发的FIN报文我收到了”。只有等到我服务器所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。 SYN攻击 什么是 SYN 攻击（SYN Flood）？ 在三次握手过程中，服务器发送 SYN-ACK 之后，收到客户端的 ACK 之前的 TCP 连接称为半连接(half-open connect)。此时服务器处于 SYN_RCVD 状态。当收到 ACK 后，服务器才能转入 ESTABLISHED 状态. SYN 攻击指的是，攻击客户端在短时间内伪造大量不存在的IP地址，向服务器不断地发送SYN包，服务器回复确认包，并等待客户的确认。由于源地址是不存在的，服务器需要不断的重发直至超时，这些伪造的SYN包将长时间占用未连接队列，正常的SYN请求被丢弃，导致目标系统运行缓慢，严重者会引起网络堵塞甚至系统瘫痪。 SYN 攻击是一种典型的 DoS/DDoS 攻击。 如何检测 SYN 攻击？ 检测 SYN 攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击。在 Linux/Unix 上可以使用系统自带的 netstats 命令来检测 SYN 攻击。 如何防御 SYN 攻击？ SYN攻击不能完全被阻止，除非将TCP协议重新设计。我们所做的是尽可能的减轻SYN攻击的危害，常见的防御 SYN 攻击的方法有如下几种： 缩短超时（SYN Timeout）时间 增加最大半连接数 过滤网关防护 SYN cookies技术 TCP KeepAliveTCP 的连接，实际上是一种纯软件层面的概念，在物理层面并没有“连接”这种概念。TCP 通信双方建立交互的连接，但是并不是一直存在数据交互，有些连接会在数据交互完毕后，主动释放连接，而有些不会。在长时间无数据交互的时间段内，交互双方都有可能出现掉电、死机、异常重启等各种意外，当这些意外发生之后，这些 TCP 连接并未来得及正常释放，在软件层面上，连接的另一方并不知道对端的情况，它会一直维护这个连接，长时间的积累会导致非常多的半打开连接，造成端系统资源的消耗和浪费，为了解决这个问题，在传输层可以利用 TCP 的 KeepAlive 机制实现来实现。主流的操作系统基本都在内核里支持了这个特性。 TCP KeepAlive 的基本原理是，隔一段时间给连接对端发送一个探测包，如果收到对方回应的 ACK，则认为连接还是存活的，在超过一定重试次数之后还是没有收到对方的回应，则丢弃该 TCP 连接。 TCP-Keepalive-HOWTO 有对 TCP KeepAlive 特性的详细介绍，有兴趣的同学可以参考。这里主要说一下，TCP KeepAlive 的局限。首先 TCP KeepAlive 监测的方式是发送一个 probe 包，会给网络带来额外的流量，另外 TCP KeepAlive 只能在内核层级监测连接的存活与否，而连接的存活不一定代表服务的可用。例如当一个服务器 CPU 进程服务器占用达到 100%，已经卡死不能响应请求了，此时 TCP KeepAlive 依然会认为连接是存活的。因此 TCP KeepAlive 对于应用层程序的价值是相对较小的。需要做连接保活的应用层程序，例如 QQ，往往会在应用层实现自己的心跳功能。 播放视频用TCP还是UDP播放视频适合用UDP。UDP适用于对网络通讯质量要求不高、要求网络通讯速度能尽量快的实时性应用；而TCP适用于对网络通讯质量有要求的可靠性应用。而且视频区分关键帧和普通帧，虽然UDP会丢帧但如果只是丢普通帧损失并不大，取而代之的是高速率和实时性。]]></content>
      <categories>
        <category>网络</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[插入排序]]></title>
    <url>%2F2019%2F04%2F14%2F%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[本篇介绍插入排序排序算法 直接插入排序直接插入排序（Straight Insertion Sort）：是一种最简单的排序方法，其基本操作是将一条记录插入到已排好序的有序表中，从而得到一个新的，记录数量为1的有序表。 算法步骤 将第一待排序序列第一个元素看做一个有序序列，把第二个元素到最后一个元素当成是未排序序列。 从头到尾依次扫描未排序序列，将扫描到的每个元素插入有序序列的适当位置。（如果待插入的元素与有序序列中的某个元素相等，则将待插入元素插入到相等元素的后面。） 动画演示图片来源：https://mp.weixin.qq.com/s/vn3KiV-ez79FmbZ36SX9lg 代码实现123456789101112131415161718public class InsertSort &#123; public static void insertSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return; &#125; for (int i = 1; i &lt; arr.length; i++) &#123; for (int j = i - 1; j &gt;= 0 &amp;&amp; arr[j] &gt; arr[j + 1]; j--) &#123; swap(arr, j, j + 1); &#125; &#125; &#125; public static void swap(int[] arr, int i, int j) &#123; int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; &#125;&#125; 折半插入排序折半插入排序（Binary Insertion Sort）：直接插入排序采用查找法查找当前记录在已排好序的序列中的插入位置，这个“查找”操作可利用“折半查找”来实现，由此进行的插入排序称之为折半插入排序。 算法步骤 将第一待排序序列第一个元素看做一个有序序列，把第二个元素到最后一个元素当成是未排序序列。 从头到尾依次扫描未排序序列，将扫描到的每个元素插入有序序列的适当位置，在查找元素的适当位置时，采用了折半查找方法。（如果待插入的元素与有序序列中的某个元素相等，则将待插入元素插入到相等元素的后面。） 代码实现123456789101112131415161718192021222324252627public class BinsertSort &#123; public static void binsertSort(int[] arr)&#123; if(arr == null || arr.length &lt; 2)&#123; return; &#125; for (int i = 1; i &lt; arr.length; i++) &#123; int low = 0, high = i-1, tmp = arr[i]; while(low &lt;= high)&#123; int mid = (low + high) / 2; if(arr[mid] &gt; tmp)&#123; high = mid - 1; &#125;else&#123; low = mid + 1; &#125; &#125; for(int j = i -1; j &gt;= high + 1; j--)&#123; arr[j + 1] = arr[j]; &#125; arr[high+1] = tmp; &#125; &#125; public static void swap(int[] arr, int i, int j) &#123; int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; &#125;&#125; 算法分析 时间复杂度 在平均情况下，折半插入排序仅减少了关键字间的比较次数，而记录的移动次数不变。因此折半插入排序的时间复杂度仍未$O(n^2)$。 空间复杂度 只需要一个记录辅助空间，所以空间复杂度为$O(1)$。 算法特点 稳定排序 因为要进行折半查找，所以只能用于顺序结构，不能用于链式结构。 适合初始记录无序、n较大时的情况。 希尔排序希尔排序：（Shell’s Sort）:又称“缩小量排序”（Diminishing Increment Sort），是插入排序的一种。 算法步骤 选择一个增量序列 t1，t2，……，tk，其中 ti &gt; tj, tk = 1； 按增量序列个数 k，对序列进行 k 趟排序； 每趟排序，根据对应的增量 ti，将待排序列分割成若干长度为 m 的子序列，分别对各子表进行直接插入排序。仅增量因子为 1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 动画演示图片来源：https://mp.weixin.qq.com/s/vn3KiV-ez79FmbZ36SX9lg 代码实现123456789101112131415161718192021222324public class ShellSort &#123; public static void shellSort(int[] arr)&#123; if(arr == null || arr.length &lt; 2)&#123; return; &#125; for(int gap = arr.length &gt;&gt; 1; gap &gt; 0; gap &gt;&gt;= 1)&#123; //从第gap个元素，逐个对其所在组进行直接插入排序操作 for(int i = gap; i&lt; arr.length; i++)&#123; int j = i; while(j-gap &gt;= 0 &amp;&amp; arr[j] &lt; arr[j-gap])&#123; swap(arr, j, j-gap); j -= gap; &#125; &#125; &#125; &#125; public static void swap(int[] arr, int i, int j) &#123; int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; &#125;&#125; 算法分析 时间复杂度 希尔排序中对于增量序列的选择十分重要，直接影响到希尔排序的性能。我们上面选择的增量序列${n/2,(n/2)/2…1}$(希尔增量)，其最坏时间复杂度依然为$O(n^2)$，一些经过优化的增量序列如Hibbard经过复杂证明可使得最坏时间复杂度为$O(n^{2/3})$ 空间复杂度 只有在两个记录交换时需要一个辅助空间，所以空间复杂度为$O(1)$。 算法特点 记录跳跃式地移动导致排序方法是不稳定的。 只能用于顺序结构，不能用于链式结构。 记录总的比较次数和移动次数都比直接插入排序要少，n越大时，效果越明显。所以适合初始记录无序、n较大时的情况。]]></content>
      <categories>
        <category>排序</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[冒泡排序&选择排序]]></title>
    <url>%2F2019%2F04%2F14%2F%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F%26%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[本篇介绍冒泡排序、选择排序两种排序算法 冒泡排序冒泡排序（Bubble Sort）:是一种简单的交换排序方法，它通过两两比较相邻记录的关键子，如果发生逆序，则进行交换，从而使关键字小的记录如气泡一般逐渐网上“漂浮”（左移），或者使关键字大的记录如石块一样逐渐向下“坠落”（右移）。 算法步骤 比较相邻的元素。如果第一个比第二个大，就交换他们两个。 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。 针对所有的元素重复以上的步骤，除了最后一个。 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。 动画演示 图片来源：https://mp.weixin.qq.com/s/vn3KiV-ez79FmbZ36SX9lg 代码实现1234567891011121314151617181920public class BubbleSort &#123; public static void bubbleSort(int[] arr)&#123; if(arr == null || arr.length &lt; 2)&#123; return; &#125; for(int i = 0; i&lt; arr.length-1; i++)&#123; for(int j = i+1; j &lt; arr.length; j++)&#123; if(arr[i] &gt; arr[j])&#123; swap(arr, i, j); &#125; &#125; &#125; &#125; public static void swap(int[]arr, int a, int b)&#123; int temp = arr[a]; arr[a] = arr[b]; arr[b] = temp; &#125;&#125; 算法改进标志变量用于记录每趟冒泡排序是否发生数据元素位置交换。如果没有发生交换，说明序列已经有序了，不必继续进行下去了。 1234567891011121314public static void bubbleSort_imp(int[] arr)&#123; if(arr == null || arr.length &lt; 2)&#123; return; &#125; boolean flag = true; for(int i = 0; i&lt; arr.length-1 &amp;&amp; flag; i++)&#123; for(int j = i+1; j &lt; arr.length; j++)&#123; if(arr[i] &gt; arr[j])&#123; swap(arr, i, j); flag = true; &#125; &#125; &#125;&#125; 算法分析 时间复杂度 当原始序列“正序”排列时，冒泡排序总的比较次数为$n-1$，移动次数为0，也就是说冒泡排序在最好情况下的时间间复杂度为$O(n)$； 当原始序列“逆序”排序时，冒泡排序总的比较次数为$n(n-1)/2$，移动次数为$3n(n-1)/2$次，所以冒泡排序在最坏情况下的时间复杂度为$O(n^2)$； 所在在平均情况下冒泡排序的平均时间复杂度为$O(n^2)$。 空间复杂度 冒泡排序排序过程中需要一个临时变量进行两两交换，所需要的额外空间为1，因此空间复杂度为O(1)。 算法特点： 冒泡排序是一种稳定的排序算法。 可用于链式存储结构 移动记录次数较多，算法平均时间性能比较直接插入排序差。当初始记录无序，n较大时，此算法不宜采用。 选择排序 简单选择排序是最简单直观的一种算法，基本思想为每一趟从待排序的数据元素中选择最小（或最大）的一个元素作为首元素，直到所有元素排完为止， 算法步骤 首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置 再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。 重复第二步，直到所有元素均排序完毕。 动画演示 代码实现123456789101112131415161718192021222324public class SelectSort &#123; public static void selectSort(int[] arr)&#123; if(arr == null &amp;&amp; arr.length &lt; 2)&#123; return; &#125; for(int i = 0; i &lt; arr.length - 1; i++)&#123; // 用于存放较小元素的数组下标 int minIndex = i; for(int j = i + 1; j &lt; arr.length; j++)&#123; minIndex = arr[j] &lt; arr[minIndex] ? j : minIndex; &#125; //如果minIndex 未发生变化，则不需要交换 if(minIndex != i)&#123; swap(arr, i, minIndex); &#125; &#125; &#125; public static void swap(int[] arr, int i, int j) &#123; int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; &#125;&#125; 算法分析 时间复杂度 最好情况（正序）：不移动；最坏情况（逆序）：移动3(n-1)此。所以选择排序的时间复杂度也是$O(n^2)$ 空间复杂度 只有在两个记录交换时需要一个辅助空间，所以空间复杂度为O(1)。 算法特点 选择排序是一种不稳定的排序 可用于链式存储结构 移动记录次数较少，当每一记录占用的空间较多时，此方法比直接插入排序块。]]></content>
      <categories>
        <category>排序</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[归并排序]]></title>
    <url>%2F2019%2F04%2F13%2F%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[本篇简单讲述一下归并排序以及时间复杂度 归并排序思想 代码实现 过程分析 时间复杂度和空间复杂 归并排序归并排序（Merging Sort）就是将两个或者两个以上的有序表合并成一个有序表的过程。将两个有序表合并成一个有序表的过程2-路归并 归并排序算法的思想是： 假设初始序列含有n个记录，则可看成n个有序的子序列，每个子序列的长度为1，然后两两归并，得到[n/2]个长度为2或1的子序列；再两两归并, …..， 如此重复，直至得到一个长度为n的有序序列为止。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142public class MergeSort &#123; public static void mergeSort(int[] arr)&#123; if(arr == null || arr.length &lt; 2)&#123; return; &#125; mergeSort(arr, 0, arr.length - 1); &#125; private static void mergeSort(int[] arr, int left, int right)&#123; if(left == right)&#123; return; &#125; int mid = left + ((right-left) &gt;&gt; 1); // &lt;--&gt; (l+r)/2 mergeSort(arr, left, mid); mergeSort(arr, mid + 1, right); // left - mid mid+1 - right 两个序列已经排好序，但整体无序 // merge的过程就是将两个序列排序 merge(arr, left, mid, right); &#125; private static void merge(int[] arr, int left, int m, int right) &#123; // 申请辅助数组,存放合并后的序列 int[] help = new int[right - left + 1]; int i= 0; int p1 = left; int p2 = m + 1; while(p1 &lt;= m &amp;&amp; p2 &lt;= right)&#123; help[i++] = arr[p1] &lt; arr[p2] ? arr[p1++] : arr[p2++]; &#125; // 两个必有且只有一个越界 // 两个循环只会执行一个 while (p1 &lt;= m) &#123; help[i++] = arr[p1++]; &#125; while (p2 &lt;= right) &#123; help[i++] = arr[p2++]; &#125; for (i = 0; i &lt; help.length; i++) &#123; arr[left + i] = help[i]; &#125; &#125;&#125; 动画演示图片来源：https://mp.weixin.qq.com/s/vn3KiV-ez79FmbZ36SX9lg merge过程： 12345678while (p1 &lt;= m) &#123; help[i++] = arr[p1++];&#125;while (p2 &lt;= right) &#123; help[i++] = arr[p2++];&#125;p1,p2每次只会移动一个，所以必定会有一个越界。如果p1耗尽，需要把p2后面内容拷贝至help数组，反之。 时间复杂度当有n个记录时，需进行$\lceil log_2n \rceil$躺归并排序，其关键字比较次数不超过n，元素移动次数都是n，因此，归并排序的时间复杂度为$O(nlog_2n)$。 空间复杂度用顺序表实现归并排序时，需要和待排序记录个数相等的辅助存储空间，所以空间复杂度为O(n)。 特点归并排序是一种稳定的排序]]></content>
      <categories>
        <category>排序</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程安全与锁优化]]></title>
    <url>%2F2019%2F04%2F10%2F%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E4%B8%8E%E9%94%81%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[本篇将介绍线程安全所涉及的概念和分类、同步实现的方式及虚拟机的底层运作原理，以及虚拟机为了实现高效并发所采取的一系列锁优化措施。 线程安全《Java Concurrency In Practice》的作者Brian Goetz对“线程安全”有个比较恰当的定义：当多个线程访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那这个对象是线程安全的。 这个定义比较严谨，它要求线程安全的代码都必须具备一个特征： 代码本身封装了所有必要的正确性保障手段（如互斥同步等），令调用者无须关心多线程的问题，更无须 自己采取任何措施来保证多线程的正确调用。 Java语言中的线程安全分类：按照线程安全的程度由强至弱分成五类 不可变：外部的可见状态永远不会改变，在多个线程之中永远都是一致的状态。 一定是线程安全的 如何实现： 如果共享数据是一个基本数据类型，只要在定义时用final关键子修饰； 如果共享数据是一个对象，最简单的方法是把对象中带有状态的变量都声明为final 绝对的线程安全：完全满足之前给出的线程安全的定义，即达到“不管运行时环境如何，调用者都不需要任何额外的同步措施”。 相对的线程安全：能保证对该对象单独的操作是线程安全的，在调用时无需做额外保障措施，当对于一些特定顺序的连续调用，可能需要在调用端使用额外的同步措施来保证调用的正确性。 是通常意义上所讲的线程安全 大部分的线程安全类都属于这种类型，如Vector、HashTable、Collections#synchronizedCollection()包装的集合.. 线程兼容：对象本身非线程安全的，但可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用。 是通常意义上所讲的非线程安全 Java API中大部分类都是属于线程兼容的，如ArrayList和HashMap… 线程对立：无论调用端是否采取了同步措施，都无法在多线程环境中并发使用的代码。 线程安全的实现方式 可分为两大手段，本篇重点在虚拟机本身 通过代码编写实现线程安全 通过虚拟机本身实现同步与锁 互斥同步 含义： 同步：在多个线程并发访问共享数据时，保证共享数据在同一个时刻只被一个线程使用。 互斥：是实现同步的一种手段，临界区（Critical Section）、互斥量（Mutex）和信号量（Semaphore）都是主要的互斥实现方式。 互斥是因，同步是果；互斥是方法，同步是目的。 属于悲观并发策略，即认为只要不做正确的同步措施就肯定会出现问题，因此无论共享数据是否真的会出现竞争，都要加锁。 最大的问题是进行线程阻塞和唤醒所带来的性能问题，也称为阻塞同步（Blocking Synchronization） 手段： 使用synchronized关键字： 原理：编译后会在同步块的前后分别形成monitorenter和monitorexit这两个字节码指令，并通过一个reference类型的参数来指明要锁定和解锁的对象。若明确指定了对象参数，则取该对象的reference；否则，会根据synchronized修饰的是实例方法还是类方法去取对应的对象实例或Class对象来作为锁对象。 过程：执行monitorenter指令时先要尝试获取对象的锁。若该对象没被锁定或者已被当前线程获取，那么锁计数器+1；而在执行monitorexit指令时，锁计数器-1；当锁计数器=0时，锁就被释放；若获取对象锁失败，那当前线程会一直被阻塞等待，直到对象锁被另外一个线程释放为止。 特别注意：synchronized同步块对同一条线程来说是可重入的，不会出现自我锁死的问题；还有，同步块在已进入的线程执行完之前，会阻塞后面其他线程的进入。 使用重入锁ReentrantLock： 相同：用法与synchronized很相似，且都可重入。 不同： 等待可中断：当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。 公平锁：多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。而synchronized是非公平的，即在锁被释放时，任何一个等待锁的线程都有机会获得锁。ReentrantLock默认情况下也是非公平的，但可以通过带布尔值的构造函数改用公平锁。 锁绑定多个条件：一个ReentrantLock对象可以通过多次调用newCondition()同时绑定多个Condition对象。而在synchronized中，锁对象的wait()和notify()或notifyAll()只能实现一个隐含的条件，若要和多于一个的条件关联不得不额外地添加一个锁。 选择：在synchronized能实现需求的情况下，优先考虑使用它来进行同步。下两张图是两者在不同处理器上的吞吐量对比。 非阻塞同步（Non-Blocking Synchronization）： 基于冲突检测的乐观并发策略，即先进行操作，若无其他线程争用共享数据，操作成功；反之产生了冲突再去采取其他的补偿措施。 为了保证操作和冲突检测这两步具备原子性，需要用到硬件指令集，比如： 测试并设置（Test-and-Set） 获取并增加（Fetch-and-Increment） 交换（Swap） 比较并交换（Compare-and-Swap,CAS） 加载链接/条件存储（Load-Linked/Store-Conditional,LL/SC） 无同步方案 定义：不同同步的方式保证线程安全，因为有些代码天生就是线程安全的。下面列举两个例子： 可重入代码（Reentrant Code）/纯代码（Pure Code） 含义：可在代码执行的任何时刻中断它去执行另外一段代码，当控制权返回后原来的程序并不会出现任何错误。 共同特征：不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法… 判定依据：如果一个方法，它的返回结果是可预测的，只要输入相同的数据就都能返回相同的结果，就满足可重入性。 满足可重入性的代码一定是线程安全的，反之，满足线程安全的代码不一定是可重入的。 线程本地存储（Thread Local Storage） 含义：把共享数据的可见范围限制在同一个线程之内，无须同步就能保证线程之间不出现数据争用的问题。 使用ThreadLocal类可实现线程本地存储的功能：每个线程的Thread对象中都有一个ThreadLocalMap对象，它存储了一组以ThreadLocal.threadLocalHashCode为key、以本地线程变量为value的键值对，而ThreadLocal对象就是当前线程的ThreadLocalMap的访问入口，也就包含了一个独一无二的ThreadLocalHashCode值，通过这个值就可以在线程键值值对中找回对应的本地线程变量。 锁优化解决并发的正确性之后，为了能在线程之间更『高效』地共享数据、解决竞争问题、提高程序的执行效率，下面介绍五种锁优化技术。 适应性自旋（Adaptive Spinning） 背景：互斥同步在实现阻塞和唤醒时需要挂起线程和恢复线程的操作，都需要转入内核态中完成，很影响系统的并发性能；同时，在许多应用上共享数据的锁定状态只是暂时，没必要去挂起和恢复线程。 自旋锁：当物理机器有多个处理器使得多个线程同时并行执行时，先让后请求锁的线程等待，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁，这时只需让线程执行一个忙循环，即自旋 注意：自旋等待不能代替阻塞，它虽然能避免线程切换的开销，但会占用处理器时间，因此自旋等待的时间必须要有一定的限度，如果自旋超过了限定的次数仍未成功获锁，就需要挂线程了。 自适应自旋锁：自旋的时间不再固定，而是由该锁上的上次自旋时间及锁的拥有者的状态共同决定。具体表现是： 如果对于某个锁，自旋等待刚刚成功获得，且持有锁的线程正在运行中，那么虚拟机很可能允许自旋等待的时间更久点。 如果对于某个锁，自旋很少成功获得过，那么很可能以后将省略自旋等待这个锁，避免浪费处理器资源。 锁消除（Lock Elimination） 锁消除：指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。 判定依据：如果一段代码中堆上的所有数据都不会逃逸出去被其他线程访问到，可把它们当做栈上数据对待，即线程私有的，无须同步加锁。 锁粗化(Lock Coarsening) 一般情况下，会将同步块的作用范围限制到只在共享数据的实际作用域中才进行同步，使得需要同步的操作数量尽可能变小，保证就算存在锁竞争，等待锁的线程也能尽快拿到锁。 但如果反复操作对同一个对象进行加锁和解锁，即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗，此时，虚拟机将会把加锁同步的范围粗化到整个操作序列的外部，这样只需加一次锁。 轻量级锁（Lightweight Locking） 目的：在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗，注意不是用来代替重量级锁的。 首先先理解HotSpot虚拟机的对象头的内存布局：分为两部分 第一部分用于存储对象自身的运行时数据，这部分被称为Mark Word，是实现轻量级锁和偏向锁的关键。如哈希码、GC分代年龄等。 另外一部分用于存储指向方法区对象类型数据的指针，如果是数组对象还会有一个额外的部分用于存储数组长度。 加锁过程：代码进入同步块时，如果同步对象未被锁定（锁标志位为01），虚拟机会在当前线程的栈帧中建立一个名为Lock Record的空间，用于存储锁对象Mark Word的拷贝。如下图。 之后虚拟机会尝试用CAS操作将对象的Mark Word更新为指向Lock Record的指针。若更新动作成功，那么当前线程就拥有了该对象的锁，且对象Mark Word的锁标志位变为00，即处于轻量级锁定状态；反之，虚拟机会先检查对象的Mark Word是否指向当前线程的栈帧，若当前线程已有该对象的锁，可直接进入同步块继续执行，否则说明改对象已被其他线程抢占。如下图。 如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁，锁标志位变为10，Mark Word中存储的就是指向重量级锁的指针，后面等待锁的线程也要进入阻塞状态。 解锁过程：若对象的Mark Word仍指向着线程的Lock Record，就用CAS操作把对象当前的Mark Word和线程中复制的Displaced Mark Word替换回来。若替换成功，那么就完成了整个同步过程；反之，说明有其他线程尝试获取该锁，那么就要在释放锁的同时唤醒被挂起的线程。 优点：因为对于绝大部分的锁，在整个同步周期内都是不存在竞争的，所以轻量级锁通过使用CAS操作消除同步使用的互斥量。 偏向锁（Biased Locking） 目的：消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。 含义：偏向锁会偏向于第一个获得它的线程，如果在后面的执行中该锁没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步。 加锁过程：启用偏向锁的锁对象在第一次被线程获取时，Mark Word的锁标志位会被设置为01，即偏向模式，同时使用CAS操作把获取到这个锁的线程ID记录在对象的Mark Word中。若操作成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时都可不再进行任何同步操作。 解锁过程：当有另外的线程去尝试获取这个锁时，根据锁对象目前是否处于被锁定的状态，撤销偏向后恢复到未锁定01或轻量级锁定00的状态，后续的同步操作就如轻量级锁执行过程。如下图。 优点：可提高带有同步但无竞争的程序性能，但若程序中大多数锁总被多个线程访问，此模式就没必要了。 参考简书-厘米姑娘：要点提炼| 理解JVM之线程安全&amp;锁优化]]></content>
      <categories>
        <category>JVM</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[招商银行笔试编程题]]></title>
    <url>%2F2019%2F04%2F10%2F%E6%8B%9B%E5%95%86%E9%93%B6%E8%A1%8C%E7%AC%94%E8%AF%95%E7%BC%96%E7%A8%8B%E9%A2%98%2F</url>
    <content type="text"><![CDATA[记录了一下4月9日招商银行的笔试题中的编程题 第一题，巧克力 第二题，倒水 第一题，巧克力题目描述： 123456期未到了，老师为了表扬各位学生，购买了与学生数量相同的巧克力。* 老师制定了一个规则，每位学生按学号顺序依次独自进入他的办公室，* 他会随机给一定数量的巧克力给进入他办公室的学生(最少1块，学号靠后的同学可能拿不到巧克力)。* 小招喵的学号是1,所以他是第一个进入老师办公室的。他希望自己能从老师那里拿到至少6块巧克力。* 他希望你帮他计算一下他拿到至少6块巧克力的方案数一共是多少(如果最终分配方案中，某个学号的同学拿到的巧克力数不一样则认为是不同的方案)。* 最终的结果可能很大，输出对6666666取模后的结果。 输入描述： 一个整数n，代表学生的人数。 输出描述 一个整数ans，代表方案数对6666666取模后的结果。 实例1 输入 6 输出 1 实例2 输入 8 输出 4 题目分析： 这道题比较简单，我们先列下变量 12345678910111213141516* 6: 6 -&gt;1* 7: 6 1 -&gt;2* 7* 8: 6 1 1 -&gt;4* 6 2* 7 1* 8* 9: 6 3 -&gt;8* 6 2 1* 6 1 1 1* 6 1 2* 7 1 1* 7 2* 8 1* 9* ....... 不难看出这是一个$2^0,2^1,2^2,2^3……2^{n-6}$，所以就可以写代码了 123456789101112131415161718192021public class Chocolate &#123; public static void main(String[] args) &#123; Scanner s = new Scanner(System.in); int n = s.nextInt(); if( n &lt; 6)&#123; System.out.println(0); &#125;else&#123; System.out.println(Math.pow(2， n-6) % 6666666)； &#125; //get(n); &#125; //public static void get(int n)&#123; // int result = 1; // for(int i = 0; i &lt; n - 6; i++)&#123; // result *= 2;; // result %= 6666666; // &#125; // System.out.println(result); //&#125;&#125; 第二题，倒水题目描述： 123给出n*2个杯子，每个杯子的容星为ai，以及w毫升的水，小招喵将要接待n个男孩和n个女孩。每人一个杯子，倒水的规则如下:-每个男孩杯子里的水量要相同-每个女孩杯子里的水量要相同一男孩杯子里的水量要是女孩杯子里的水量的两倍。问最多总共能倒入多少毫升水。 输入描述: 输入包含两行。w(1≤n≤105, 1≤w≤10%)第一行为两个整数n和第二行为2n个整数a1,a2…a2n(1≤ai≤10^9) 输出描述 一个数， 表示最多倒入多少 毫升水，答案保留6位小数。 示例 输入 2 4 1 1 1 1 输出 3.000000 直接贴代码，分析写在代码注释里了 123456789101112131415161718192021222324252627282930import java.util.Arrays;import java.util.Scanner;public class PourWater &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); int n = scanner.nextInt(), w = scanner.nextInt(); int[] a = new int[2 * n]; for (int i = 0; i &lt; 2 * n; i++) &#123; a[i] = scanner.nextInt(); &#125; // 将杯子容量进行排序 Arrays.sort(a); // 男生的第一个杯子，女生的第一个杯子 double bMin = a[n], gMin = a[0]; double ans; // 如果男生的第一个杯子比女生第一个杯子2倍少 if (bMin / 2 &lt;= gMin) &#123; // 女生的杯子容量是男生第一个杯子的1/2 ans = bMin * 1.5 * n; &#125; else &#123;//男生的第一个杯子比女生第一个杯子2倍多 // 男生的杯子容量是女生第一个杯子的2倍 ans = gMin * n * 3; &#125; // 判断总容量 if (ans &gt;= w) &#123; ans = w; &#125; System.out.printf("%.6f", ans); &#125;&#125;]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java内存模型与线程]]></title>
    <url>%2F2019%2F04%2F09%2FJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[本篇介绍虚拟机如何实现多线程、多线程之间由于共享和竞争数据而导致的一系列问题及解决方案。 概述 Java内存模型 Java与线程 概述多任务处理的必要性 充分利用计算机处理器的能力，避免处理器在磁盘I/O、网络通信或数据库访问时总是处于等待其他资源的状态。 便于一个服务端同时对多个客户端提供服务。通过指标每秒事务处理数（Transactions Per Second， TPS）可衡量一个服务性能的高低好坏，它表示每秒服务端平均能响应的请求总数，进而体现出程序的并发能力。 硬件的效率与一致性 为了更好的理解Java内存模型，先理解物理计算机中的并发问题，两者有很高的可比性。 由于计算机的存储设备与处理器的运算速度有几个数量级的差距，所以现代计算机系统都不得加入一层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲： 将运算需要使用到的数据复制到缓存中，让运算能快速进行； 当运算结束后再从缓存同步回内存之中，而无须让处理器等待缓慢的内存读写。 但是基于高速缓存的存储交互在多处理器系统中会带来缓存一致性（Cache Coherence）的问题。这是因为每个处理器都有自己的高速缓存，而它们又共享同一主内存（Main Memory），当多个处理器的运算任务都涉及同一块主内存区域时，就可能导致各自的缓存数据不一致。解决办法就是需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作。如下图： 在本篇提到的“内存模型”，可以理解为在特定的操作协议下，对特定的内存或高速缓存进行读写访问的过程抽象。不同架构的物理机可以拥有不同的内存模型，Java虚拟机也有自己的内存模型。 Java内存模型 目的：屏蔽掉各种硬件和操作系统的内存访问差异，实现Java冲虚在各种平台下都能达到一致的内存访问效果。 主要目标：通过定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。 注意：这里的变量与Java编程中说的变量不同，它包括了实例字段、静态字段和构成数组对象的元素，但不包括局部变量与方法参数，因为后者是线程私有的，不会被共享，自然就不会存在竞争问题。 模型结构图：和物理机的内存模型图类比。 主内存（Main Memory）：所有的变量都存储在主内存中。直接对应物理硬件的内存 工作内存（Working Memory)：每条线程还有自己的工作内存，用于保存被该线程使用到的变量的主内存副本拷贝。为了获取更好的运行速度，虚拟机可能会让工作内存优先存储于寄存器和高速缓存中。 注意： 这里的主内存、工作内存与Java内存区域中的Java堆、栈、方法区等并不是同一个层次的内存划分，两者基本上是没有关系的。 线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存中的变量。 不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递必须通过主内存来完成。 内存间的交互操作交互协议：用于规定一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节。共有8种操作： ①用于主内存变量： 锁定（lock）：把变量标识为一条线程独占的状态。 解锁（unlock）：把处于锁定状态的变量释放出来。 读取（read）：把变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。 写入（write）：把store操作从工作内存中得到的变量的值放入主内存的变量中。 ②用于工作内存变量： 使用（use）：把工作内存中一个变量的值传递给执行引擎。 赋值（assign）：把从执行引擎接收到的值赋给工作内存的变量。 存储（store）：把工作内存中变量的值传送到主内存中，以便随后的write操作使用。 载入（load）：把read操作从主内存中得到的变量值放入工作内存的变量副本中。 结论：注意是顺序非连续 如果要把变量从主内存复制到工作内存，那就要顺序地执行read和load。 如果要把变量从工作内存同步回主内存，就要顺序地执行store和write。 确保并发操作安全的原则，在Java内存模型中规定了执行上述8种基本操作时需要满足如下规则： 不允许read和load、store和write操作之一单独出现，即不允许一个变量从主内存读取了但工作内存不接受，或者从工作内存发起回写了但主内存不接受的情况出现。 不允许一个线程丢弃它的最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。 不允许一个线程无原因地，即没有发生过任何assign操作就把数据从线程的工作内存同步回主内存中。 一个新的变量只能在主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量，即对一个变量实施use、store操作之前必须先执行过了assign和load操作。 一个变量在同一个时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。 如果对一个变量执行lock操作，那将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值。 如果一个变量事先没有被lock操作锁定，那就不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定住的变量。 对一个变量执行unlock操作之前，必须先把此变量同步回主内存中。 可见这么多规则相当严谨但又十分繁琐，实践起来非常麻烦。下面介绍一个等效判断原则：先行发生原则。 先行发生原则先行发生原则是Java内存模型中定义的两项操作之间的偏序关系。它是判断数据是否存在竞争、线程是否安全的主要依据。 下面例举一些“天然的”先行发生关系，无须任何同步器协助就已经存在，可以在编码中直接使用。 程序次序规则（Program Order Rule）：在一个线程内，按照控制流顺序，书写在前面的操作先行发生于书写在后面的操作。 管程锁定规则（Monitor Lock Rule）：一个unlock操作先行发生于后面对同一个锁的lock操作。 volatile变量规则（Volatile Variable Rule）：对一个volatile变量的写操作先行发生于后面对这个变量的读操作。 线程启动规则（Thread Start Rule）：Thread对象的start()先行发生于此线程的每一个动作。 线程终止规则（Thread Termination Rule）：线程中的所有操作都先行发生于对此线程的终止检测.可通过Thread.join()结束、Thread.isAlive()的返回值等手段检测到线程已经终止执行。 线程中断规则（Thread Interruption Rule）：对线程interrupt()的调用先行发生于被中断线程的代码检测到中断事件的发生。可通过Thread.interrupted()检测到是否有中断发生。 对象终结规则（Finalizer Rule）：一个对象的初始化完成先行发生于它的finalize()的开始。 传递性（Transitivity）：如果操作A先行发生于操作B，操作B先行发生于操作C，那么操作A一定先行发生于操作C。 原子性、可见性、有序性Java内存模型保证并发过程的原子性、可见性、和有序性的措施： 原子性（Atomicity）：一个操作要么都执行要么都不执行 可直接保证的原子性变量操作有：read、load、assign、use、store和write，因此可认为基本数据类型的访问读写是具备原子性的。 若需要保证更大范围的原子性，可通过更高层次的字节码指令monitorenter和monitorexit来隐式地使用lock和unlock这两个操作，反映到Java代码中就是同步代码块synchronized关键字。 可见性（Visibility）：当一个线程修改了共享变量的值，其他线程能够立即得知这个修改。 通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现。 提供三个关键字保证可见性：volatile能保证新值能立即同步到主内存，且每次使用前立即从主内存刷新；synchronized对一个变量执行unlock操作之前可以先把此变量同步回主内存中；被final修饰的字段在构造器中一旦初始化完成且构造器没有把this的引用传递出去，就可以在其他线程中就能看见final字段的值。 有序性（Ordering）：程序代码按照指令顺序执行。 如果在本线程内观察，所有的操作都是有序的，指“线程内表现为串行的语义”；如果在一个线程中观察另一个线程，所有的操作都是无序的，指“指令重排序”现象和“工作内存与主内存同步延迟”现象。 提供两个关键字保证有序性：volatile 本身就包含了禁止指令重排序的语义；synchronized保证一个变量在同一个时刻只允许一条线程对其进行lock操作，使得持有同一个锁的两个同步块只能串行地进入。 Java与线程线程实现的三种方式 使用内核线程（Kernel-Level Thread,KLT） 定义：直接由操作系统内核支持的线程。 原理：由内核来完成线程切换，内核通过操纵调度器（Scheduler）对线程进行调度，并负责将线程的任务映射到各个处理器上。每个内核线程可以视为内核的一个分身， 这样操作系统就有能力同时处理多件事情。 多线程内核（Multi-Threads Kernel）：支持多线程的内核 轻量级进程（Light Weight Process,LWP）：内核线程的一种高级接口 优点：每个轻量级进程都由一个内核线程支持，因此每个都成为一个独立的调度单元，即使有一个轻量级进程在系统调用中阻塞，也不会影响整个进程继续工作。 缺点：由于基于内核线程实现，所以各种线程操作（创建、析构及同步）都需要进行系统调用，代价相对较高，需要在用户态（User Mode）和内核态（Kernel Mode）中来回切换；另外，一个系统支持轻量级进程的数量是有限的。 一对一线程模型：轻量级进程与内核线程之间1：1的关系，如图所示 使用用户线程（User Thread,UT） 定义：广义上认为一个线程不是内核线程就是用户线程；狭义上认为用户线程指的是完全建立在用户空间的线程库上，而系统内核不能感知线程存在的实现。 优点：由于用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助，甚至可以不需要切换到内核态，所以操作非常快速且低消耗的，且可以支持规模更大的线程数量。 缺点：由于没有系统内核的支援，所有的线程操作都需要用户程序自己处理，线程的创建、切换和调度都是需要考虑的问题，实现较复杂。 一对多的线程模型进程：进程与用户线程之间1：N的关系，如图所示 使用用户线程加轻量级进程混合 定义：既存在用户线程，也存在轻量级进程。 优点：用户线程完全建立在用户空间中，因此用户线程的创建、切换、析构等操作依然廉价，并且可以支持大规模的用户线程并发；操作系统提供支持的轻量级进程作为用户线程和内核线程之间的桥梁，可以使用内核提供的线程调度功能及处理器映射，且用户线程的系统调用要通过轻量级线程来完成，大大降低了整个进程被完全阻塞的风险。 多对多的线程模型：用户线程与轻量级进程的数量比不定，即用户线程与轻量级进程之间N：M的关系，如图所示 那么Java线程的实现是选择哪一种呢？答案是不确定的。操作系统支持怎样的线程模型，在很大程度上决定了Java虚拟机的线程是怎样映射的。线程模型只对线程的并发规模和操作成本产生影响，而对Java程序的编码和运行过程来说，这些差异都是透明的。 Java线程调度的两种方式线程调度：指系统为线程分配处理器使用权的过程。 协同式线程调度（Cooperative Threads-Scheduling） 由线程本身来控制线程的执行时间。线程把自己的工作执行完后，要主动通知系统切换到另外一个线程上。 优点：实现简单；切换操作自己可知，不存在线程同步的问题。 缺点：线程执行时间不可控，假如一个线程编写有问题一直不告知系统进行线程切换，那么程序就会一直被阻塞。 抢占式线程调度（Preemptive Threads-Scheduling） 由系统来分配每个线程的执行时间。 优点：线程执行时间是系统可控的，不存在一个线程导致整个进程阻塞的问题。 可以通过设置线程优先级，优先级越高的线程越容易被系统选择执行。 但是线程优先级并不是太靠谱，一方面因为Java的线程是通过映射到系统的原生线程上来实现的，所以线程调度最终还是取决于操作系统，在一些平台上不同的优先级实际会变得相同；另一方面优先级可能会被系统自行改变。 线程的五种状态在任意一个时间，一个线程只能有且只有其中的一种状态： 新建（New）：线程创建后尚未启动 运行（Runable）：包括正在执行（Running）和等待着CPU为它分配执行时间（Ready）两种 无限期等待（Waiting）：该线程不会被分配CPU执行时间，要等待被其他线程显式地唤醒。以下方法会让线程陷入无限期等待状态： 没有设置Timeout参数的Object.wait() 没有设置Timeout参数的Thread.join() LockSupport.park() 限期等待（Timed Waiting）：该线程不会被分配CPU执行时间，但在一定时间后会被系统自动唤醒。以下方法会让线程进入限期等待状态： Thread.sleep() 设置了Timeout参数的Object.wai() 设置了Timeout参数的Thread.join() LockSupport.parkNanos() LockSupport.parkUntil() 阻塞（Blocked）：线程被阻塞 注意区别： 阻塞状态：在等待获取到一个排他锁，在另外一个线程放弃这个锁的时候发生； 等待状态：在等待一段时间或者唤醒动作的发生，在程序等待进入同步区域的时候发生。 结束（Terminated）：线程已经结束执行 线程状态之间的转换图： 参考简书-厘米姑娘：要点提炼| 理解JVM之内存模型&amp;线程]]></content>
      <categories>
        <category>JVM</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MySql常见问题总结]]></title>
    <url>%2F2019%2F04%2F07%2FMySql%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[简单的总结了下Mysql的知识点 存储索引 索引 缓存 事务 锁机制 存储引擎MyISAMMyISAM是MySQL的默认数据库引擎（5.5版之前），由早期的 ISAM （Indexed Sequential Access Method：有索引的顺序访问方法）所改良。虽然性能极佳，而且提供了大量的特性，包括全文索引、压缩、空间函数等，但MyISAM不支持事务和行级锁，而且最大的缺陷就是崩溃后无法安全恢复。不过，5.5版本之后，MySQL引入了InnoDB（另一种数据库引擎）。 两者有不同的使用场景，比如：MyISAM更适合读密集的表，而InnoDB更适合写密集的的表。 在数据库做主从分离的情况下，经常选择InnoDB作为主库的存储引擎。 MyISAM特点 不支持行锁(MyISAM只有表锁)，读取时对需要读到的所有表加锁，写入时则对表加排他锁； 不支持事务 不支持外键 不支持崩溃后的安全恢复 在表有读取查询的同时，支持往表中插入新纪录 支持BLOB和TEXT的前500个字符索引，支持全文索引 支持延迟更新索引，极大地提升了写入性能 对于不会进行修改的表，支持 压缩表 ，极大地减少了磁盘空间的占用 补充概念 Mysql的行锁和表锁（ 锁是计算机协调多个进程或纯线程并发访问某一资源的机制） 表级锁： 每次操作锁住整张表。开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低； 行级锁： 每次操作锁住一行数据。开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高； InnoDBInnoDB是MySQL的默认数据库引擎（5.5版之后），2006年五月时由甲骨文公司并购。与传统的ISAM与MyISAM相比，InnoDB的最大特色就是支持了ACID兼容的事务（Transaction）功能。 InnoDB特点 支持行锁，采用MVCC来支持高并发，有可能死锁 支持事务 支持外键 支持崩溃后的安全恢复 不支持全文索引 二者的对比与总结对比 count运算上的区别： 因为MyISAM缓存有表meta-data（行数等），因此在做COUNT(*)时对于一个结构很好的查询是不需要消耗多少资源的。而对于InnoDB来说，则没有这种缓存。 是否支持事务和崩溃后的安全恢复： MyISAM 强调的是性能，每次查询具有原子性,其执行数度比InnoDB类型更快，但是不提供事务支持。但是InnoDB 提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。 是否支持外键： MyISAM不支持，而InnoDB支持。 总结MyISAM更适合读密集的表，而InnoDB更适合写密集的的表。 在数据库做主从分离的情况下，经常选择MyISAM作为主库的存储引擎。 一般来说，如果需要事务支持，并且有较高的并发读取频率(MyISAM的表锁的粒度太大，所以当该表写并发量较高时，要等待的查询就会很多了)，InnoDB是不错的选择。如果你的数据量很大（MyISAM支持压缩特性可以减少磁盘的空间占用），而且不需要支持事务时，MyISAM是最好的选择。 对比项 MyISAM InnoDB 主外键 不支持 支持 事务 不支持 支持 行表锁 表锁，不适合高并发 行锁，适合高并发 缓存 只缓存索引，不缓存真实数据 不仅缓存索引，还要缓存真实数据 表空间 小 大 关注点 性能 事务 默认安装 Y Y 索引Mysql索引使用的数据结构主要有BTree索引 和 哈希索引 。对于哈希索引来说，底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引。 Mysql的BTree索引使用的是B数中的B+Tree，但对于主要的两种存储引擎的实现方式是不同的。 MyISAM: B+Tree叶节点的data域存放的是数据记录的地址。在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“非聚簇索引”。 InnoDB: 其数据文件本身就是索引文件。相比MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按B+Tree组织的一个索引结构，树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。这被称为“聚簇索引（或聚集索引）”。而其余的索引都作为辅助索引，辅助索引的data域存储相应记录主键的值而不是地址，这也是和MyISAM不同的地方。在根据主索引搜索时，直接找到key所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。 因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。 查询缓存的使用my.cnf加入以下配置，重启Mysql开启查询缓存 12query_cache_type=1query_cache_size=600000 Mysql执行以下命令也可以开启查询缓存 12set global query_cache_type=1;set global query_cache_size=600000; 如上，开启查询缓存后在同样的查询条件以及数据情况下，会直接在缓存中返回结果。这里的查询条件包括查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息。因此任何两个查询在任何字符上的不同都会导致缓存不命中。此外，如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、Mysql库中的系统表，其查询结果也不会被缓存。 缓存建立之后，Mysql的查询缓存系统会跟踪查询中涉及的每张表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。 缓存虽然能够提升数据库的查询性能，但是缓存同时也带来了额外的开销，每次查询后都要做一次缓存操作，失效后还要销毁。 因此，开启缓存查询要谨慎，尤其对于写密集的应用来说更是如此。如果开启，要注意合理控制缓存空间大小，一般来说其大小设置为几十MB比较合适。此外，还可以通过sql_cache和sql_no_cache来控制某个查询语句是否需要缓存： 1select sql_no_cache count(*) from usr; 事务机制关系性数据库需要遵循ACID规则，具体内容如下： 原子性： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性： 执行事务前后，数据库从一个一致性状态转换到另一个一致性状态。 隔离性： 并发访问数据库时，一个用户的事物不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库 发生故障也不应该对其有任何影响。 为了达到上述事务特性，数据库定义了几种不同的事务隔离级别： READ_UNCOMMITTED（未提交读）: 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读 READ_COMMITTED（提交读）: 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生 REPEATABLE_READ（可重复读）: 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 SERIALIZABLE（串行）: 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。 锁机制与InnoDB锁算法MyISAM和InnoDB存储引擎使用的锁： MyISAM采用表级锁(table-level locking)。 InnoDB支持行级锁(row-level locking)和表级锁,默认为行级锁 表级锁和行级锁对比： 表级锁： Mysql中锁定 粒度最大 的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM和 InnoDB引擎都支持表级锁。 行级锁： Mysql中锁定 粒度最小 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。 详细内容可以参考： Mysql锁机制简单了解一下 InnoDB存储引擎的锁的算法有三种： Record lock：单个行记录上的锁 Gap lock：间隙锁，锁定一个范围，不包括记录本身 Next-key lock：record+gap 锁定一个范围，包含记录本身 相关知识点： innodb对于行的查询使用next-key lock Next-locking keying为了解决Phantom Problem幻读问题 当查询的索引含有唯一属性时，将next-key lock降级为record key Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生 有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock） A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1]]></content>
      <categories>
        <category>MySql</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[快速排序]]></title>
    <url>%2F2019%2F03%2F12%2F%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[本篇简单讲述一下快速排序以及时间复杂度 快速排序快速排序（Quick Sort）是由冒泡排序改进而得的。在冒泡排序过程中，只对相邻的两个记录进行比较，因此每次交换两个相邻记录时只能消除一个逆序。如果能通过两个（不相邻）记录的一次交换，消除多个逆序，则会大大加快排序的速度。快速排序方法中的一次交换可能消除多个逆序。 动画演示图片来源：https://mp.weixin.qq.com/s/vn3KiV-ez79FmbZ36SX9lg 代码实现123456789101112131415161718192021222324252627282930313233343536373839public class QuickSort &#123; public static void quickSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return; &#125; quickSort(arr, 0, arr.length - 1); &#125; private static void quickSort(int[] arr, int l, int r) &#123; if (l &lt; r) &#123; // l == r 则结束递归 // 随机选定一个值与最后一个值交换作为判定值(随机快排) swap(arr, l + (int) (Math.random() * (r - l + 1)), r); int[] p = partition(arr, l, r); quickSort(arr, l, p[0] - 1); // 对 &lt; x 的区域继续排序 quickSort(arr, p[1] + 1, r); // 对 &gt; x 的区域继续排序 &#125; &#125; private static int[] partition(int[] arr, int l, int r) &#123; int less = l - 1; int more = r; while (l &lt; more) &#123; if (arr[l] &lt; arr[r]) &#123; swap(arr, ++less, l++); &#125; else if (arr[l] &gt; arr[r]) &#123; swap(arr, --more, l); &#125; else &#123; l++; &#125; &#125; // 将最后一个值交换到 = x 和 &gt; x 的边界 swap(arr, more, r); // 返回等于区域两个边界的下标值 return new int[] &#123; less + 1, more &#125;; &#125; public static void swap(int[] arr, int i, int j) &#123; int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; &#125;&#125; 快速排序上述代码中swap(arr, l + (int) (Math.random() * (r - l + 1)), r);该行代码随机选取一个值与最后一个值交换作为判断值（枢轴记录），这就是随机排序，是比较常用的快排算法。 经典快排在选取主元的时候，每次都选取最右边的元素。当序列为有序时，会发现划分出来的两个子序列一个里面没有元素，而另一个则只比原来少一个元素。为了避免这种情况，引入一个随机化量来破坏这种有序状态。 但是随机化快排因为要生成随机数，所以有一些性能损失，所以数据规模较小，数据分布均匀时普通快排还是比随机化快排要快些的，不过随着数据规模的上升，随机化快排的性能优势就展现出来了。 时间复杂度平均情况下，快速排序的时间复杂度为$O(nlog_2n)$。 空间复杂度快速排序是递归的，执行时需要有一个栈来存放相应的数据。最大递归调用次数与递归树的深度一致，所以最好情况下的空间复杂度为$O(nlog_2n)$，最坏情况下为O(n)。]]></content>
      <categories>
        <category>排序</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java基础]]></title>
    <url>%2F2019%2F03%2F11%2FJava%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[一些Java基础的总结 转自Github-JavaGuide并做了一些添加和修改 面向对象和面向过程的区别面向过程优点： 性能比面向对象高，因为类调用时需要实例化，开销比较大，比较消耗资源;比如单片机、嵌入式开发、Linux/Unix等一般采用面向过程开发，性能是最重要的因素。 缺点： 没有面向对象易维护、易复用、易扩展 面向对象优点： 易维护、易复用、易扩展，由于面向对象有封装、继承、多态性的特性，可以设计出低耦合的系统，使系统更加灵活、更加易于维护 缺点： 性能比面向过程低 Java 语言有哪些特点 简单易学； 面向对象（封装，继承，多态）； 平台无关性（ Java 虚拟机实现平台无关性）； 可靠性； 安全性； 支持多线程（ C++ 语言没有内置的多线程机制，因此必须调用操作系统的多线程功能来进行多线程程序设计，而 Java 语言却提供了多线程支持）； 支持网络编程并且很方便（ Java 语言诞生本身就是为简化网络编程设计的，因此 Java 语言不仅支持网络编程而且很方便）； 编译与解释并存； 关于 JVM JDK 和 JRE 最详细通俗的解答JVMJava虚拟机（JVM）是运行 Java 字节码的虚拟机。JVM有针对不同系统的特定实现（Windows，Linux，macOS），目的是使用相同的字节码，它们都会给出相同的结果。 什么是字节码?采用字节码的好处是什么? 在 Java 中，JVM可以理解的代码就叫做字节码（即扩展名为 .class 的文件），它不面向任何特定的处理器，只面向虚拟机。Java 语言通过字节码的方式，在一定程度上解决了传统解释型语言执行效率低的问题，同时又保留了解释型语言可移植的特点。所以 Java 程序运行时比较高效，而且，由于字节码并不专对一种特定的机器，因此，Java程序无须重新编译便可在多种不同的计算机上运行。 Java 程序从源代码到运行一般有下面3步： 我们需要格外注意的是 .class-&gt;机器码 这一步。在这一步 jvm 类加载器首先加载字节码文件，然后通过解释器逐行解释执行，这种方式的执行速度会相对比较慢。而且，有些方法和代码块是经常需要被调用的，也就是所谓的热点代码，所以后面引进了 JIT 编译器，JIT 属于运行时编译。当 JIT 编译器完成第一次编译后，其会将字节码对应的机器码保存下来，下次可以直接使用。而我们知道，机器码的运行效率肯定是高于 Java 解释器的。这也解释了我们为什么经常会说 Java 是编译与解释共存的语言。 HotSpot采用了惰性评估(Lazy Evaluation)的做法，根据二八定律，消耗大部分系统资源的只有那一小部分的代码（热点代码），而这也就是JIT所需要编译的部分。JVM会根据代码每次被执行的情况收集信息并相应地做出一些优化，因此执行的次数越多，它的速度就越快。JDK 9引入了一种新的编译模式AOT(Ahead of Time Compilation)，它是直接将字节码编译成机器码，这样就避免了JIT预热等各方面的开销。JDK支持分层编译和AOT协作使用。但是 ，AOT 编译器的编译质量是肯定比不上 JIT 编译器的。 总结：Java虚拟机（JVM）是运行 Java 字节码的虚拟机。JVM有针对不同系统的特定实现（Windows，Linux，macOS），目的是使用相同的字节码，它们都会给出相同的结果。字节码和不同系统的 JVM 实现是 Java 语言“一次编译，随处可以运行”的关键所在。 JDK 和 JREJDK是Java Development Kit，它是功能齐全的Java SDK。它拥有JRE所拥有的一切，还有编译器（javac）和工具（如javadoc和jdb）。它能够创建和编译程序。 JRE 是 Java运行时环境。它是运行已编译 Java 程序所需的所有内容的集合，包括 Java虚拟机（JVM），Java类库，java命令和其他的一些基础构件。但是，它不能用于创建新程序。 如果你只是为了运行一下 Java 程序的话，那么你只需要安装 JRE 就可以了。如果你需要进行一些 Java 编程方面的工作，那么你就需要安装JDK了。但是，这不是绝对的。有时，即使您不打算在计算机上进行任何Java开发，仍然需要安装JDK。例如，如果要使用JSP部署Web应用程序，那么从技术上讲，您只是在应用程序服务器中运行Java程序。那你为什么需要JDK呢？因为应用程序服务器会将 JSP 转换为 Java servlet，并且需要使用 JDK 来编译 servlet。 Oracle JDK 和 OpenJDK 的对比可能在看这个问题之前很多人和我一样并没有接触和使用过 OpenJDK 。那么Oracle和OpenJDK之间是否存在重大差异？下面通过我通过我收集到一些资料对你解答这个被很多人忽视的问题。 对于Java 7，没什么关键的地方。OpenJDK项目主要基于Sun捐赠的HotSpot源代码。此外，OpenJDK被选为Java 7的参考实现，由Oracle工程师维护。关于JVM，JDK，JRE和OpenJDK之间的区别，Oracle博客帖子在2012年有一个更详细的答案： 问：OpenJDK存储库中的源代码与用于构建Oracle JDK的代码之间有什么区别？ 答：非常接近 - 我们的Oracle JDK版本构建过程基于OpenJDK 7构建，只添加了几个部分，例如部署代码，其中包括Oracle的Java插件和Java WebStart的实现，以及一些封闭的源代码派对组件，如图形光栅化器，一些开源的第三方组件，如Rhino，以及一些零碎的东西，如附加文档或第三方字体。展望未来，我们的目的是开z源Oracle JDK的所有部分，除了我们考虑商业功能的部分。 总结： Oracle JDK版本将每三年发布一次，而OpenJDK版本每三个月发布一次； OpenJDK 是一个参考模型并且是完全开源的，而Oracle JDK是OpenJDK的一个实现，并不是完全开源的； Oracle JDK 比 OpenJDK 更稳定。OpenJDK和Oracle JDK的代码几乎相同，但Oracle JDK有更多的类和一些错误修复。因此，如果您想开发企业/商业软件，我建议您选择Oracle JDK，因为它经过了彻底的测试和稳定。某些情况下，有些人提到在使用OpenJDK 可能会遇到了许多应用程序崩溃的问题，但是，只需切换到Oracle JDK就可以解决问题； 在响应性和JVM性能方面，Oracle JDK与OpenJDK相比提供了更好的性能； Oracle JDK不会为即将发布的版本提供长期支持，用户每次都必须通过更新到最新版本获得支持来获取最新版本； Oracle JDK根据二进制代码许可协议获得许可，而OpenJDK根据GPL v2许可获得许可。 Java和C++的区别我知道很多人没学过 C++，但是面试官就是没事喜欢拿咱们 Java 和 C++ 比呀！没办法！！！就算没学过C++，也要记下来！ 都是面向对象的语言，都支持封装、继承和多态 Java 不提供指针来直接访问内存，程序内存更加安全 Java 的类是单继承的，C++ 支持多重继承；虽然 Java 的类不可以多继承，但是接口可以多继承。 Java 有自动内存管理机制，不需要程序员手动释放无用内存 什么是 Java 程序的主类 应用程序和小程序的主类有何不同一个程序中可以有多个类，但只能有一个类是主类。在 Java 应用程序中，这个主类是指包含 main（）方法的类。而在 Java 小程序中，这个主类是一个继承自系统类 JApplet 或 Applet 的子类。应用程序的主类不一定要求是 public 类，但小程序的主类要求必须是 public 类。主类是 Java 程序执行的入口点。 Java 应用程序与小程序之间有那些差别简单说应用程序是从主线程启动(也就是 main() 方法)。applet 小程序没有main方法，主要是嵌在浏览器页面上运行(调用init()线程或者run()来启动)，嵌入浏览器这点跟 flash 的小游戏类似。 字符型常量和字符串常量的区别 形式上: 字符常量是单引号引起的一个字符 字符串常量是双引号引起的若干个字符 含义上: 字符常量相当于一个整形值( ASCII 值),可以参加表达式运算 字符串常量代表一个地址值(该字符串在内存中存放位置) 占内存大小 字符常量只占2个字节 字符串常量占若干个字节(至少一个字符结束标志) (注意： char在Java中占两个字节) java编程思想第四版：2.2.2节 构造器 Constructor 是否可被 override在讲继承的时候我们就知道父类的私有属性和构造方法并不能被继承，所以 Constructor 也就不能被 override（重写）,但是可以 overload（重载）,所以你可以看到一个类中有多个构造函数的情况。 重载和重写的区别重载： 发生在同一个类中，方法名必须相同，参数类型不同、个数不同、顺序不同，方法返回值和访问修饰符可以不同，发生在编译时。 重写： 发生在父子类中，方法名、参数列表必须相同，返回值范围小于等于父类，抛出的异常范围小于等于父类，访问修饰符范围大于等于父类；如果父类方法访问修饰符为 private 则子类就不能重写该方法。 Java 面向对象编程三大特性: 封装 继承 多态封装封装把一个对象的属性私有化，同时提供一些可以被外界访问的属性的方法，如果属性不想被外界访问，我们大可不必提供方法给外界访问。但是如果一个类没有提供给外界访问的方法，那么这个类也没有什么意义了。 继承继承是使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。通过使用继承我们能够非常方便地复用以前的代码。 关于继承如下 3 点请记住： 子类拥有父类非 private 的属性和方法。 子类可以拥有自己属性和方法，即子类可以对父类进行扩展。 子类可以用自己的方式实现父类的方法。（以后介绍）。 多态所谓多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量到底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。 在Java中有两种形式可以实现多态：继承（多个子类对同一方法的重写）和接口（实现接口并覆盖接口中同一方法）。 String StringBuffer 和 StringBuilder 的区别是什么 String 为什么是不可变的可变性 简单的来说：String 类中使用 final 关键字字符数组保存字符串，private final char value[]，所以 String 对象是不可变的。而StringBuilder 与 StringBuffer 都继承自 AbstractStringBuilder 类，在 AbstractStringBuilder 中也是使用字符数组保存字符串char[]value 但是没有用 final 关键字修饰，所以这两种对象都是可变的。 StringBuilder 与 StringBuffer 的构造方法都是调用父类构造方法也就是 AbstractStringBuilder 实现的，大家可以自行查阅源码。 AbstractStringBuilder.java 123456789abstract class AbstractStringBuilder implements Appendable, CharSequence &#123; char[] value; int count; AbstractStringBuilder() &#123; &#125; AbstractStringBuilder(int capacity) &#123; value = new char[capacity]; &#125;&#125; 线程安全性 String 中的对象是不可变的，也就可以理解为常量，线程安全。AbstractStringBuilder 是 StringBuilder 与 StringBuffer 的公共父类，定义了一些字符串的基本操作，如 expandCapacity、append、insert、indexOf 等公共方法。StringBuffer 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。StringBuilder 并没有对方法进行加同步锁，所以是非线程安全的。 性能 每次对 String 类型进行改变的时候，都会生成一个新的 String 对象，然后将指针指向新的 String 对象。StringBuffer 每次都会对 StringBuffer 对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用 StringBuilder 相比使用 StringBuffer 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。 对于三者使用的总结： 操作少量的数据 = String 单线程操作字符串缓冲区下操作大量数据 = StringBuilder 多线程操作字符串缓冲区下操作大量数据 = StringBuffer Java支持的数据类型有哪些？ 自动装箱与拆箱基本数据类型： 整数值型：byte,short,int,long, 字符型：char 浮点类型：float,double 布尔型：boolean 整数默认int型，小数默认是double型。Float和long类型的必须加后缀。 首先知道String是引用类型不是基本类型，引用类型声明的变量是指该变量在内存中实际存储的是一个引用地址，实体在堆中。引用类型包括类、接口、数组等。String类还是final修饰的。 而包装类就属于引用类型，自动装箱和拆箱就是基本类型和引用类型之间的转换，至于为什么要转换，因为基本类型转换为引用类型后，就可以new对象，从而调用包装类中封装好的方法进行基本类型之间的转换或者toString（当然用类名直接调用也可以，便于一眼看出该方法是静态的），还有就是如果集合中想存放基本类型，泛型的限定类型只能是对应的包装类型。 装箱：将基本类型用它们对应的引用类型包装起来； 拆箱：将包装类型转换为基本数据类型； ”static”关键字是什么意思？Java中是否可以覆盖(override)一个private或者是static的方法？Static表示静态的意思，可用于修饰成员变量和成员函数，被静态修饰的成员函数只能访问静态成员，不可以访问非静态成员。静态是随着类的加载而加载的，因此可以直接用类进行访问。 重写是子类中的方法和子类继承的父类中的方法一样（函数名，参数，参数类型，反回值类型），但是子类中的访问权限要不低于父类中的访问权限。重写的前提是必须要继承，private修饰不支持继承，因此被私有的方法不可以被重写。静态方法形式上可以被重写，即子类中可以重写父类中静态的方法。但是实际上从内存的角度上静态方法不可以被重写。 在 Java 中定义一个不做事且没有参数的构造方法的作用 Java 程序在执行子类的构造方法之前，如果没有用 super() 来调用父类特定的构造方法，则会调用父类中“没有参数的构造方法”。因此，如果父类中只定义了有参数的构造方法，而在子类的构造方法中又没有用 super() 来调用父类中特定的构造方法，则编译时将发生错误，因为 Java 程序在父类中找不到没有参数的构造方法可供执行。解决办法是在父类里加上一个不做事且没有参数的构造方法。 Java中的方法重写(Overriding)和方法重载(Overload)是什么意思？方法重写的原则： 重写方法的方法名称、参数列表必须与原方法的相同，返回类型可以相同也可以是原类型的子类型(从Java SE5开始支持)。 重写方法不能比原方法访问性差（即访问权限不允许缩小）。 重写方法不能比原方法抛出更多的异常。 被重写的方法不能是final类型，因为final修饰的方法是无法重写的。 被重写的方法不能为private，否则在其子类中只是新定义了一个方法，并没有对其进行重写。 被重写的方法不能为static。如果父类中的方法为静态的，而子类中的方法不是静态的，但是两个方法除了这一点外其他都满足重写条件，那么会发生编译错误；反之亦然。即使父类和子类中的方法都是静态的，并且满足重写条件，但是仍然不会发生重写，因为静态方法是在编译的时候把静态方法和类的引用类型进行匹配。 重写是发生在运行时的，因为编译期编译器不知道并且没办法确定该去调用哪个方法，JVM会在代码运行的时候作出决定。 方法重载的原则： 方法名称必须相同。 参数列表必须不同（个数不同、或类型不同、参数类型排列顺序不同等）。 方法的返回类型可以相同也可以不相同。 仅仅返回类型不同不足以成为方法的重载。 重载是发生在编译时的，因为编译器可以根据参数的类型来选择使用哪个方法。 重写和重载的不同： 方法重写要求参数列表必须一致，而方法重载要求参数列表必须不一致。 方法重写要求返回类型必须一致(或为其子类型)，方法重载对此没有要求。 方法重写只能用于子类重写父类的方法，方法重载用于同一个类中的所有方法。 方法重写对方法的访问权限和抛出的异常有特殊的要求，而方法重载在这方面没有任何限制。 父类的一个方法只能被子类重写一次，而一个方法可以在所有的类中可以被重载多次。 重载是编译时多态，重写是运行时多态。 import java和javax有什么区别刚开始的时候 JavaAPI 所必需的包是 java 开头的包，javax 当时只是扩展 API 包来说使用。然而随着时间的推移，javax 逐渐的扩展成为 Java API 的组成部分。但是，将扩展从 javax 包移动到 java 包将是太麻烦了，最终会破坏一堆现有的代码。因此，最终决定 javax 包将成为标准API的一部分。 所以，实际上java和javax没有区别。这都是一个名字。 关于 final 关键字的一些总结final关键字主要用在三个地方：变量、方法、类。 对于一个final变量，如果是基本数据类型的变量，则其数值一旦在初始化之后便不能更改；如果是引用类型的变量，则在对其初始化之后便不能再让其指向另一个对象。 当用final修饰一个类时，表明这个类不能被继承。final类中的所有成员方法都会被隐式地指定为final方法。 使用final方法的原因有两个。第一个原因是把方法锁定，以防任何继承类修改它的含义；第二个原因是效率。在早期的Java实现版本中，会将final方法转为内嵌调用。但是如果方法过于庞大，可能看不到内嵌调用带来的任何性能提升（现在的Java版本已经不需要使用final方法进行这些优化了）。类中所有的private方法都隐式地指定为final。 接口和抽象类的区别是什么 接口的方法默认是 public，所有方法在接口中不能有实现(Java 8 开始接口方法可以有默认实现），抽象类可以有非抽象的方法 接口中的实例变量默认是 final 类型的，而抽象类中则不一定 一个类可以实现多个接口，但最多只能实现一个抽象类 一个类实现接口的话要实现接口的所有方法，而抽象类不一定 接口不能用 new 实例化，但可以声明，但是必须引用一个实现该接口的对象 从设计层面来说，抽象是对类的抽象，是一种模板设计，接口是行为的抽象，是一种行为的规范。 备注:在JDK8中，接口也可以定义静态方法，可以直接用接口名调用。实现类和实现是不可以调用的。如果同时实现两个接口，接口中定义了一样的默认方法，必须重写，不然会报错。(详见issue:https://github.com/Snailclimb/JavaGuide/issues/146) 成员变量与局部变量的区别有那些 从语法形式上，看成员变量是属于类的，而局部变量是在方法中定义的变量或是方法的参数；成员变量可以被 public,private,static 等修饰符所修饰，而局部变量不能被访问控制修饰符及 static 所修饰；但是，成员变量和局部变量都能被 final 所修饰； 从变量在内存中的存储方式来看:如果成员变量是使用static修饰的，那么这个成员变量是属于类的，如果没有使用使用static修饰，这个成员变量是属于实例的。而对象存在于堆内存，局部变量存在于栈内存 从变量在内存中的生存时间上看:成员变量是对象的一部分，它随着对象的创建而存在，而局部变量随着方法的调用而自动消失。 成员变量如果没有被赋初值:则会自动以类型的默认值而赋值（一种情况例外被 final 修饰的成员变量也必须显示地赋值）；而局部变量则不会自动赋值。 创建一个对象用什么运算符?对象实体与对象引用有何不同?new运算符，new创建对象实例（对象实例在堆内存中），对象引用指向对象实例（对象引用存放在栈内存中）。一个对象引用可以指向0个或1个对象（一根绳子可以不系气球，也可以系一个气球）;一个对象可以有n个引用指向它（可以用n条绳子系住一个气球）。 什么是方法的返回值?返回值在类的方法里的作用是什么?方法的返回值是指我们获取到的某个方法体中的代码执行后产生的结果！（前提是该方法可能产生结果）。返回值的作用:接收出结果，使得它可以用于其他的操作！ 一个类的构造方法的作用是什么 若一个类没有声明构造方法,该程序能正确执行吗 ?为什么?主要作用是完成对类对象的初始化工作。可以执行。因为一个类即使没有声明构造方法也会有默认的不带参数的构造方法。 构造方法有哪些特性 名字与类名相同； 没有返回值，但不能用void声明构造函数； 生成类的对象时自动执行，无需调用。 静态方法和实例方法有何不同 在外部调用静态方法时，可以使用”类名.方法名”的方式，也可以使用”对象名.方法名”的方式。而实例方法只有后面这种方式。也就是说，调用静态方法可以无需创建对象。 静态方法在访问本类的成员时，只允许访问静态成员（即静态成员变量和静态方法），而不允许访问实例成员变量和实例方法；实例方法则无此限制. 对象的相等与指向他们的引用相等,两者有什么不同?对象的相等，比的是内存中存放的内容是否相等。而引用相等，比较的是他们指向的内存地址是否相等。 在调用子类构造方法之前会先调用父类没有参数的构造方法,其目的是?帮助子类做初始化工作。 继承和多态类的 复用有两种方式：组成(has-a)和继承(is-a) 1）组成就是在新的类中直接创建旧类的对象，这里我们复用的只是代码的功能而不是它的形式。 2）继承是在原有的类的基础上建立一个新类，新类具有旧类的形式，但也加入了一些新的特性。 继承：指一个新的类继承原有类的基本特性，并增加了新的特性。（Java不允许多继承，而C++可以） 多态性： 指允许不同类的对象对同一消息做出响应。即同一消息可以根据发送对象的不同而采用多种不同的行为方式。 1）多态存在的三个必要条件 ①要有继承 ②要有重写 ③父类引用指向子类对象（向上转型） 2）实现多态性的三种形式 ①方法的重载 ②通过继承机制而产生方法覆盖 ③通过接口实现方法覆盖 3）多态的分类 多态分为编译时多态和运行时多态。其中编译 时多态是静态的，主要是指方法的重载，它是根据参数列表的不同来区分不同的函数，通过编译之后会变成两个不同的函数，在运行时谈不上多态。而运行时多态是动态的，它是通过动态绑定来实现的，也就是我们平常所说的多态性。 == 与 equals的区别== : 它的作用是判断两个对象的地址是不是相等。即，判断两个对象是不是同一个对象。(基本数据类型==比较的是值，引用数据类型==比较的是内存地址) equals() : 它的作用也是判断两个对象是否相等。但它一般有两种使用情况： 情况1：类没有覆盖 equals() 方法。则通过 equals() 比较该类的两个对象时，等价于通过“==”比较这两个对象。 情况2：类覆盖了 equals() 方法。一般，我们都覆盖 equals() 方法来两个对象的内容相等；若它们的内容相等，则返回 true (即，认为这两个对象相等)。 举个例子： 1234567891011121314151617public class test1 &#123; public static void main(String[] args) &#123; String a = new String(&quot;ab&quot;); // a 为一个引用 String b = new String(&quot;ab&quot;); // b为另一个引用,对象的内容一样 String aa = &quot;ab&quot;; // 放在常量池中 String bb = &quot;ab&quot;; // 从常量池中查找 if (aa == bb) // true System.out.println(&quot;aa==bb&quot;); if (a == b) // false，非同一对象 System.out.println(&quot;a==b&quot;); if (a.equals(b)) // true System.out.println(&quot;aEQb&quot;); if (42 == 42.0) &#123; // true System.out.println(&quot;true&quot;); &#125; &#125;&#125; 说明： String 中的 equals 方法是被重写过的，因为 object 的 equals 方法是比较的对象的内存地址，而 String 的 equals 方法比较的是对象的值。 当创建 String 类型的对象时，虚拟机会在常量池中查找有没有已经存在的值和要创建的值相同的对象，如果有就把它赋给当前引用。如果没有就在常量池中重新创建一个 String 对象。 hashCode 与 equals面试官可能会问你：“你重写过 hashcode 和 equals 么，为什么重写equals时必须重写hashCode方法？” hashCode（）介绍hashCode() 的作用是获取哈希码，也称为散列码；它实际上是返回一个int整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。hashCode() 定义在JDK的Object.java中，这就意味着Java中的任何类都包含有hashCode() 函数。 散列表存储的是键值对(key-value)，它的特点是：能根据“键”快速的检索出对应的“值”。这其中就利用到了散列码！（可以快速找到所需要的对象） 为什么要有 hashCode我们以“HashSet 如何检查重复”为例子来说明为什么要有 hashCode： 当你把对象加入 HashSet 时，HashSet 会先计算对象的 hashcode 值来判断对象加入的位置，同时也会与其他已经加入的对象的 hashcode 值作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用 equals（）方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。（摘自我的Java启蒙书《Head first java》第二版）。这样我们就大大减少了 equals 的次数，相应就大大提高了执行速度。 hashCode（）与equals（）的相关规定 如果两个对象相等，则hashcode一定也是相同的 两个对象相等,对两个对象分别调用equals方法都返回true 两个对象有相同的hashcode值，它们也不一定是相等的 因此，equals 方法被覆盖过，则 hashCode 方法也必须被覆盖 hashCode() 的默认行为是对堆上的对象产生独特值。如果没有重写 hashCode()，则该 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据） 为什么Java中只有值传递为什么Java中只有值传递？ Java集合类框架的基本接口有哪些？总共有两大接口：Collection 和Map ，一个元素集合，一个是键值对集合； 其中List和Set接口继承了Collection接口，一个是有序元素集合，一个是无序元素集合； 而ArrayList和 LinkedList 实现了List接口，HashSet实现了Set接口，这几个都比较常用； HashMap 和HashTable实现了Map接口，并且HashTable是线程安全的，但是HashMap性能更好； java.util.Collection [I]1234567891011121314151617|—java.util.List [I] |—java.util.ArrayList [C] |—java.util.LinkedList [C] |—java.util.Vector [C] |—java.util.Stack [C]|—java.util.Set [I] |—java.util.HashSet [C] |—java.util.SortedSet [I] |—java.util.TreeSet [C] java.util.Map [I]1234567891011|—java.util.SortedMap [I] |—java.util.TreeMap [C]|—java.util.Hashtable [C]|—java.util.HashMap [C] |—java.util.LinkedHashMap [C]|—java.util.WeakHashMap [C] 为什么集合类没有实现Cloneable和Serializable接口？克隆(cloning)或者是序列化(serialization)的语义和含义是跟具体的实现相关的。因此，应该由集合类的具体实现来决定如何被克隆或者是序列化。实现Serializable序列化的作用将对象的状态保存在存储媒体中以便可以在以后重写创建出完全相同的副本；按值将对象从一个从一个应用程序域发向另一个应用程序域。实现 Serializable接口的作用就是可以把对象存到字节流，然后可以恢复。所以你想如果你的对象没有序列化，怎么才能进行网络传输呢？要网络传输就得转为字节流，所以在分布式应用中，你就得实现序列化。如果你不需要分布式应用，那就没必要实现实现序列化。 什么是迭代器(Iterator)？迭代器是一种设计模式，它是一个对象，它可以遍历并选择序列中的对象，而开发人员不需要了解该序列的底层结构。迭代器通常被称为“轻量级”对象，因为创建它的代价小。 Java中的Iterator功能比较简单，并且只能单向移动： (1) 使用方法iterator()要求容器返回一个Iterator。第一次调用Iterator的next()方法时，它返回序列的第一个元素。注意：iterator()方法是java.lang.Iterable接口,被Collection继承。 (2) 使用next()获得序列中的下一个元素。 (3) 使用hasNext()检查序列中是否还有元素。 (4) 使用remove()将迭代器新返回的元素删除。 Iterator是Java迭代器最简单的实现，为List设计的ListIterator具有更多的功能，它可以从两个方向遍历List，也可以从List中插入和删除元素。 Iterator和ListIterator的区别是什么？我们在使用List,Set的时候,为了实现对其数据的遍历,我们经常使用到了Iterator(迭代器)。 使用迭代器，你不需要干涉其遍历的过程，只需要每次取出一个你想要的数据进行处理就可以了。但是在使用的时候也是有不同的。 List和Set都有iterator()来取得其迭代器。对List来说，你也可以通过listIterator()取得其迭代器，两种迭代器在有些时候是不能通用的，Iterator和ListIterator主要区别在以下方面： ListIterator有add()方法，可以向List中添加对象，而Iterator不能 ListIterator和Iterator都有hasNext()和next()方法，可以实现顺序向后遍历，但是ListIterator有hasPrevious()和previous()方法，可以实现逆向（顺序向前）遍历。Iterator就不可以。 ListIterator可以定位当前的索引位置，nextIndex()和previousIndex()可以实现。Iterator没有此功能。 都可实现删除对象，但是ListIterator可以实现对象的修改，set()方法可以实现。Iierator仅能遍历，不能修改。 因为ListIterator的这些功能，可以实现对LinkedList等List数据结构的操作。 其实,数组对象也可以用迭代器来实现。 org.apache.commons.collections.iterators.ArrayIterator就可以实现此功能。 一般情况下，我们使用Iterator就可以了，如果你需要进行记录的前后反复检索的话，你就可以使用ListIterator来扩展你的功能，（有点象JDBC中的滚动结果集）。 ListIterator是一个双向迭代器。ListIterator没有当前元素，它的当前游标是位于调用next()和previsous()返回的元素之间。不过下面举的例子有点问题：下面的例子是n+1个元素。如果有n个元素，那么游标索引就是0…n共n+1个。 注意：romove和set方法不是针对当前游标的操作，而是针对最后一次的next()或者previous()调用Iterator，ListIterator 简述线程,程序,进程的基本概念.以及他们之间关系是什么?线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享同一块内存空间和一组系统资源，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。 程序是含有指令和数据的文件，被存储在磁盘或其他的数据存储设备中，也就是说程序是静态的代码。 进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。简单来说，一个进程就是一个执行中的程序，它在计算机中一个指令接着一个指令地执行着，同时，每个进程还占有某些系统资源如CPU时间，内存空间，文件，文件，输入输出设备的使用权等等。换句话说，当程序在执行时，将会被操作系统载入内存中。线程是进程划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。从另一角度来说，进程属于操作系统的范畴，主要是同一段时间内，可以同时执行一个以上的程序，而线程则是在同一程序内几乎同时执行一个以上的程序段。 进程和线程的区别 进程是运行中的程序，线程是进程的内部的一个执行序列 进程是资源分配的单元，线程是执行行单元 进程间切换代价大，线程间切换代价小 进程拥有资源多，线程拥有资源少 多个线程共享进程的资源 创建线程有哪几种方式？①继承Thread类（真正意义上的线程类），是Runnable接口的实现。 ②实现Runnable接口，并重写里面的run方法。 ③使用Executor框架创建线程池。Executor框架是juc里提供的线程池的实现。 调用线程的start()：启动此线程；调用相应的run()方法 继承于Thread类的线程类，可以直接调用start方法启动线程（使用static也可以实现资源共享）.一个线程（对象）只能够执行一次start()，而且不能通过Thread实现类对象的run()去启动一个线程。 实现Runnable接口的类需要再次用Thread类包装后才能调用start方法。（三个Thread对象包装一个类对象，就实现了资源共享）。 线程的使用的话，注意锁和同步的使用。（多线程访问共享资源容易出现线程安全问题） 一般情况下，常见的是第二种。 Runnable接口有如下好处： *①避免点继承的局限，一个类可以继承多个接口。 *②适合于资源的共享 /* Thread的常用方法： 1.start()：启动线程并执行相应的run()方法 2.run():子线程要执行的代码放入run()方法中 3.currentThread()：静态的，调取当前的线程 4.getName():获取此线程的名字 5.setName():设置此线程的名字 6.yield():调用此方法的线程释放当前CPU的执行权（很可能自己再次抢到资源） 7.join():在A线程中调用B线程的join()方法，表示：当执行到此方法，A线程停止执行，直至B线程执行完毕， A线程再接着join()之后的代码执行 8.isAlive():判断当前线程是否还存活 9.sleep(long l):显式的让当前线程睡眠l毫秒 (只能捕获异常，因为父类run方法没有抛异常) 10.线程通信（方法在Object类中）：wait() notify() notifyAll() *设置线程的优先级（非绝对，只是相对几率大些） getPriority()：返回线程优先值 setPriority(int newPriority)：改变线程的优先级 */ 线程有哪些基本状态?Java 线程在运行的生命周期中的指定时刻只可能处于下面6种不同状态的其中一个状态（图源《Java 并发编程艺术》4.1.4节）。 线程在生命周期中并不是固定处于某一个状态而是随着代码的执行在不同状态之间切换。Java 线程状态变迁如下图所示（图源《Java 并发编程艺术》4.1.4节）： 由上图可以看出： 线程创建之后它将处于 NEW（新建） 状态，调用 start() 方法后开始运行，线程这时候处于 READY（可运行） 状态。可运行状态的线程获得了 cpu 时间片（timeslice）后就处于 RUNNING（运行） 状态。 操作系统隐藏 Java虚拟机（JVM）中的 RUNNABLE 和 RUNNING 状态，它只能看到 RUNNABLE 状态（图源：HowToDoInJava：Java Thread Life Cycle and Thread States），所以 Java 系统一般将这两个状态统称为 RUNNABLE（运行中） 状态 。 当线程执行 wait()方法之后，线程进入 WAITING（等待）状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而 TIME_WAITING(超时等待) 状态相当于在等待状态的基础上增加了超时限制，比如通过 sleep（long millis）方法或 wait（long millis）方法可以将 Java 线程置于 TIMED WAITING 状态。当超时时间到达后 Java 线程将会返回到 RUNNABLE 状态。当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到 BLOCKED（阻塞） 状态。线程在执行 Runnable 的run()方法之后将会进入到 TERMINATED（终止） 状态。 同步方法和同步代码块的区别是什么？为何要使用同步？ java允许多线程并发控制，当多个线程同时操作一个可共享的资源变量时（如数据的增删改查）， 将会导致数据不准确，相互之间产生冲突，因此加入同步锁以避免在该线程没有完成操作之前，被其他线程的调用， 从而保证了该变量的唯一性和准确性。 1.同步方法 即有synchronized关键字修饰的方法。 由于java的每个对象都有一个内置锁，当用此关键字修饰方法时， 内置锁会保护整个方法。在调用该方法前，需要获得内置锁，否则就处于阻塞状态。 12代码如： public synchronized void save()&#123;&#125; 注： synchronized关键字也可以修饰静态方法，此时如果调用该静态方法，将会锁住整个类 2.同步代码块 即有synchronized关键字修饰的语句块。 被该关键字修饰的语句块会自动被加上内置锁，从而实现同步 123456代码如： synchronized(object)&#123; &#125;注：同步是一种高开销的操作，因此应该尽量减少同步的内容。 通常没有必要同步整个方法，使用synchronized代码块同步关键代码即可。 3.使用特殊域变量(volatile)实现线程同步 123456a.volatile关键字为域变量的访问提供了一种免锁机制， b.使用volatile修饰域相当于告诉虚拟机该域可能会被其他线程更新， c.因此每次使用该域就要重新计算，而不是使用寄存器中的值 d.volatile不会提供任何原子操作，它也不能用来修饰final类型的变量 注：volatile 只能保证可见性和有序，无法保证原子性操作 4.使用重入锁实现线程同步 12345678910在JavaSE5.0中新增了一个java.util.concurrent包来支持同步。 ReentrantLock类是可重入、互斥、实现了Lock接口的锁， 它与使用synchronized方法和快具有相同的基本行为和语义，并且扩展了其能力ReenreantLock类的常用方法有： ReentrantLock() : 创建一个ReentrantLock实例 lock() : 获得锁 unlock() : 释放锁 注：ReentrantLock()还有一个可以创建公平锁的构造方法，但由于能大幅度降低程序运行效率，不推荐使用 注：关于Lock对象和synchronized关键字的选择： a.最好两个都不用，使用一种java.util.concurrent包提供的机制， 能够帮助用户处理所有与锁相关的代码。 b.如果synchronized关键字能满足用户的需求，就用synchronized，因为它能简化代码 c.如果需要更高级的功能，就用ReentrantLock类，此时要注意及时释放锁，否则会出现死锁，通常在finally代码释放锁 5.使用局部变量实现线程同步 如果使用ThreadLocal管理变量，则每一个使用该变量的线程都获得该变量的副本， 副本之间相互独立，这样每一个线程都可以随意修改自己的变量副本，而不会对其他线程产生影响。 123456ThreadLocal 类的常用方法ThreadLocal() : 创建一个线程本地变量 get() : 返回此线程局部变量的当前线程副本中的值 initialValue() : 返回此线程局部变量的当前线程的&quot;初始值&quot; set(T value) : 将此线程局部变量的当前线程副本中的值设置为value 注：ThreadLocal与同步机制 a.ThreadLocal与同步机制都是为了解决多线程中相同变量的访问冲突问题。 b.前者采用以”空间换时间”的方法，后者采用以”时间换空间”的方式 Java 中的异常处理Java异常类层次结构图在 Java 中，所有的异常都有一个共同的祖先java.lang包中的 Throwable类。Throwable： 有两个重要的子类：Exception（异常） 和 Error（错误） ，二者都是 Java 异常处理的重要子类，各自都包含大量子类。 Error（错误）:是程序无法处理的错误，表示运行应用程序中较严重问题。大多数错误与代码编写者执行的操作无关，而表示代码运行时 JVM（Java 虚拟机）出现的问题。例如，Java虚拟机运行错误（Virtual MachineError），当 JVM 不再有继续执行操作所需的内存资源时，将出现 OutOfMemoryError。这些异常发生时，Java虚拟机（JVM）一般会选择线程终止。 这些错误表示故障发生于虚拟机自身、或者发生在虚拟机试图执行应用时，如Java虚拟机运行错误（Virtual MachineError）、类定义错误（NoClassDefFoundError）等。这些错误是不可查的，因为它们在应用程序的控制和处理能力之 外，而且绝大多数是程序运行时不允许出现的状况。对于设计合理的应用程序来说，即使确实发生了错误，本质上也不应该试图去处理它所引起的异常状况。在 Java中，错误通过Error的子类描述。 Exception（异常）:是程序本身可以处理的异常。Exception 类有一个重要的子类 RuntimeException。RuntimeException 异常由Java虚拟机抛出。NullPointerException（要访问的变量没有引用任何对象时，抛出该异常）、ArithmeticException（算术运算异常，一个整数除以0时，抛出该异常）和 ArrayIndexOutOfBoundsException （下标越界异常）。 注意：异常和错误的区别：异常能被程序本身可以处理，错误是无法处理。 Throwable类常用方法 public string getMessage():返回异常发生时的详细信息 public string toString():返回异常发生时的简要描述 public string getLocalizedMessage():返回异常对象的本地化信息。使用Throwable的子类覆盖这个方法，可以声称本地化信息。如果子类没有覆盖该方法，则该方法返回的信息与getMessage（）返回的结果相同 public void printStackTrace():在控制台上打印Throwable对象封装的异常信息 异常处理总结 try 块：用于捕获异常。其后可接零个或多个catch块，如果没有catch块，则必须跟一个finally块。 catch 块：用于处理try捕获到的异常。 finally 块：无论是否捕获或处理异常，finally块里的语句都会被执行。当在try块或catch块中遇到return语句时，finally语句块将在方法返回之前被执行。 在以下4种特殊情况下，finally块不会被执行： 在finally语句块第一行发生了异常。 因为在其他行，finally块还是会得到执行 在前面的代码中用了System.exit(int)已退出程序。 exit是带参函数 ；若该语句在异常语句之后，finally会执行 程序所在的线程死亡。 关闭CPU。 下面这部分内容来自issue:https://github.com/Snailclimb/JavaGuide/issues/190。 关于返回值： 如果try语句里有return，返回的是try语句块中变量值。详细执行过程如下： 如果有返回值，就把返回值保存到局部变量中； 执行jsr指令跳到finally语句里执行； 执行完finally语句后，返回之前保存在局部变量表里的值。 如果try，finally语句里均有return，忽略try的return，而使用finally的return. Java序列化中如果有些字段不想进行序列化 怎么办对于不想进行序列化的变量，使用transient关键字修饰。 transient关键字的作用是：阻止实例中那些用此关键字修饰的的变量序列化；当对象被反序列化时，被transient修饰的变量值不会被持久化和恢复。transient只能修饰变量，不能修饰类和方法。 获取用键盘输入常用的的两种方法方法1：通过 Scanner 123Scanner input = new Scanner(System.in);String s = input.nextLine();input.close(); 方法2：通过 BufferedReader 12BufferedReader input = new BufferedReader(new InputStreamReader(System.in)); String s = input.readLine(); 参考 https://stackoverflow.com/questions/1906445/what-is-the-difference-between-jdk-and-jre https://www.educba.com/oracle-vs-openjdk/ https://stackoverflow.com/questions/22358071/differences-between-oracle-jdk-and-openjdk?answertab=active#tab-top]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[堆排序]]></title>
    <url>%2F2019%2F03%2F11%2F%E5%A0%86%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[本篇简单讲述一下堆和堆排序 堆堆分为堆分为最大堆和最小堆，其实就是完全二叉树，是一种经过排序的完全二叉树。 最大堆要求节点的元素都要不小于其孩子 最小堆要求节点元素都不大于其左右孩子 两者对左右孩子的大小关系不做任何要求 完全二叉树若设二叉树的深度为h，除第 h 层外，其它各层 (1～h-1) 的结点数都达到最大个数，第 h 层所有的结点都连续集中在最左边，这就是完全二叉树。 完全二叉树是由满二叉树而引出来的。对于深度为K的，有n个结点的二叉树，当且仅当其每一个结点都与深度为K的满二叉树中编号从1至n的结点一一对应时称之为完全二叉树。 一棵二叉树至多只有最下面的两层上的结点的度数可以小于2，并且最下层上的结点都集中在该层最左边的若干位置上，则此二叉树成为完全二叉树。 特点：叶子结点只可能在最大的两层上出现,对任意结点，若其右分支下的子孙最大层次为L，则其左分支下的子孙的最大层次必为L 或 L+1。 堆排序堆排序是一种树形选择排序，在排序过程中，将待排序多的记录r[1..n]看成是一棵完全二叉树的顺序存储结构，利用完全二叉树中双亲结点和孩子结点之间的内在关系，在当前无序的序列中选择关键字最大（或最小）的记录。 基本思想 将初始待排序关键字序列(R1,R2….Rn)构建成大顶堆，此堆为初始的无序区。 将堆顶元素R[1]与最后一个元素R[n]交换，此时得到新的无序区(R1,R2,……Rn-1)和新的有序区(Rn)。 由于交换后新的堆顶R[1]可能违反堆的性质，因此需要对当前无序区(R1,R2,……Rn-1)调整为新堆，然后再次将R[1]与无序区最后一个元素交换，得到新的无序区(R1,R2….Rn-2)和新的有序区(Rn-1,Rn)。不断重复此过程直到有序区的元素个数为n-1，则整个排序过程完成。 堆排序过程的核心就是先初始化大根堆，将最大数（堆顶）放到堆的最后一个，堆长度-1，继续调整成大根堆，直至有序序列为length-1。 注意： 在初始化大跟堆时，是从最后一个有子节点开始向上调整到最大堆。而堆顶元素与堆最后一个数交换后，需要再次调整为大根堆 ，此时是从上往下调整的。 不管是初始大顶堆的从下往上调整，还是堆顶堆尾元素交换，每次调整都是从父节点、左孩子节点、右孩子节点三者中选择最大者跟父节点进行交换，交换之后都可能造成被交换的孩子节点不满足堆的性质，因此每次交换之后要重新对被交换的孩子节点进行调整。 动画演示图片来源：https://mp.weixin.qq.com/s/vn3KiV-ez79FmbZ36SX9lg 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class HeapSort &#123; public static void heapSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return; &#125; for (int i = 0; i &lt; arr.length; i++) &#123; heapInsert(arr, i); &#125; int size = arr.length; // 将堆顶元素调整到最后 swap(arr, 0, --size); //继续调整大根堆 while (size &gt; 0) &#123; heapify(arr, 0, size); swap(arr, 0, --size); &#125; &#125; // 建立大根堆 public static void heapInsert(int[] arr, int index) &#123; while (arr[index] &gt; arr[(index - 1) / 2])&#123; // (index -1) / 2 表示 index 的根结点 swap(arr, index, (index - 1) / 2); // 如果当前结点的值比根结点的值大，则交换 index = (index - 1) / 2; // 继续往下比较 &#125; &#125; // 调整大根堆 public static void heapify(int[] arr, int index, int size) &#123; // index * 2 + 1 当前结点的左孩子， + 2 为右孩子 int left = index * 2 + 1; while (left &lt; size) &#123; // left + 1 &lt; size 右孩子不越界 // 左孩子和右孩子谁大，谁的下标作为largest int largest = left + 1 &lt; size &amp;&amp; arr[left + 1] &gt; arr[left] ? left + 1 : left; // 我和孩子谁大，谁的下标作为largest largest = arr[largest] &gt; arr[index] ? largest : index; // 最大是自己， 则结束下沉 if (largest == index) &#123; break; &#125; // 不是，则继续下沉 swap(arr, largest, index); index = largest; left = index * 2 + 1; &#125; &#125; // 交换方法 public static void swap(int[] arr, int i, int j) &#123; int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; &#125;&#125; 时间复杂度堆排序的运行时间主要耗费在建初堆和调整堆时进行的反复“筛选”上。 在构建堆(初始化大顶堆)的过程中，完全二叉树从最下层最右边的非终端结点开始构建，将它与其孩子进行比较和必要的互换，对于每个非终端结点来说，其实最多进行两次比较和一次互换操作，因此整个构建堆的时间复杂度为:$O(n)$。大概需进行n/2 * 2 = n次比较和n/2次交换。 在正式排序时，n个结点的完全二叉树的深度为$⌊O(log_2n)⌋+1$，并且有n个数据则需要取n-1次调整成大顶堆的操作，每次调整成大顶堆的时间复杂度为$O(log2n)$。 初始化建堆的时间复杂度为$O(n)$，排序重建堆的时间复杂度为$O(log_2n)$，所以总的时间复杂度为$O(n+log_2n)=O(log_2n)O(n+log_2n)=O(log_2n)$。另外堆排序的比较次数和序列的初始状态有关，但只是在序列初始状态为堆的情况下比较次数显著减少，在序列有序或逆序的情况下比较次数不会发生明显变化。 实验研究表明，平均性能接近于最坏性能。 空间复杂度堆排序数据交换时需要一个辅助空间，故空间复杂度是$O(1)$。 算法特点 是不稳定的排序 只能用于顺序结构，不能用于链式结构 初始建堆所需要的比较次数较多，因此记录数较少时不宜采用。堆排序在最坏情况下时间复杂度为$O(nlog_2n)$ 参考博客园：堆排序详解-前程明亮]]></content>
      <categories>
        <category>排序</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git笔记（二）]]></title>
    <url>%2F2019%2F03%2F09%2FGit%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[本篇记述Git”时光穿梭机“功能： 版本回退 工作区和暂存区 管理修改 撤销修改 删除文件 时光机穿梭我们已经成功地添加并提交了一个readme.txt文件，现在，是时候继续工作了，于是，我们继续修改readme.txt文件，改成如下内容： 12Git is a distributed version control system.Git is free software. 现在，运行git status命令看看结果： 123456789$ git statusOn branch masterChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: readme.txtno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) git status命令可以让我们时刻掌握仓库当前的状态，上面的命令输出告诉我们，readme.txt被修改过了，但还没有准备提交的修改。 虽然Git告诉我们readme.txt被修改了，但如果能看看具体修改了什么内容，自然是很好的。比如你休假两周从国外回来，第一天上班时，已经记不清上次怎么修改的readme.txt，所以，需要用git diff这个命令看看： 123456789$ git diff readme.txt diff --git a/readme.txt b/readme.txtindex 46d49bf..9247db6 100644--- a/readme.txt+++ b/readme.txt@@ -1,2 +1,2 @@-Git is a version control system.+Git is a distributed version control system. Git is free software. git diff顾名思义就是查看difference，显示的格式正是Unix通用的diff格式，可以从上面的命令输出看到，我们在第一行添加了一个distributed单词。 知道了对readme.txt作了什么修改后，再把它提交到仓库就放心多了，提交修改和提交新文件是一样的两步，第一步是git add： 1$ git add readme.txt 同样没有任何输出。在执行第二步git commit之前，我们再运行git status看看当前仓库的状态： 123456$ git statusOn branch masterChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: readme.txt git status告诉我们，将要被提交的修改包括readme.txt，下一步，就可以放心地提交了： 123$ git commit -m &quot;add distributed&quot;[master e475afc] add distributed 1 file changed, 1 insertion(+), 1 deletion(-) 提交后，我们再用git status命令看看仓库的当前状态： 123$ git statusOn branch masternothing to commit, working tree clean Git告诉我们当前没有需要提交的修改，而且，工作目录是干净（working tree clean）的。 版本回退现在，你已经学会了修改文件，然后把修改提交到Git版本库，现在，再练习一次，修改readme.txt文件如下： 12Git is a distributed version control system.Git is free software distributed under the GPL. 然后尝试提交： 1234$ git add readme.txt$ git commit -m &quot;append GPL&quot;[master 1094adb] append GPL 1 file changed, 1 insertion(+), 1 deletion(-) 像这样，你不断对文件进行修改，然后不断提交修改到版本库里，就好比玩RPG游戏时，每通过一关就会自动把游戏状态存盘，如果某一关没过去，你还可以选择读取前一关的状态。有些时候，在打Boss之前，你会手动存盘，以便万一打Boss失败了，可以从最近的地方重新开始。Git也是一样，每当你觉得文件修改到一定程度的时候，就可以“保存一个快照”，这个快照在Git中被称为commit。一旦你把文件改乱了，或者误删了文件，还可以从最近的一个commit恢复，然后继续工作，而不是把几个月的工作成果全部丢失。 现在，我们回顾一下readme.txt文件一共有几个版本被提交到Git仓库里了： 版本1：wrote a readme file 12Git is a version control system.Git is free software. 版本2：add distributed 12Git is a distributed version control system.Git is free software. 版本3：append GPL 12Git is a distributed version control system.Git is free software distributed under the GPL. 当然了，在实际工作中，我们脑子里怎么可能记得一个几千行的文件每次都改了什么内容，不然要版本控制系统干什么。版本控制系统肯定有某个命令可以告诉我们历史记录，在Git中，我们用git log命令查看： 123456789101112131415161718$ git logcommit 1094adb7b9b3807259d8cb349e7df1d4d6477073 (HEAD -&gt; master)Author: Michael Liao &lt;askxuefeng@gmail.com&gt;Date: Fri May 18 21:06:15 2018 +0800 append GPLcommit e475afc93c209a690c39c13a46716e8fa000c366Author: Michael Liao &lt;askxuefeng@gmail.com&gt;Date: Fri May 18 21:03:36 2018 +0800 add distributedcommit eaadf4e385e865d25c48e7ca9c8395c3f7dfaef0Author: Michael Liao &lt;askxuefeng@gmail.com&gt;Date: Fri May 18 20:59:18 2018 +0800 wrote a readme file git log命令显示从最近到最远的提交日志，我们可以看到3次提交，最近的一次是append GPL，上一次是add distributed，最早的一次是wrote a readme file。 如果嫌输出信息太多，看得眼花缭乱的，可以试试加上--pretty=oneline参数： 1234$ git log --pretty=oneline1094adb7b9b3807259d8cb349e7df1d4d6477073 (HEAD -&gt; master) append GPLe475afc93c209a690c39c13a46716e8fa000c366 add distributedeaadf4e385e865d25c48e7ca9c8395c3f7dfaef0 wrote a readme file 需要友情提示的是，你看到的一大串类似1094adb...的是commit id（版本号），和SVN不一样，Git的commit id不是1，2，3……递增的数字，而是一个SHA1计算出来的一个非常大的数字，用十六进制表示，而且你看到的commit id和我的肯定不一样，以你自己的为准。为什么commit id需要用这么一大串数字表示呢？因为Git是分布式的版本控制系统，后面我们还要研究多人在同一个版本库里工作，如果大家都用1，2，3……作为版本号，那肯定就冲突了。 现在我们启动时光穿梭机，准备把readme.txt回退到上一个版本，也就是add distributed的那个版本，怎么做呢？ 首先，Git必须知道当前版本是哪个版本，在Git中，用HEAD表示当前版本，也就是最新的提交1094adb...（注意我的提交ID和你的肯定不一样），上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100。 现在，我们要把当前版本append GPL回退到上一个版本add distributed，就可以使用git reset命令： 12$ git reset --hard HEAD^HEAD is now at e475afc add distributed --hard参数有啥意义？这个后面再讲，现在你先放心使用。 看看readme.txt的内容是不是版本add distributed： 123$ cat readme.txtGit is a distributed version control system.Git is free software. 果然被还原了。 还可以继续回退到上一个版本wrote a readme file，不过且慢，然我们用git log再看看现在版本库的状态： 123456789101112$ git logcommit e475afc93c209a690c39c13a46716e8fa000c366 (HEAD -&gt; master)Author: Michael Liao &lt;askxuefeng@gmail.com&gt;Date: Fri May 18 21:03:36 2018 +0800 add distributedcommit eaadf4e385e865d25c48e7ca9c8395c3f7dfaef0Author: Michael Liao &lt;askxuefeng@gmail.com&gt;Date: Fri May 18 20:59:18 2018 +0800 wrote a readme file 最新的那个版本append GPL已经看不到了！好比你从21世纪坐时光穿梭机来到了19世纪，想再回去已经回不去了，肿么办？ 办法其实还是有的，只要上面的命令行窗口还没有被关掉，你就可以顺着往上找啊找啊，找到那个append GPL的commit id是1094adb...，于是就可以指定回到未来的某个版本： 12$ git reset --hard 1094aHEAD is now at 83b0afe append GPL 版本号没必要写全，前几位就可以了，Git会自动去找。当然也不能只写前一两位，因为Git可能会找到多个版本号，就无法确定是哪一个了。 再小心翼翼地看看readme.txt的内容： 123GPL：$ cat readme.txtGit is a distributed version control system.Git is free software distributed under the GPL. Git的版本回退速度非常快，因为Git在内部有个指向当前版本的HEAD指针，当你回退版本的时候，Git仅仅是把HEAD从指向append GPL： 改为指向add distributed： 然后顺便把工作区的文件更新了。所以你让HEAD指向哪个版本号，你就把当前版本定位在哪。 现在，你回退到了某个版本，关掉了电脑，第二天早上就后悔了，想恢复到新版本怎么办？找不到新版本的commit id怎么办？ 在Git中，总是有后悔药可以吃的。当你用$ git reset --hard HEAD^回退到add distributed版本时，再想恢复到append GPL，就必须找到append GPL的commit id。Git提供了一个命令git reflog用来记录你的每一次命令： 12345$ git refloge475afc HEAD@&#123;1&#125;: reset: moving to HEAD^1094adb (HEAD -&gt; master) HEAD@&#123;2&#125;: commit: append GPLe475afc HEAD@&#123;3&#125;: commit: add distributedeaadf4e HEAD@&#123;4&#125;: commit (initial): wrote a readme file 从输出可知，append GPL的commit id是1094adb，现在，你又可以乘坐时光机回到未来了。 小结现在总结一下： HEAD指向的版本就是当前版本，因此，Git允许我们在版本的历史之间穿梭，使用命令git reset --hard commit_id。 穿梭前，用git log可以查看提交历史，以便确定要回退到哪个版本。 要重返未来，用git reflog查看命令历史，以便确定要回到未来的哪个版本。 工作区和暂存区 工作区(Working Directory)你在电脑里能看到的目录 版本库(Repository)工作区有一个隐藏目录.git,这个不算工作区,而是Git的版本库.我们可以称它为RepoRepo里存放了很多东西,其中最重要的就是暂存区stage(或者叫index),还有Git为我们自动创建的第一个分支(Branch)master.以及指向master的一个指针叫HEAD. cat file_name命令，其功能是显示在工作区、暂存区和分支里同名文档的最新修改版本的内容 把文件往Git版本库里添加的时候，是分两步执行的：第一步是用git add把文件添加进去，实际上就是把文件修改添加到暂存区；第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。 管理修改为什么Git比其他版本控制系统设计得优秀，因为Git跟踪并管理的是修改，而非文件。 假如我们做一下操作 第一次修改 -&gt; git add -&gt; 第二次修改 -&gt; git commit Git管理的是修改，当你用git add命令后，在工作区的第一次修改被放入暂存区，准备提交，但是，在工作区的第二次修改并没有放入暂存区，所以，git commit只负责把暂存区的修改提交了，也就是第一次的修改被提交了，第二次的修改不会被提交。 提交后，用git diff HEAD -- readme.txt命令可以查看工作区和版本库里面最新版本的区别。 怎么提交第二次修改？可以先别提交，先git add第二次修改，再git commit，就相当于把两次修改合并后一块提交了： 第一次修改 -&gt; git add -&gt; 第二次修改 -&gt; git add -&gt; git commit 这样两次修改就都提交了 撤销修改 场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout -- file_name 可以用git checkout -- *丢弃所有工作区文件的修改 场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步 第一步用命令git reset HEAD file_name就回到了场景1 使用git reset HEAD丢弃所有暂存区的修改 第二步按场景1操作 场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考版本回退一节，不过前提是没有推送到远程库。 注意:使用版本退回操作git reset –hard会导致所有暂存区和工作区的当前修改但未commit的内容全部丢弃. 特别:使用git reset –hard HEAD会导致上述结果,并在git reflog中生成记录,但不改变 命令总结： 命令 作用域 常用情景 git reset 提交层面 在私有分支上舍弃一些没有提交的更改 git reset 文件层面 将文件从缓存区中移除 git checkout 提交层面 切换分支或查看旧版本 git checkout 文件层面 舍弃工作目录中的更改 git revert 提交层面 在公共分支上回滚更改 git revert 文件层面 （然而并没有） 删除文件命令git rm用于删除一个文件。如果一个文件已经被提交到版本库，那么你永远不用担心误删，但是要小心，你只能恢复文件到最新版本，你会丢失最近一次提交后你修改的内容。 使用rm file_name删除本地文件使用git rm file_name提交删除到暂存区使用git commit -m &quot;balabala&quot;提交到本地库注意: 可以直接使用git rm file_name删除本地文件以及提交删除到暂存区,但仅用于暂存区有此本地文件的情况 笔记记于：Git教程 - 廖雪峰的官方网站]]></content>
      <categories>
        <category>Git</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Git笔记（一）]]></title>
    <url>%2F2019%2F03%2F06%2FGit%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Git简介Git是目前世界上最先进的分布式版本控制系统 什么是版本控制系统？ 比如你在写Microsoft Word写文章，对每一个的修改都做个备份以及说明 版本 文件名 用户 说明 日期 1 service.doc 张三 删除了软件服务条款5 7/12 10:38 2 service.doc 张三 增加了License人数限制 7/12 18:09 3 service.doc 李四 财务部门调整了合同金额 7/13 9:51 4 service.doc 张三 延长了免费升级周期 7/14 15:17 当你使用Git，你就结束了手动管理多个“版本”的史前时代，进入到版本控制的新世纪。 集中式vs分布式比较早的CVS及SVN都是集中式的版本控制系统，而Git是分布式版本控制系统，集中式和分布式版本控制系统有什么区别呢？ 先说集中式版本控制系统，版本库是集中存放在中央服务器的，而干活的时候，用的都是自己的电脑，所以要先从中央服务器取得最新的版本，然后开始干活，干完活了，再把自己的活推送给中央服务器。中央服务器就好比是一个图书馆，你要改一本书，必须先从图书馆借出来，然后回到家自己改，改完了，再放回图书馆。 集中式版本控制系统最大的毛病就是必须联网才能工作，如果在局域网内还好，带宽够大，速度够快，可如果在互联网上，遇到网速慢的话，可能提交一个10M的文件就需要5分钟，这还不得把人给憋死啊。 那分布式版本控制系统与集中式版本控制系统有何不同呢？首先，分布式版本控制系统根本没有“中央服务器”，每个人的电脑上都是一个完整的版本库，这样，你工作的时候，就不需要联网了，因为版本库就在你自己的电脑上。既然每个人电脑上都有一个完整的版本库，那多个人如何协作呢？比方说你在自己电脑上改了文件A，你的同事也在他的电脑上改了文件A，这时，你们俩之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。 和集中式版本控制系统相比，分布式版本控制系统的安全性要高很多，因为每个人电脑里都有完整的版本库，某一个人的电脑坏掉了不要紧，随便从其他人那里复制一个就可以了。而集中式版本控制系统的中央服务器要是出了问题，所有人都没法干活了。 在实际使用分布式版本控制系统的时候，其实很少在两人之间的电脑上推送版本库的修改，因为可能你们俩不在一个局域网内，两台电脑互相访问不了，也可能今天你的同事病了，他的电脑压根没有开机。因此，分布式版本控制系统通常也有一台充当“中央服务器”的电脑，但这个服务器的作用仅仅是用来方便“交换”大家的修改，没有它大家也一样干活，只是交换修改不方便而已。 当然，Git的优势不单是不必联网这么简单，后面我们还会看到Git极其强大的分支管理，把SVN等远远抛在了后面。 安装Git最早Git是在Linux上开发的，很长一段时间内，Git也只能在Linux和Unix系统上跑。不过，慢慢地有人把它移植到了Windows上。现在，Git可以在Linux、Unix、Mac和Windows这几大平台上正常运行了。 要使用Git，第一步当然是安装Git了。 在Linux上安装Git首先，你可以试着输入git，看看系统有没有安装Git： 123$ gitThe program &apos;git&apos; is currently not installed. You can install it by typing:sudo apt-get install git 像上面的命令，有很多Linux会友好地告诉你Git没有安装，还会告诉你如何安装Git。 如果你碰巧用Debian或Ubuntu Linux，通过一条sudo apt-get install git就可以直接完成Git的安装，非常简单。 安装Git阅读: 1637394 最早Git是在Linux上开发的，很长一段时间内，Git也只能在Linux和Unix系统上跑。不过，慢慢地有人把它移植到了Windows上。现在，Git可以在Linux、Unix、Mac和Windows这几大平台上正常运行了。 要使用Git，第一步当然是安装Git了。根据你当前使用的平台来阅读下面的文字： 在Linux上安装Git首先，你可以试着输入git，看看系统有没有安装Git： 123$ gitThe program &apos;git&apos; is currently not installed. You can install it by typing:sudo apt-get install git 像上面的命令，有很多Linux会友好地告诉你Git没有安装，还会告诉你如何安装Git。 如果你碰巧用Debian或Ubuntu Linux，通过一条sudo apt-get install git就可以直接完成Git的安装，非常简单。 老一点的Debian或Ubuntu Linux，要把命令改为sudo apt-get install git-core，因为以前有个软件也叫GIT（GNU Interactive Tools），结果Git就只能叫git-core了。由于Git名气实在太大，后来就把GNU Interactive Tools改成gnuit，git-core正式改为git。 如果是其他Linux版本，可以直接通过源码安装。先从Git官网下载源码，然后解压，依次输入：./config，make，sudo make install这几个命令安装就好了。 在Mac OS X上安装Git如果你正在使用Mac做开发，有两种安装Git的方法。 一是安装homebrew，然后通过homebrew安装Git，具体方法请参考homebrew的文档：http://brew.sh/。 第二种方法更简单，也是推荐的方法，就是直接从AppStore安装Xcode，Xcode集成了Git，不过默认没有安装，你需要运行Xcode，选择菜单“Xcode”-&gt;“Preferences”，在弹出窗口中找到“Downloads”，选择“Command Line Tools”，点“Install”就可以完成安装了。 在Windows上安装Git在Windows上使用Git，可以从Git官网直接下载安装程序，（网速慢的同学请移步国内镜像），然后按默认选项安装即可。 安装完成后，在开始菜单里找到“Git”-&gt;“Git Bash”，蹦出一个类似命令行窗口的东西，就说明Git安装成功！ 安装完成后，还需要最后一步设置，在命令行输入： 12$ git config --global user.name &quot;Your Name&quot;$ git config --global user.email &quot;email@example.com&quot; 因为Git是分布式版本控制系统，所以，每个机器都必须自报家门：你的名字和Email地址。你也许会担心，如果有人故意冒充别人怎么办？这个不必担心，首先我们相信大家都是善良无知的群众，其次，真的有冒充的也是有办法可查的。 注意git config命令的--global参数，用了这个参数，表示你这台机器上所有的Git仓库都会使用这个配置，当然也可以对某个仓库指定不同的用户名和Email地址。 创建版本库什么是版本库呢？版本库又名仓库，英文名repository，你可以简单理解成一个目录，这个目录里面的所有文件都可以被Git管理起来，每个文件的修改、删除，Git都能跟踪，以便任何时刻都可以追踪历史，或者在将来某个时刻可以“还原”。 所以，创建一个版本库非常简单，首先，选择一个合适的地方，创建一个空目录： 1234$ mkdir learngit$ cd learngit$ pwd/Users/michael/learngit pwd命令用于显示当前目录。在我的Mac上，这个仓库位于/Users/michael/learngit。 如果你使用Windows系统，为了避免遇到各种莫名其妙的问题，请确保目录名（包括父目录）不包含中文。 第二步，通过git init命令把这个目录变成Git可以管理的仓库： 12$ git initInitialized empty Git repository in /Users/michael/learngit/.git/ 瞬间Git就把仓库建好了，而且告诉你是一个空的仓库（empty Git repository），细心的读者可以发现当前目录下多了一个.git的目录，这个目录是Git来跟踪管理版本库的，没事千万不要手动修改这个目录里面的文件，不然改乱了，就把Git仓库给破坏了。 如果你没有看到.git目录，那是因为这个目录默认是隐藏的，用ls -ah命令就可以看见。 把文件添加到版本库首先这里再明确一下，所有的版本控制系统，其实只能跟踪文本文件的改动，比如TXT文件，网页，所有的程序代码等等，Git也不例外。版本控制系统可以告诉你每次的改动，比如在第5行加了一个单词“Linux”，在第8行删了一个单词“Windows”。而图片、视频这些二进制文件，虽然也能由版本控制系统管理，但没法跟踪文件的变化，只能把二进制文件每次改动串起来，也就是只知道图片从100KB改成了120KB，但到底改了啥，版本控制系统不知道，也没法知道。 不幸的是，Microsoft的Word格式是二进制格式，因此，版本控制系统是没法跟踪Word文件的改动的，前面我们举的例子只是为了演示，如果要真正使用版本控制系统，就要以纯文本方式编写文件。 因为文本是有编码的，比如中文有常用的GBK编码，日文有Shift_JIS编码，如果没有历史遗留问题，强烈建议使用标准的UTF-8编码，所有语言使用同一种编码，既没有冲突，又被所有平台所支持。 创建一个readme.txt文件，一定要放到learngit目录下（子目录也行），放到其他地方Git会找不到这个文件。 第一步，用命令git add告诉Git，把文件添加到仓库： 1$ git add readme.txt 执行上面的命令，没有任何显示，这就对了，Unix的哲学是“没有消息就是好消息”，说明添加成功。 第二步，用命令git commit告诉Git，把文件提交到仓库： 1234$ git commit -m &quot;wrote a readme file&quot;[master (root-commit) eaadf4e] wrote a readme file 1 file changed, 2 insertions(+) create mode 100644 readme.txt 简单解释一下git commit命令，-m后面输入的是本次提交的说明，可以输入任意内容，当然最好是有意义的，这样你就能从历史记录里方便地找到改动记录。 git commit命令执行成功后会告诉你，1 file changed：1个文件被改动（我们新添加的readme.txt文件）；2 insertions：插入了两行内容（readme.txt有两行内容）。 小结现在总结以上两点内容： 初始化一个Git仓库，使用git init命令。 添加文件到Git仓库，分两步： 使用命令git add &lt;file&gt;，注意，可反复多次使用，添加多个文件； 使用命令git commit -m &lt;message&gt;，完成。 笔记记于：Git教程 - 廖雪峰的官方网站]]></content>
      <categories>
        <category>Git</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[垃圾收集器和内存分配策略(一)]]></title>
    <url>%2F2019%2F03%2F03%2F%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%92%8C%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[引入计数法概念 在对象中引入计数器(无符号整数)，用于记录有多少对象引用了该对象。 通过增减计数器实现对内存的管理。 分配对象时将计数器置1。 更新引用时先对新指定的对象进行计数器加，而后才对旧对象进行减。 在对计数器做减法时，判断其计数器是否等于0，等于0 表示为垃圾，即可进行回收。 在更新引用时就进行了垃圾的标记与回收，因此STW会很短而且当对象变垃圾时能立马被回收。 优点 即刻回收垃圾，在更改引用时就知道该对象是否为垃圾若是垃圾立马进行回收(但是该操作会占用用户线程的时间片) STW短，回收垃圾不需要遍历堆了。 不需要根据GC root遍历。 缺点 计数器值增减频繁。 计数器需要占用很多位。 实现繁琐，更新引用时很容易导致内存泄露。 循环引用无法回收(最重要的缺点) 引用计数算法的缺陷123456789101112131415161718192021public class ReferenceCountingGC &#123; public Object instance = null; private static int int_1MB = 1024 * 1024; private byte[] bigSize = new byte[10 * int_1MB]; public static void testGC() &#123; ReferenceCountingGC a = new ReferenceCountingGC(); ReferenceCountingGC b = new ReferenceCountingGC(); a.instance = b; b.instance = a; a = null; b = null; System.gc(); &#125; public static void main(String[] args) &#123; testGC(); &#125;&#125; 代码中的testGC()方法：对象a和b都有字段instance，赋值令a.instance = b 及b.instance = a，除此之外，这两个对象再无任何引用，实际上这两个对象已经不可能再被访问，但是它们因为互相引用着对方，导致它们的引用计数都不为0，于是引用计数算法无法通知GC收集器回收它们。 可达性分析算法概念在Java中，是通过可达性分析（Reachability Analysis）来判定对象是否存活的。该算法的基本思路就是通过一些被称为引用链（GC Roots）的对象作为起点，从这些节点开始向下搜索，搜索走过的路径被称为（Reference Chain)，当一个对象到GC Roots没有任何引用链相连时（即从GC Roots节点到该节点不可达），则证明该对象是不可用的。 如上图所示，object1~object4对GC Root都是可达的，说明不可被回收，object5和object6对GC Root节点不可达，说明其可以被回收。 在Java中，可作为GC Root的对象包括以下几种： 虚拟机栈（栈帧中的本地变量表）中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI（即一般说的Native方法）引用的对象 引用无论通过引用计数算法判断对象的引用数量，还是通过可达性分析算法判断对象的引用链是否可达，判断对象是否存活都与”引用“有关。 在JDK1.2之后，Java对引用的概念做了扩充，将引用分为四类： 强引用(Strong Reference) 软引用(Soft Reference) 弱引用(Weak Reference) 虚引用(Phantom Reference) 这四种引用的强度依次递减。 强引用强引用就是指在程序代码中普遍存在的，类似Object obj = new Object()这类似的引用，只要强引用在，垃圾搜集器永远不会搜集被引用的对象。也就是说，宁愿出现内存溢出，也不会回收这些对象。因此强引用是造成Java内存泄漏的主要原因之一。 软引用软引用是用来描述一些有用但并不是必需的对象，在Java中用java.lang.ref.SoftReference类来表示。对于软引用关联着的对象，只有在内存不足的时候JVM才会回收该对象。因此，这一点可以很好地用来解决OOM的问题，并且这个特性很适合用来实现缓存：比如网页缓存、图片缓存等。 弱引用弱引用也是用来描述非必需对象的，当JVM进行垃圾回收时，无论内存是否充足，都会回收被弱引用关联的对象。在java中，用java.lang.ref.WeakReference类来表示。 虚引用虚引用和前面的软引用、弱引用不同，它并不影响对象的生命周期。在java中用java.lang.ref.PhantomReference类表示。如果一个对象与虚引用关联，则跟没有引用与之关联一样，在任何时候都可能被垃圾回收器回收。要注意的是，虚引用必须和引用队列关联使用，当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会把这个虚引用加入到与之 关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。 垃圾收集算法标记 - 清除算法（Mark-Sweep）介绍标记 - 清除算法是最基础的收集算法，算法分为两个阶段“标记“和”清除。 标记：标记的过程其实就是，遍历所有的GC Roots，然后将所有GC Roots可达的对象标记为存活的对象。 清除：清除的过程将遍历堆中所有的对象，将没有标记的对象全部清除掉。 这两个步骤用通俗的话解释一下就是：当程序运行期间，若可以使用的内存被耗尽的时候，GC线程就会被触发并将程序暂停，随后将依旧存活的对象标记一遍，最终再将堆中所有没被标记的对象全部清除掉，接下来便让程序恢复运行。 缺点 效率问题：效率比较低（递归与全堆对象遍历），而且在进行GC的时候，需要停止应用程序，这会导致用户体验非常差劲，尤其对于交互式的应用程序来说简直是无法接受。试想一下，如果你玩一个网站，这个网站一个小时就挂五分钟，你还玩吗？ 空间问题：这种方式清理出来的空闲内存是不连续的，这点不难理解，我们的死亡对象都是随即的出现在内存的各个角落的，现在把它们清除之后，内存的布局自然会乱七八糟。而为了应付这一点，JVM就不得不维持一个内存的空闲列表，这又是一种开销。而且在分配数组对象的时候，寻找连续的内存空间会不太好找。 复制算法（Copying）介绍为解决效率问题，“复制”收集算法出现了。它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。 这样使得每次都是对其中的一块进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。 缺点 效率问题：在对象存活率较高时，复制操作次数多，效率降低； 空间问题：內存缩小了一半；需要額外空间做分配担保(老年代) From Survivor, To Survivor使用的就是复制算法，老年代不使用这种算法。 标记 - 整理算法(Mark-Compact)介绍复制收集算法在对象存活率较高时就要执行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。 1根据老年代的特点，有人提出了另外一种“标记-整理”（Mark-Compact）算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法（Generational Collection）介绍GC分代的基本假设：绝大部分对象的生命周期都非常短暂，存活时间短。“分代收集”算法，把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清理”或“标记-整理”算法来进行回收。 垃圾收集器如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。Java虚拟机规范中对垃圾收集器应该如何实现并没有任何规定，因此不同的厂商、版本的虚拟机所提供的垃圾收集器都可能会有很大差别，并且一般都会提供参数供用户根据自己的应用特点和要求组合出各个年代所使用的收集器。接下来讨论的收集器基于JDK1.7 Update 14 之后的HotSpot虚拟机（在此版本中正式提供了商用的G1收集器，之前G1仍处于实验状态），该虚拟机包含的所有收集器如下图所示： 相关概念并行和并发 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续运行。而垃圾收集程序运行在另一个CPU上。 吞吐量（Throughput）吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即 吞吐量 = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间）。 假设虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。 Minor GC 和 Full GC 新生代GC（Minor GC）：指发生在新生代的垃圾收集动作，因为Java对象大多都具备朝生夕灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。具体原理见上一篇文章。 老年代GC（Major GC / Full GC）：指发生在老年代的GC，出现了Major GC，经常会伴随至少一次的Minor GC（但非绝对的，在Parallel Scavenge收集器的收集策略里就有直接进行Major GC的策略选择过程）。Major GC的速度一般会比Minor GC慢10倍以上。 新生代收集器Serial收集器Serial（串行）收集器是最基本、发展历史最悠久的收集器，它是采用复制算法的新生代收集器，曾经（JDK 1.3.1之前）是虚拟机新生代收集的唯一选择。它是一个单线程收集器，只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集时，必须暂停其他所有的工作线程，直至Serial收集器收集结束为止（“Stop The World”）。这项工作是由虚拟机在后台自动发起和自动完成的，在用户不可见的情况下把用户正常工作的线程全部停掉，这对很多应用来说是难以接收的。 下图展示了Serial 收集器（老年代采用Serial Old收集器）的运行过程： ParNew收集器除了使用多线程收集外，其他与Serial收集器相比并无太多创新之处，但它却是许多运行在Server模式下的虚拟机中首选的新生代收集器，其中有一个与性能无关的重要原因是，除了Serial收集器外，目前只有它能和CMS收集器（Concurrent Mark Sweep）配合工作，CMS收集器是JDK 1.5推出的一个具有划时代意义的收集器，具体内容将在稍后进行介绍。 ParNew 收集器在单CPU的环境中绝对不会有比Serial收集器有更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证可以超越。在多CPU环境下，随着CPU的数量增加，它对于GC时系统资源的有效利用是很有好处的。它默认开启的收集线程数与CPU的数量相同，在CPU非常多的情况下可使用-XX:ParallerGCThreads参数设置。 ParNew收集器ParNew收集器就是Serial收集器的多线程版本，它也是一个新生代收集器。除了使用多线程进行垃圾收集外，其余行为包括Serial收集器可用的所有控制参数、收集算法（复制算法）、Stop The World、对象分配规则、回收策略等与Serial收集器完全相同，两者共用了相当多的代码。 ParNew收集器的工作过程如下图（老年代采用Serial Old收集器）： ParNew收集器除了使用多线程收集外，其他与Serial收集器相比并无太多创新之处，但它却是许多运行在Server模式下的虚拟机中首选的新生代收集器，其中有一个与性能无关的重要原因是，除了Serial收集器外，目前只有它能和CMS收集器（Concurrent Mark Sweep）配合工作，CMS收集器是JDK 1.5推出的一个具有划时代意义的收集器，具体内容将在稍后进行介绍。 ParNew 收集器在单CPU的环境中绝对不会有比Serial收集器有更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证可以超越。在多CPU环境下，随着CPU的数量增加，它对于GC时系统资源的有效利用是很有好处的。它默认开启的收集线程数与CPU的数量相同，在CPU非常多的情况下可使用-XX:ParallerGCThreads参数设置。 Parallel Scavenge 收集器Parallel Scavenge收集器也是一个并行的多线程新生代收集器，它也使用复制算法。Parallel Scavenge收集器的特点是它的关注点与其他收集器不同，CMS等收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标是达到一个可控制的吞吐量（Throughput）。 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验。而高吞吐量则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 Parallel Scavenge收集器除了会显而易见地提供可以精确控制吞吐量的参数，还提供了一个参数-XX:+UseAdaptiveSizePolicy，这是一个开关参数，打开参数后，就不需要手工指定新生代的大小（-Xmn）、Eden和Survivor区的比例（-XX:SurvivorRatio）、晋升老年代对象年龄（-XX:PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种方式称为GC自适应的调节策略（GC Ergonomics）。自适应调节策略也是Parallel Scavenge收集器与ParNew收集器的一个重要区别。 另外值得注意的一点是，Parallel Scavenge收集器无法与CMS收集器配合使用，所以在JDK 1.6推出Parallel Old之前，如果新生代选择Parallel Scavenge收集器，老年代只有Serial Old收集器能与之配合使用。 老年代收集器Serial Old收集器Serial Old 是 Serial收集器的老年代版本，它同样是一个单线程收集器，使用“标记-整理”（Mark-Compact）算法。 此收集器的主要意义也是在于给Client模式下的虚拟机使用。如果在Server模式下，它还有两大用途： 在JDK1.5 以及之前版本（Parallel Old诞生以前）中与Parallel Scavenge收集器搭配使用。 作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure时使用。 Parallel Old收集器Parallel Old收集器是Parallel Scavenge收集器的老年代版本，使用多线程和“标记 - 整理”算法。前面已经提到过，这个收集器是在JDK 1.6中才开始提供的，在此之前，如果新生代选择了Parallel Scavenge收集器，老年代除了Serial Old以外别无选择，所以在Parallel Old诞生以后，“吞吐量优先”收集器终于有了比较名副其实的应用组合，在注重吞吐量以及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge加Parallel Old收集器。Parallel Old收集器的工作流程与Parallel Scavenge相同。 这里给出Parallel Scavenge/Parallel Old收集器配合使用的流程图： CMS收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器，它非常符合那些集中在互联网站或者B/S系统的服务端上的Java应用，这些应用都非常重视服务的响应速度。从名字上（“Mark Sweep”）就可以看出它是基于“标记-清除”算法实现的。 CMS收集器工作的整个流程分为以下4个步骤： 初始标记（CMS initial mark）：仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，需要“Stop The World”。 并发标记（CMS concurrent mark）：进行GC Roots Tracing的过程，在整个过程中耗时最长。 重新标记（CMS remark）：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。此阶段也需要“Stop The World”。 并发清除（CMS concurrent sweep） 由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。通过下图可以比较清楚地看到CMS收集器的运作步骤中并发和需要停顿的时间： 优点CMS是一款优秀的收集器，它的主要优点在名字上已经体现出来了：并发收集、低停顿，因此CMS收集器也被称为并发低停顿收集器（Concurrent Low Pause Collector）。 缺点 对CPU资源非常敏感 其实，面向并发设计的程序都对CPU资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。CMS默认启动的回收线程数是（CPU数量+3）/4，也就是当CPU在4个以上时，并发回收时垃圾收集线程不少于25%的CPU资源，并且随着CPU数量的增加而下降。但是当CPU不足4个时（比如2个），CMS对用户程序的影响就可能变得很大，如果本来CPU负载就比较大，还要分出一半的运算能力去执行收集器线程，就可能导致用户程序的执行速度忽然降低了50%，其实也让人无法接受。 无法处理浮动垃圾（Floating Garbage） 可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生。这一部分垃圾出现在标记过程之后，CMS无法再当次收集中处理掉它们，只好留待下一次GC时再清理掉。这一部分垃圾就被称为“浮动垃圾”。也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。 标记-清除算法导致的空间碎片 CMS是一款基于“标记-清除”算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。空间碎片过多时，将会给大对象分配带来很大麻烦，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象。 G1收集器G1（Garbage-First）收集器是当今收集器技术发展最前沿的成果之一，它是一款面向服务端应用的垃圾收集器，HotSpot开发团队赋予它的使命是（在比较长期的）未来可以替换掉JDK 1.5中发布的CMS收集器。与其他GC收集器相比，G1具备如下特点： 并行与并发 G1 能充分利用多CPU、多核环境下的硬件优势，使用多个CPU来缩短“Stop The World”停顿时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。 分代收集 与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同方式去处理新创建的对象和已存活一段时间、熬过多次GC的旧对象来获取更好的收集效果。 空间整合 G1从整体来看是基于“标记-整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的。这意味着G1运行期间不会产生内存空间碎片，收集后能提供规整的可用内存。此特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。 可预测的停顿 这是G1相对CMS的一大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了降低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在GC上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了。 横跨整个堆内存在G1之前的其他收集器进行收集的范围都是整个新生代或者老生代，而G1不再是这样。G1在使用时，Java堆的内存布局与其他收集器有很大区别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，而都是一部分Region（不需要连续）的集合。 建立可预测的时间模型G1收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region（这也就是Garbage-First名称的来由）。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。 避免全堆扫描——Remembered SetG1把Java堆分为多个Region，就是“化整为零”。但是Region不可能是孤立的，一个对象分配在某个Region中，可以与整个Java堆任意的对象发生引用关系。在做可达性分析确定对象是否存活的时候，需要扫描整个Java堆才能保证准确性，这显然是对GC效率的极大伤害。 为了避免全堆扫描的发生，虚拟机为G1中每个Region维护了一个与之对应的Remembered Set。虚拟机发现程序在对Reference类型的数据进行写操作时，会产生一个Write Barrier暂时中断写操作，检查Reference引用的对象是否处于不同的Region之中（在分代的例子中就是检查是否老年代中的对象引用了新生代中的对象），如果是，便通过CardTable把相关引用信息记录到被引用对象所属的Region的Remembered Set之中。当进行内存回收时，在GC根节点的枚举范围中加入Remembered Set即可保证不对全堆扫描也不会有遗漏。 如果不计算维护Remembered Set的操作，G1收集器的运作大致可划分为以下几个步骤： 初始标记（Initial Marking） 仅仅只是标记一下GC Roots 能直接关联到的对象，并且修改TAMS（Nest Top Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可以的Region中创建对象，此阶段需要停顿线程，但耗时很短。 并发标记（Concurrent Marking） 从GC Root 开始对堆中对象进行可达性分析，找到存活对象，此阶段耗时较长，但可与用户程序并发执行。 最终标记（Final Marking） 为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的Remembered Set Logs里面，最终标记阶段需要把Remembered Set Logs的数据合并到Remembered Set中，这阶段需要停顿线程，但是可并行执行。 筛选回收（Live Data Counting and Evacuation） 首先对各个Region中的回收价值和成本进行排序，根据用户所期望的GC 停顿是时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。 通过下图可以比较清楚地看到G1收集器的运作步骤中并发和需要停顿的阶段（Safepoint处）： 总结 收集器 串行、并行or并发 新生代/老年代 算法 目标 适用场景 Serial 串行 新生代 复制算法 响应速度优先 单CPU环境下的Client模式 Serial Old 串行 老年代 标记-整理 响应速度优先 单CPU环境下的Client模式、CMS的后备预案 ParNew 并行 新生代 复制算法 响应速度优先 多CPU环境时在Server模式下与CMS配合 Parallel Scavenge 并行 新生代 复制算法 吞吐量优先 在后台运算而不需要太多交互的任务 Parallel Old 并行 老年代 标记-整理 吞吐量优先 在后台运算而不需要太多交互的任务 CMS 并发 老年代 标记-清除 响应速度优先 集中在互联网站或B/S系统服务端上的Java应用 G1 并发 both 标记-整理+复制算法 响应速度优先 面向服务端应用，将来替换CMS 垃圾收集的相关常用参数]]></content>
      <categories>
        <category>JVM</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[图床]]></title>
    <url>%2F2019%2F03%2F01%2F%E5%9B%BE%E5%BA%8A%2F</url>
    <content type="text"><![CDATA[关于图床的选择网上谷歌下还是能搜到很多图床网站的，先随便列举一些 公共图床SM.MS https://sm.ms/SM.MS 是由 V2EX @Showfom 自建的，无外链限制，无流量限制的图床，支持 HTTPS，速度不错，已经运行两年多了。 极简图床 https://jiantuku.com/#/ 路过图床 https://imgchr.com/ Imgur https://imgur.com/Imgur 是一家国外老牌的图片存储服务商，国外速度很快，口碑不错，支持 HTTPS。但是国内速度很不稳定，所以追求国内速度的同学慎用。 Qchan图床http://tuchuang.org/ 微博图床 不限空间，不限流量。最重要的是，新浪微博允许外链引用图片。速度、安全、稳定。 微博图床，可以自定义支持七牛，界面简洁美观，支持 Chrome 插件，注册后还可以同步上传历史。 关于微博图床的Chrome插件： 一：WeiboPicBed，地址是https://github.com/Suxiaogang/WeiboPicBed/不过现在已经停止维护了 二：Weibo-Picture-Store，地址是https://github.com/Semibold/Weibo-Picture-Store这个项目目前还在维护 自建图床 目前自建图床方案有两种 是利用云服务商提供的存储服务来作为图床，通过 API 来管理图片 是在 VPS 上安装开源的图片或文件管理程序，只要能提供外链，基本都可以作为图床来用。 建图床（云服务） 七牛云，又拍云，阿里云OSS 自建图床（开源方案） 如果你有 VPS，并且网络速度 OK 的话，自建图床也是一个不错的选择。 Lychee https://github.com/electerious/LycheeLychee 是一个开源免费的基于 PHP 的图片管理系统，支持 Docker 部署，可以直接当做图床来用，Lychee 还支持很多扩展。 树洞外链 https://yun.aoaoao.me/https://github.com/HFO4/shudong-share树洞外链 是一款免费开源的 PHP 外链网盘系统，界面简洁友好，支持七牛、本地、远程、阿里云OSS、又拍云五种储存方式，支持多用户系统，多上传方案策略。 Chevereto https://chevereto.com/https://github.com/Chevereto/Chevereto-Freehttps://chevereto.com/docs/requirementsChevereto 是一款分享照片的程序，可以非常轻松得在自己的服务器上搭建照片分享程序，功能强大，外观精美。Chevereto 本身是收费使用的，一次性付费，终身使用，但是其开源版本可以免费使用。 使用图床的目的是希望文章的图片资源能有更好的加载速度和稳定的显示效果。]]></content>
  </entry>
</search>
